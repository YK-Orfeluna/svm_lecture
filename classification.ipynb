{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythonを使った機械学習：Classification（分類）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習（Machine Learning）とは？\n",
    "与えられたデータ群から規則性を見つけ出して，人間の学習能力をコンピュータ上で再現すること\n",
    "\n",
    "## 教師あり学習\n",
    "人間が正解データ（教師データ）を事前に与えて，それに基づいて学習を行う手法．<br>\n",
    "Classification（分類）やRegresion（回帰）など\n",
    "\n",
    "### Classification: Suport Vector Machine（SVM）\n",
    "複数のデータ群を分類する境界線を作り出すことで，与えられたデータがどの分類に属するのかがわかる<br>\n",
    "境界線の引き方にも色々と種類がある<br>\n",
    "![](./images/svms.png) <br>\n",
    "http://scikit-learn.org/stable/auto_examples/exercises/plot_iris_exercise.html\n",
    "\n",
    "### Classification: K-Nearest Neighbor Algorithm(KNN法）\n",
    "教師データ上に与えられたデータを配置した時，教師データに近いk個のデータの割合で与えられたデータの割合を決める<br>\n",
    "![](./images/knn.png)\n",
    "\n",
    "## 教師なし学習\n",
    "人間から正解データを付与されず，アルゴリズムによってコンピュータが答え（分類）を計算する手法<br>\n",
    "Clustering（クラスタリング）など\n",
    "\n",
    "## 半教師あり学習\n",
    "教師ありとなしのいいとこ取りみたいな感じ\n",
    "\n",
    "# ここでは，Classificationを扱う\n",
    "\n",
    "# 特徴量（Features）とは？\n",
    "分類のためには特徴量が必要<br>\n",
    "特徴量＝コンピュータが理解できるデータ上の違い<br>\n",
    "この違いが分類の決めてになる\n",
    "\n",
    "## Irisデータ\n",
    "有名なデータセットの一つで，あやめ（Iris）の花の萼片（Sepal）と花びら（Petal）の長さ（Length）と幅（Width）が三種類分（Setosa・Versicolour・Virginica）格納されている<br>\n",
    "![](./images/iris.jpg)\n",
    "<br>\n",
    "データの種類は次元と言われる<br>\n",
    "つまり，Irisデータの場合四種類のデータなので，「四次元」のデータということになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learnとは？\n",
    "![Scikit-Learn ロゴマーク](http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png)\n",
    "Pythonで提供されている機械学習のライブラリ<br>\n",
    "http://scikit-learn.org/stable/index.html\n",
    "<br>\n",
    "importするときは，sklearnとして扱われる<br>\n",
    "anacondaに標準インストールされている<br>\n",
    "<br>\n",
    "anacondaを使っていない場合は\n",
    "* pip install scikit-learn\n",
    "\n",
    "<br>で導入可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# では，実際にやってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n', 'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
      "      dtype='<U10'), 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
      "       [ 4.9,  3. ,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.3,  0.2],\n",
      "       [ 4.6,  3.1,  1.5,  0.2],\n",
      "       [ 5. ,  3.6,  1.4,  0.2],\n",
      "       [ 5.4,  3.9,  1.7,  0.4],\n",
      "       [ 4.6,  3.4,  1.4,  0.3],\n",
      "       [ 5. ,  3.4,  1.5,  0.2],\n",
      "       [ 4.4,  2.9,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5.4,  3.7,  1.5,  0.2],\n",
      "       [ 4.8,  3.4,  1.6,  0.2],\n",
      "       [ 4.8,  3. ,  1.4,  0.1],\n",
      "       [ 4.3,  3. ,  1.1,  0.1],\n",
      "       [ 5.8,  4. ,  1.2,  0.2],\n",
      "       [ 5.7,  4.4,  1.5,  0.4],\n",
      "       [ 5.4,  3.9,  1.3,  0.4],\n",
      "       [ 5.1,  3.5,  1.4,  0.3],\n",
      "       [ 5.7,  3.8,  1.7,  0.3],\n",
      "       [ 5.1,  3.8,  1.5,  0.3],\n",
      "       [ 5.4,  3.4,  1.7,  0.2],\n",
      "       [ 5.1,  3.7,  1.5,  0.4],\n",
      "       [ 4.6,  3.6,  1. ,  0.2],\n",
      "       [ 5.1,  3.3,  1.7,  0.5],\n",
      "       [ 4.8,  3.4,  1.9,  0.2],\n",
      "       [ 5. ,  3. ,  1.6,  0.2],\n",
      "       [ 5. ,  3.4,  1.6,  0.4],\n",
      "       [ 5.2,  3.5,  1.5,  0.2],\n",
      "       [ 5.2,  3.4,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.6,  0.2],\n",
      "       [ 4.8,  3.1,  1.6,  0.2],\n",
      "       [ 5.4,  3.4,  1.5,  0.4],\n",
      "       [ 5.2,  4.1,  1.5,  0.1],\n",
      "       [ 5.5,  4.2,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5. ,  3.2,  1.2,  0.2],\n",
      "       [ 5.5,  3.5,  1.3,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 4.4,  3. ,  1.3,  0.2],\n",
      "       [ 5.1,  3.4,  1.5,  0.2],\n",
      "       [ 5. ,  3.5,  1.3,  0.3],\n",
      "       [ 4.5,  2.3,  1.3,  0.3],\n",
      "       [ 4.4,  3.2,  1.3,  0.2],\n",
      "       [ 5. ,  3.5,  1.6,  0.6],\n",
      "       [ 5.1,  3.8,  1.9,  0.4],\n",
      "       [ 4.8,  3. ,  1.4,  0.3],\n",
      "       [ 5.1,  3.8,  1.6,  0.2],\n",
      "       [ 4.6,  3.2,  1.4,  0.2],\n",
      "       [ 5.3,  3.7,  1.5,  0.2],\n",
      "       [ 5. ,  3.3,  1.4,  0.2],\n",
      "       [ 7. ,  3.2,  4.7,  1.4],\n",
      "       [ 6.4,  3.2,  4.5,  1.5],\n",
      "       [ 6.9,  3.1,  4.9,  1.5],\n",
      "       [ 5.5,  2.3,  4. ,  1.3],\n",
      "       [ 6.5,  2.8,  4.6,  1.5],\n",
      "       [ 5.7,  2.8,  4.5,  1.3],\n",
      "       [ 6.3,  3.3,  4.7,  1.6],\n",
      "       [ 4.9,  2.4,  3.3,  1. ],\n",
      "       [ 6.6,  2.9,  4.6,  1.3],\n",
      "       [ 5.2,  2.7,  3.9,  1.4],\n",
      "       [ 5. ,  2. ,  3.5,  1. ],\n",
      "       [ 5.9,  3. ,  4.2,  1.5],\n",
      "       [ 6. ,  2.2,  4. ,  1. ],\n",
      "       [ 6.1,  2.9,  4.7,  1.4],\n",
      "       [ 5.6,  2.9,  3.6,  1.3],\n",
      "       [ 6.7,  3.1,  4.4,  1.4],\n",
      "       [ 5.6,  3. ,  4.5,  1.5],\n",
      "       [ 5.8,  2.7,  4.1,  1. ],\n",
      "       [ 6.2,  2.2,  4.5,  1.5],\n",
      "       [ 5.6,  2.5,  3.9,  1.1],\n",
      "       [ 5.9,  3.2,  4.8,  1.8],\n",
      "       [ 6.1,  2.8,  4. ,  1.3],\n",
      "       [ 6.3,  2.5,  4.9,  1.5],\n",
      "       [ 6.1,  2.8,  4.7,  1.2],\n",
      "       [ 6.4,  2.9,  4.3,  1.3],\n",
      "       [ 6.6,  3. ,  4.4,  1.4],\n",
      "       [ 6.8,  2.8,  4.8,  1.4],\n",
      "       [ 6.7,  3. ,  5. ,  1.7],\n",
      "       [ 6. ,  2.9,  4.5,  1.5],\n",
      "       [ 5.7,  2.6,  3.5,  1. ],\n",
      "       [ 5.5,  2.4,  3.8,  1.1],\n",
      "       [ 5.5,  2.4,  3.7,  1. ],\n",
      "       [ 5.8,  2.7,  3.9,  1.2],\n",
      "       [ 6. ,  2.7,  5.1,  1.6],\n",
      "       [ 5.4,  3. ,  4.5,  1.5],\n",
      "       [ 6. ,  3.4,  4.5,  1.6],\n",
      "       [ 6.7,  3.1,  4.7,  1.5],\n",
      "       [ 6.3,  2.3,  4.4,  1.3],\n",
      "       [ 5.6,  3. ,  4.1,  1.3],\n",
      "       [ 5.5,  2.5,  4. ,  1.3],\n",
      "       [ 5.5,  2.6,  4.4,  1.2],\n",
      "       [ 6.1,  3. ,  4.6,  1.4],\n",
      "       [ 5.8,  2.6,  4. ,  1.2],\n",
      "       [ 5. ,  2.3,  3.3,  1. ],\n",
      "       [ 5.6,  2.7,  4.2,  1.3],\n",
      "       [ 5.7,  3. ,  4.2,  1.2],\n",
      "       [ 5.7,  2.9,  4.2,  1.3],\n",
      "       [ 6.2,  2.9,  4.3,  1.3],\n",
      "       [ 5.1,  2.5,  3. ,  1.1],\n",
      "       [ 5.7,  2.8,  4.1,  1.3],\n",
      "       [ 6.3,  3.3,  6. ,  2.5],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 7.1,  3. ,  5.9,  2.1],\n",
      "       [ 6.3,  2.9,  5.6,  1.8],\n",
      "       [ 6.5,  3. ,  5.8,  2.2],\n",
      "       [ 7.6,  3. ,  6.6,  2.1],\n",
      "       [ 4.9,  2.5,  4.5,  1.7],\n",
      "       [ 7.3,  2.9,  6.3,  1.8],\n",
      "       [ 6.7,  2.5,  5.8,  1.8],\n",
      "       [ 7.2,  3.6,  6.1,  2.5],\n",
      "       [ 6.5,  3.2,  5.1,  2. ],\n",
      "       [ 6.4,  2.7,  5.3,  1.9],\n",
      "       [ 6.8,  3. ,  5.5,  2.1],\n",
      "       [ 5.7,  2.5,  5. ,  2. ],\n",
      "       [ 5.8,  2.8,  5.1,  2.4],\n",
      "       [ 6.4,  3.2,  5.3,  2.3],\n",
      "       [ 6.5,  3. ,  5.5,  1.8],\n",
      "       [ 7.7,  3.8,  6.7,  2.2],\n",
      "       [ 7.7,  2.6,  6.9,  2.3],\n",
      "       [ 6. ,  2.2,  5. ,  1.5],\n",
      "       [ 6.9,  3.2,  5.7,  2.3],\n",
      "       [ 5.6,  2.8,  4.9,  2. ],\n",
      "       [ 7.7,  2.8,  6.7,  2. ],\n",
      "       [ 6.3,  2.7,  4.9,  1.8],\n",
      "       [ 6.7,  3.3,  5.7,  2.1],\n",
      "       [ 7.2,  3.2,  6. ,  1.8],\n",
      "       [ 6.2,  2.8,  4.8,  1.8],\n",
      "       [ 6.1,  3. ,  4.9,  1.8],\n",
      "       [ 6.4,  2.8,  5.6,  2.1],\n",
      "       [ 7.2,  3. ,  5.8,  1.6],\n",
      "       [ 7.4,  2.8,  6.1,  1.9],\n",
      "       [ 7.9,  3.8,  6.4,  2. ],\n",
      "       [ 6.4,  2.8,  5.6,  2.2],\n",
      "       [ 6.3,  2.8,  5.1,  1.5],\n",
      "       [ 6.1,  2.6,  5.6,  1.4],\n",
      "       [ 7.7,  3. ,  6.1,  2.3],\n",
      "       [ 6.3,  3.4,  5.6,  2.4],\n",
      "       [ 6.4,  3.1,  5.5,  1.8],\n",
      "       [ 6. ,  3. ,  4.8,  1.8],\n",
      "       [ 6.9,  3.1,  5.4,  2.1],\n",
      "       [ 6.7,  3.1,  5.6,  2.4],\n",
      "       [ 6.9,  3.1,  5.1,  2.3],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 6.8,  3.2,  5.9,  2.3],\n",
      "       [ 6.7,  3.3,  5.7,  2.5],\n",
      "       [ 6.7,  3. ,  5.2,  2.3],\n",
      "       [ 6.3,  2.5,  5. ,  1.9],\n",
      "       [ 6.5,  3. ,  5.2,  2. ],\n",
      "       [ 6.2,  3.4,  5.4,  2.3],\n",
      "       [ 5.9,  3. ,  5.1,  1.8]]), 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "#  irisデータを読み込む\n",
    "iris = datasets.load_iris()\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# irisデータを学習データとテストデータに分割する\n",
    "# データの奇数番目を学習データに，偶数番目をテストデータにする\n",
    "\n",
    "x_train = iris.data[range(0, len(iris.data), 2)]\n",
    "y_train = iris.target[range(0, len(iris.data), 2)]\n",
    "\n",
    "x_test = iris.data[range(1, len(iris.data), 2)]\n",
    "y_test = iris.target[range(1, len(iris.data), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': True,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#　学習の用意\n",
    "svm = SVC(probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "# 分類器の設定を確認する\n",
    "svm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習器に教師データを与えて学習させる\n",
    "# 引数は特徴量，教師データ（ラベル）\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "# 分類器にテストデータを分類させる\n",
    "predict = svm.predict(x_test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作成した分類器を評価する\n",
    "### 適合率（Precion）と再現率（Recall）とは？\n",
    "#### 適合率\n",
    "検索結果の中で，どの程度が正解に含まれるか\n",
    "#### 再現率\n",
    "正解の中で，どの程度が検索にヒットするのか\n",
    "![](http://cdn-ak.f.st-hatena.com/images/fotolife/Z/Zellij/20120214/20120214075315.png)\n",
    "<br>http://f.hatena.ne.jp/Zellij/20120214075315<br>\n",
    "\n",
    "# わからん！\n",
    "ということで，混合行列\n",
    "### 混合行列（Confusion Matrix）とは？\n",
    "テストデータがどのラベルにどれだけ分類されたかを表す行列<br>\n",
    "![](./images/cm1.png)<br>\n",
    "![](./images/cm2.png)<br>\n",
    "![](./images/cm3.png)<br>\n",
    "![](./images/cm4.png)<br>\n",
    "\n",
    "### F値（F-measure）とは？\n",
    "適合率と再現率は負の相関関係にあることが多い＝トレードオフの関係にある<br>\n",
    "ということで，分類器の制度を適合率と再現率の調和平均＝F値で評価する<br>\n",
    "$\n",
    "F-measure = \\displaystyle　\\frac{2\\dot precion \\times recall}{precion + recall}\n",
    "$<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  0,  0],\n",
       "       [ 0, 24,  1],\n",
       "       [ 0,  4, 21]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先ほどの分類器の混合行列を表示する\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 引数は，正解データと予測結果\n",
    "matrix = confusion_matrix(y_test, predict)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.86      0.96      0.91        25\n",
      "  virginica       0.95      0.84      0.89        25\n",
      "\n",
      "avg / total       0.94      0.93      0.93        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F値を計算する\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 引数は，正解データと予測結果\n",
    "# オプションとして，target_namesを利用可能\n",
    "report = classification_report(y_test, predict, target_names=iris.target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-分割交差検定（K-fold Cross-Validation）による分類器の検証\n",
    "データ数があまり多くなくて，学習データとテストデータにわけると数が足りない場合などに利用される\n",
    "![](./images/kfcv.png)\n",
    "\n",
    "### グリッドサーチとは？\n",
    "機械学習には，学習の際のパラメータが存在し，そのパラメータをチューニングして最良な分類器を作成する<br>\n",
    "以下では，k分割交差検定法とグリッドサーチが同時に実装されている関数を用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
      "0        0.003116         0.000710         0.973333          0.988148       1   \n",
      "1        0.002143         0.000408         0.980000          0.980000      10   \n",
      "2        0.005788         0.000630         0.973333          0.981481     100   \n",
      "3        0.009609         0.000691         0.980000          0.986667    1000   \n",
      "4        0.008661         0.000613         0.906667          0.921481       1   \n",
      "5        0.010288         0.000629         0.906667          0.921481       1   \n",
      "6        0.005414         0.000589         0.933333          0.945185      10   \n",
      "7        0.007319         0.000585         0.906667          0.921481      10   \n",
      "8        0.002954         0.000486         0.980000          0.979259     100   \n",
      "9        0.004994         0.000546         0.933333          0.945185     100   \n",
      "10       0.002586         0.000455         0.980000          0.980000    1000   \n",
      "11       0.003432         0.000538         0.980000          0.979259    1000   \n",
      "12       0.007410         0.000622         0.866667          0.865926       1   \n",
      "13       0.007538         0.000814         0.866667          0.865926       1   \n",
      "14       0.008334         0.000660         0.746667          0.748889       1   \n",
      "15       0.009171         0.000755         0.746667          0.748889       1   \n",
      "16       0.007049         0.001583         0.640000          0.642222       1   \n",
      "17       0.008817         0.000795         0.640000          0.642222       1   \n",
      "18       0.009065         0.000640         0.573333          0.576296       1   \n",
      "19       0.006227         0.000577         0.573333          0.576296       1   \n",
      "20       0.006148         0.000552         0.866667          0.865926      10   \n",
      "21       0.005349         0.000577         0.866667          0.865926      10   \n",
      "22       0.008246         0.001528         0.746667          0.748889      10   \n",
      "23       0.006210         0.001169         0.746667          0.748889      10   \n",
      "24       0.005494         0.000628         0.640000          0.642222      10   \n",
      "25       0.005131         0.000580         0.640000          0.642222      10   \n",
      "26       0.006142         0.000674         0.573333          0.576296      10   \n",
      "27       0.005468         0.000598         0.573333          0.576296      10   \n",
      "28       0.004321         0.000532         0.886667          0.898519     100   \n",
      "29       0.005744         0.000657         0.866667          0.865926     100   \n",
      "30       0.005932         0.000589         0.746667          0.748889     100   \n",
      "31       0.005725         0.000706         0.746667          0.748889     100   \n",
      "32       0.005674         0.000557         0.640000          0.642222     100   \n",
      "33       0.005931         0.000585         0.640000          0.642222     100   \n",
      "34       0.005962         0.000626         0.573333          0.576296     100   \n",
      "35       0.006020         0.000636         0.573333          0.576296     100   \n",
      "36       0.002187         0.000484         0.960000          0.961481    1000   \n",
      "37       0.004191         0.000461         0.866667          0.865926    1000   \n",
      "38       0.002875         0.000439         0.866667          0.871111    1000   \n",
      "39       0.003872         0.000411         0.746667          0.748889    1000   \n",
      "40       0.005382         0.000580         0.653333          0.656296    1000   \n",
      "41       0.004479         0.000501         0.640000          0.642222    1000   \n",
      "42       0.004553         0.000422         0.573333          0.576296    1000   \n",
      "43       0.004020         0.000397         0.573333          0.576296    1000   \n",
      "\n",
      "   param_degree param_gamma param_kernel  \\\n",
      "0           NaN         NaN       linear   \n",
      "1           NaN         NaN       linear   \n",
      "2           NaN         NaN       linear   \n",
      "3           NaN         NaN       linear   \n",
      "4           NaN       0.001          rbf   \n",
      "5           NaN      0.0001          rbf   \n",
      "6           NaN       0.001          rbf   \n",
      "7           NaN      0.0001          rbf   \n",
      "8           NaN       0.001          rbf   \n",
      "9           NaN      0.0001          rbf   \n",
      "10          NaN       0.001          rbf   \n",
      "11          NaN      0.0001          rbf   \n",
      "12            2       0.001         poly   \n",
      "13            2      0.0001         poly   \n",
      "14            3       0.001         poly   \n",
      "15            3      0.0001         poly   \n",
      "16            4       0.001         poly   \n",
      "17            4      0.0001         poly   \n",
      "18            5       0.001         poly   \n",
      "19            5      0.0001         poly   \n",
      "20            2       0.001         poly   \n",
      "21            2      0.0001         poly   \n",
      "22            3       0.001         poly   \n",
      "23            3      0.0001         poly   \n",
      "24            4       0.001         poly   \n",
      "25            4      0.0001         poly   \n",
      "26            5       0.001         poly   \n",
      "27            5      0.0001         poly   \n",
      "28            2       0.001         poly   \n",
      "29            2      0.0001         poly   \n",
      "30            3       0.001         poly   \n",
      "31            3      0.0001         poly   \n",
      "32            4       0.001         poly   \n",
      "33            4      0.0001         poly   \n",
      "34            5       0.001         poly   \n",
      "35            5      0.0001         poly   \n",
      "36            2       0.001         poly   \n",
      "37            2      0.0001         poly   \n",
      "38            3       0.001         poly   \n",
      "39            3      0.0001         poly   \n",
      "40            4       0.001         poly   \n",
      "41            4      0.0001         poly   \n",
      "42            5       0.001         poly   \n",
      "43            5      0.0001         poly   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0                        {'C': 1, 'kernel': 'linear'}                6   \n",
      "1                       {'C': 10, 'kernel': 'linear'}                1   \n",
      "2                      {'C': 100, 'kernel': 'linear'}                6   \n",
      "3                     {'C': 1000, 'kernel': 'linear'}                1   \n",
      "4           {'C': 1, 'kernel': 'rbf', 'gamma': 0.001}               11   \n",
      "5          {'C': 1, 'kernel': 'rbf', 'gamma': 0.0001}               11   \n",
      "6          {'C': 10, 'kernel': 'rbf', 'gamma': 0.001}                9   \n",
      "7         {'C': 10, 'kernel': 'rbf', 'gamma': 0.0001}               11   \n",
      "8         {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}                1   \n",
      "9        {'C': 100, 'kernel': 'rbf', 'gamma': 0.0001}                9   \n",
      "10       {'C': 1000, 'kernel': 'rbf', 'gamma': 0.001}                1   \n",
      "11      {'C': 1000, 'kernel': 'rbf', 'gamma': 0.0001}                1   \n",
      "12  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               15   \n",
      "13  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               15   \n",
      "14  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               22   \n",
      "15  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               22   \n",
      "16  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               30   \n",
      "17  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               30   \n",
      "18  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               37   \n",
      "19  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               37   \n",
      "20  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               15   \n",
      "21  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               15   \n",
      "22  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               22   \n",
      "23  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               22   \n",
      "24  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               30   \n",
      "25  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               30   \n",
      "26  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               37   \n",
      "27  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               37   \n",
      "28  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               14   \n",
      "29  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               15   \n",
      "30  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               22   \n",
      "31  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               22   \n",
      "32  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               30   \n",
      "33  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               30   \n",
      "34  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               37   \n",
      "35  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               37   \n",
      "36  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...                8   \n",
      "37  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               15   \n",
      "38  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               15   \n",
      "39  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               22   \n",
      "40  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               29   \n",
      "41  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               30   \n",
      "42  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               37   \n",
      "43  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               37   \n",
      "\n",
      "         ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0        ...                  1.000000            0.992593           1.000000   \n",
      "1        ...                  1.000000            0.985185           1.000000   \n",
      "2        ...                  0.933333            0.985185           1.000000   \n",
      "3        ...                  1.000000            0.985185           1.000000   \n",
      "4        ...                  0.933333            0.918519           0.933333   \n",
      "5        ...                  0.933333            0.918519           0.933333   \n",
      "6        ...                  0.933333            0.948148           1.000000   \n",
      "7        ...                  0.933333            0.918519           0.933333   \n",
      "8        ...                  1.000000            0.977778           1.000000   \n",
      "9        ...                  0.933333            0.948148           1.000000   \n",
      "10       ...                  1.000000            0.985185           1.000000   \n",
      "11       ...                  1.000000            0.977778           1.000000   \n",
      "12       ...                  0.933333            0.859259           0.866667   \n",
      "13       ...                  0.933333            0.859259           0.866667   \n",
      "14       ...                  0.800000            0.740741           0.866667   \n",
      "15       ...                  0.800000            0.740741           0.866667   \n",
      "16       ...                  0.600000            0.644444           0.600000   \n",
      "17       ...                  0.600000            0.644444           0.600000   \n",
      "18       ...                  0.600000            0.570370           0.466667   \n",
      "19       ...                  0.600000            0.570370           0.466667   \n",
      "20       ...                  0.933333            0.859259           0.866667   \n",
      "21       ...                  0.933333            0.859259           0.866667   \n",
      "22       ...                  0.800000            0.740741           0.866667   \n",
      "23       ...                  0.800000            0.740741           0.866667   \n",
      "24       ...                  0.600000            0.644444           0.600000   \n",
      "25       ...                  0.600000            0.644444           0.600000   \n",
      "26       ...                  0.600000            0.570370           0.466667   \n",
      "27       ...                  0.600000            0.570370           0.466667   \n",
      "28       ...                  0.933333            0.896296           0.933333   \n",
      "29       ...                  0.933333            0.859259           0.866667   \n",
      "30       ...                  0.800000            0.740741           0.866667   \n",
      "31       ...                  0.800000            0.740741           0.866667   \n",
      "32       ...                  0.600000            0.644444           0.600000   \n",
      "33       ...                  0.600000            0.644444           0.600000   \n",
      "34       ...                  0.600000            0.570370           0.466667   \n",
      "35       ...                  0.600000            0.570370           0.466667   \n",
      "36       ...                  0.933333            0.962963           1.000000   \n",
      "37       ...                  0.933333            0.859259           0.866667   \n",
      "38       ...                  0.933333            0.866667           0.866667   \n",
      "39       ...                  0.800000            0.740741           0.866667   \n",
      "40       ...                  0.666667            0.651852           0.600000   \n",
      "41       ...                  0.600000            0.644444           0.600000   \n",
      "42       ...                  0.600000            0.570370           0.466667   \n",
      "43       ...                  0.600000            0.570370           0.466667   \n",
      "\n",
      "    split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0             0.992593           1.000000            0.985185      0.002661   \n",
      "1             0.977778           1.000000            0.977778      0.000448   \n",
      "2             0.977778           1.000000            0.977778      0.007278   \n",
      "3             0.985185           1.000000            0.985185      0.008628   \n",
      "4             0.918519           0.933333            0.903704      0.000423   \n",
      "5             0.918519           0.933333            0.903704      0.005455   \n",
      "6             0.940741           1.000000            0.933333      0.000712   \n",
      "7             0.918519           0.933333            0.903704      0.001637   \n",
      "8             0.985185           1.000000            0.970370      0.000608   \n",
      "9             0.940741           1.000000            0.933333      0.000559   \n",
      "10            0.977778           1.000000            0.985185      0.000434   \n",
      "11            0.985185           1.000000            0.970370      0.000251   \n",
      "12            0.866667           0.800000            0.874074      0.002032   \n",
      "13            0.866667           0.800000            0.874074      0.002570   \n",
      "14            0.733333           0.600000            0.762963      0.003809   \n",
      "15            0.733333           0.600000            0.762963      0.003384   \n",
      "16            0.644444           0.400000            0.666667      0.000841   \n",
      "17            0.644444           0.400000            0.666667      0.002242   \n",
      "18            0.585185           0.400000            0.592593      0.003045   \n",
      "19            0.585185           0.400000            0.592593      0.000814   \n",
      "20            0.866667           0.800000            0.874074      0.000629   \n",
      "21            0.866667           0.800000            0.874074      0.000960   \n",
      "22            0.733333           0.600000            0.762963      0.002777   \n",
      "23            0.733333           0.600000            0.762963      0.001361   \n",
      "24            0.644444           0.400000            0.666667      0.001235   \n",
      "25            0.644444           0.400000            0.666667      0.001059   \n",
      "26            0.585185           0.400000            0.592593      0.000878   \n",
      "27            0.585185           0.400000            0.592593      0.001109   \n",
      "28            0.888889           0.800000            0.903704      0.000834   \n",
      "29            0.866667           0.800000            0.874074      0.000914   \n",
      "30            0.733333           0.600000            0.762963      0.000910   \n",
      "31            0.733333           0.600000            0.762963      0.001003   \n",
      "32            0.644444           0.400000            0.666667      0.000939   \n",
      "33            0.644444           0.400000            0.666667      0.001158   \n",
      "34            0.585185           0.400000            0.592593      0.000941   \n",
      "35            0.585185           0.400000            0.592593      0.001128   \n",
      "36            0.955556           1.000000            0.948148      0.000481   \n",
      "37            0.866667           0.800000            0.874074      0.000492   \n",
      "38            0.874074           0.800000            0.881481      0.000255   \n",
      "39            0.733333           0.600000            0.762963      0.000259   \n",
      "40            0.659259           0.400000            0.681481      0.001425   \n",
      "41            0.644444           0.400000            0.666667      0.000832   \n",
      "42            0.585185           0.400000            0.592593      0.000488   \n",
      "43            0.585185           0.400000            0.592593      0.000300   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.000486        0.044222         0.004914  \n",
      "1         0.000075        0.042687         0.006667  \n",
      "2         0.000267        0.044222         0.004969  \n",
      "3         0.000446        0.042687         0.005543  \n",
      "4         0.000066        0.061101         0.007554  \n",
      "5         0.000129        0.061101         0.007554  \n",
      "6         0.000058        0.051640         0.008249  \n",
      "7         0.000108        0.061101         0.007554  \n",
      "8         0.000102        0.030551         0.007258  \n",
      "9         0.000062        0.051640         0.008249  \n",
      "10        0.000086        0.042687         0.005785  \n",
      "11        0.000032        0.030551         0.007258  \n",
      "12        0.000088        0.059628         0.007734  \n",
      "13        0.000445        0.059628         0.007734  \n",
      "14        0.000113        0.093333         0.012593  \n",
      "15        0.000256        0.093333         0.012593  \n",
      "16        0.002741        0.130639         0.013679  \n",
      "17        0.000370        0.130639         0.013679  \n",
      "18        0.000108        0.112349         0.012744  \n",
      "19        0.000085        0.112349         0.012744  \n",
      "20        0.000120        0.059628         0.007734  \n",
      "21        0.000156        0.059628         0.007734  \n",
      "22        0.001814        0.093333         0.012593  \n",
      "23        0.002002        0.093333         0.012593  \n",
      "24        0.000170        0.130639         0.013679  \n",
      "25        0.000165        0.130639         0.013679  \n",
      "26        0.000147        0.112349         0.012744  \n",
      "27        0.000185        0.112349         0.012744  \n",
      "28        0.000101        0.060000         0.009966  \n",
      "29        0.000135        0.059628         0.007734  \n",
      "30        0.000130        0.093333         0.012593  \n",
      "31        0.000252        0.093333         0.012593  \n",
      "32        0.000115        0.130639         0.013679  \n",
      "33        0.000137        0.130639         0.013679  \n",
      "34        0.000113        0.112349         0.012744  \n",
      "35        0.000148        0.112349         0.012744  \n",
      "36        0.000213        0.053333         0.009827  \n",
      "37        0.000106        0.059628         0.007734  \n",
      "38        0.000103        0.051640         0.005926  \n",
      "39        0.000113        0.093333         0.012593  \n",
      "40        0.000203        0.135974         0.012915  \n",
      "41        0.000157        0.130639         0.013679  \n",
      "42        0.000102        0.112349         0.012744  \n",
      "43        0.000090        0.112349         0.012744  \n",
      "\n",
      "[44 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# グリッドサーチのために，パラメータの選択肢を決定する\n",
    "# polyは多項式の非線形SVMで，degreeで次数=n次関数を決定する（当然，1はlinearと変わりないので行わない）\n",
    "# この他にも各パラメータについてグリッドサーチを行える\n",
    "param_svm = [\n",
    "{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel':['poly'], 'degree': [2, 3, 4, 5], }\n",
    " ] \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# グリッドサーチ&交差検定用の学習器を設定する\n",
    "# 引数に，用いる分類器，パラメータ選択肢\n",
    "# オプションとして，cvはk分割交差検定の回数（つまり，k）\n",
    "# オプションとして，n_jobsは並列スレッド数\n",
    "from multiprocessing import cpu_count\n",
    "job = cpu_count() -1\n",
    "svm_cv = GridSearchCV(SVC(probability=True, decision_function_shape=\"ovr\"), param_svm, cv=10, n_jobs=job)\n",
    "\n",
    "# 交差検定を用いたグリッドサーチを行う\n",
    "# 引数に，特徴量と正解データ\n",
    "svm_cv.fit(iris.data, iris.target)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(svm_cv.cv_results_)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.98\n",
      "best param: {'C': 10, 'kernel': 'linear'}\n",
      "best score's index: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %svm_cv.best_estimator_)\n",
    "print(\"best socre: %s\" %svm_cv.best_score_)\n",
    "print(\"best param: %s\" %svm_cv.best_params_)\n",
    "print(\"best score's index: %s\" %svm_cv.best_index_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 得られた最良パラメータでもう一度学習してF値を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  1 24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.96      0.96      0.96        25\n",
      "  virginica       0.96      0.96      0.96        25\n",
      "\n",
      "avg / total       0.97      0.97      0.97        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_best = SVC(C=10, kernel=\"linear\", probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "svm_best.fit(x_train, y_train)\n",
    "\n",
    "predict_best = svm_best.predict(x_test)\n",
    "matrix_best = confusion_matrix(y_test, predict_best)\n",
    "report_best = classification_report(y_test, predict_best, target_names=iris.target_names)\n",
    "\n",
    "print(predict_best)\n",
    "print(matrix_best)\n",
    "print(report_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ↑F値が0.93から0.97に上昇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN法でirisデータを分類してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.023446         0.002437         0.960000          1.000000   \n",
      "1       0.000774         0.001546         0.960000          1.000000   \n",
      "2       0.000810         0.001390         0.953333          0.978519   \n",
      "3       0.000646         0.001168         0.960000          1.000000   \n",
      "4       0.000493         0.000912         0.966667          0.960741   \n",
      "5       0.000486         0.000913         0.966667          1.000000   \n",
      "6       0.000474         0.000928         0.966667          0.963704   \n",
      "7       0.000491         0.000936         0.966667          1.000000   \n",
      "8       0.000490         0.000855         0.966667          0.968889   \n",
      "9       0.000516         0.001040         0.966667          1.000000   \n",
      "\n",
      "  param_n_neighbors param_weights                                     params  \\\n",
      "0                 1       uniform   {'n_neighbors': 1, 'weights': 'uniform'}   \n",
      "1                 1      distance  {'n_neighbors': 1, 'weights': 'distance'}   \n",
      "2                 2       uniform   {'n_neighbors': 2, 'weights': 'uniform'}   \n",
      "3                 2      distance  {'n_neighbors': 2, 'weights': 'distance'}   \n",
      "4                 3       uniform   {'n_neighbors': 3, 'weights': 'uniform'}   \n",
      "5                 3      distance  {'n_neighbors': 3, 'weights': 'distance'}   \n",
      "6                 4       uniform   {'n_neighbors': 4, 'weights': 'uniform'}   \n",
      "7                 4      distance  {'n_neighbors': 4, 'weights': 'distance'}   \n",
      "8                 5       uniform   {'n_neighbors': 5, 'weights': 'uniform'}   \n",
      "9                 5      distance  {'n_neighbors': 5, 'weights': 'distance'}   \n",
      "\n",
      "   rank_test_score  split0_test_score  split0_train_score       ...         \\\n",
      "0                7                1.0            1.000000       ...          \n",
      "1                7                1.0            1.000000       ...          \n",
      "2               10                1.0            0.970370       ...          \n",
      "3                7                1.0            1.000000       ...          \n",
      "4                1                1.0            0.955556       ...          \n",
      "5                1                1.0            1.000000       ...          \n",
      "6                1                1.0            0.955556       ...          \n",
      "7                1                1.0            1.000000       ...          \n",
      "8                1                1.0            0.962963       ...          \n",
      "9                1                1.0            1.000000       ...          \n",
      "\n",
      "   split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0           1.000000            1.000000                1.0   \n",
      "1           1.000000            1.000000                1.0   \n",
      "2           0.933333            0.977778                1.0   \n",
      "3           1.000000            1.000000                1.0   \n",
      "4           1.000000            0.955556                1.0   \n",
      "5           1.000000            1.000000                1.0   \n",
      "6           1.000000            0.962963                1.0   \n",
      "7           1.000000            1.000000                1.0   \n",
      "8           1.000000            0.962963                1.0   \n",
      "9           1.000000            1.000000                1.0   \n",
      "\n",
      "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0            1.000000                1.0            1.000000      0.034549   \n",
      "1            1.000000                1.0            1.000000      0.000122   \n",
      "2            0.977778                1.0            0.977778      0.000030   \n",
      "3            1.000000                1.0            1.000000      0.000230   \n",
      "4            0.955556                1.0            0.955556      0.000041   \n",
      "5            1.000000                1.0            1.000000      0.000039   \n",
      "6            0.955556                1.0            0.970370      0.000058   \n",
      "7            1.000000                1.0            1.000000      0.000103   \n",
      "8            0.962963                1.0            0.970370      0.000115   \n",
      "9            1.000000                1.0            1.000000      0.000022   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.001684        0.053333         0.000000  \n",
      "1        0.000117        0.053333         0.000000  \n",
      "2        0.000168        0.052068         0.005185  \n",
      "3        0.000386        0.053333         0.000000  \n",
      "4        0.000066        0.044721         0.007444  \n",
      "5        0.000082        0.044721         0.000000  \n",
      "6        0.000239        0.044721         0.006988  \n",
      "7        0.000128        0.044721         0.000000  \n",
      "8        0.000069        0.044721         0.007258  \n",
      "9        0.000174        0.044721         0.000000  \n",
      "\n",
      "[10 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_param = [\n",
    "    {'n_neighbors': [1, 2, 3, 4, 5],'weights': ['uniform', 'distance'], }\n",
    "]\n",
    "\n",
    "knn_cv = GridSearchCV(KNeighborsClassifier(), knn_param, cv=10, n_jobs=job)\n",
    "knn_cv.fit(iris.data, iris.target)\n",
    "\n",
    "df_knn = pd.DataFrame(knn_cv.cv_results_)\n",
    "print(df_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "best socre: 0.966666666667\n",
      "best param: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "best score's index: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %knn_cv.best_estimator_)\n",
    "print(\"best socre: %s\" %knn_cv.best_score_)\n",
    "print(\"best param: %s\" %knn_cv.best_params_)\n",
    "print(\"best score's index: %s\" %knn_cv.best_index_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 23  2]\n",
      " [ 0  1 24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.96      0.92      0.94        25\n",
      "  virginica       0.92      0.96      0.94        25\n",
      "\n",
      "avg / total       0.96      0.96      0.96        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\")\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "predict_knn = knn.predict(x_test)\n",
    "matrix_knn = confusion_matrix(y_test, predict_knn)\n",
    "report_knn = classification_report(y_test, predict_knn, target_names=iris.target_names)\n",
    "\n",
    "print(predict_knn)\n",
    "print(matrix_knn)\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMでdigitsデータを分類してみる\n",
    "（おそらく）数字の手書き画像データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': array([0, 1, 2, ..., 8, 9, 8]), 'DESCR': \"Optical Recognition of Handwritten Digits Data Set\\n===================================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\nReferences\\n----------\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\", 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'data': array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
      "       ..., \n",
      "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
      "       [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'images': array([[[  0.,   0.,   5., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,  15.,   5.,   0.],\n",
      "        [  0.,   3.,  15., ...,  11.,   8.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  11., ...,  12.,   7.,   0.],\n",
      "        [  0.,   2.,  14., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   6., ...,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,   5.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,   9.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,   6.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,  10.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,  14.,   0.,   0.],\n",
      "        [  0.,   0.,   8., ...,  16.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   9.,  16., ...,   0.,   0.,   0.],\n",
      "        [  0.,   3.,  13., ...,  11.,   5.,   0.],\n",
      "        [  0.,   0.,   0., ...,  16.,   9.,   0.]],\n",
      "\n",
      "       ..., \n",
      "       [[  0.,   0.,   1., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,   2.,   1.,   0.],\n",
      "        [  0.,   0.,  16., ...,  16.,   5.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,  16., ...,  15.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  16.,   0.,   0.],\n",
      "        [  0.,   0.,   2., ...,   6.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  14., ...,  15.,   1.,   0.],\n",
      "        [  0.,   4.,  16., ...,  16.,   7.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   0., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   4., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   5., ...,  12.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,  10., ...,   1.,   0.,   0.],\n",
      "        [  0.,   2.,  16., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  15.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  16., ...,  16.,   6.,   0.],\n",
      "        [  0.,   8.,  16., ...,  16.,   8.,   0.],\n",
      "        [  0.,   1.,   8., ...,  12.,   1.,   0.]]])}\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "print(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### とりあえず表示してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADTCAYAAAChgfmQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVM64zpoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10758d978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(10) :\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(digits.images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最良パラメータをチューニングして，その評価を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
      "0        0.443201         0.012105         0.961046          1.000000       1   \n",
      "1        0.446827         0.010360         0.961046          1.000000      10   \n",
      "2        0.447012         0.009788         0.961046          1.000000     100   \n",
      "3        0.409671         0.011310         0.961046          1.000000    1000   \n",
      "4        1.058371         0.020059         0.978854          0.998887       1   \n",
      "5        0.913919         0.025540         0.954925          0.981883       1   \n",
      "6        1.059373         0.022501         0.981080          1.000000      10   \n",
      "7        0.511332         0.015265         0.969393          0.997836      10   \n",
      "8        1.033091         0.024513         0.981080          1.000000     100   \n",
      "9        0.467656         0.013597         0.971619          1.000000     100   \n",
      "10       1.139972         0.025953         0.981080          1.000000    1000   \n",
      "11       0.536867         0.012285         0.971619          1.000000    1000   \n",
      "12       0.466599         0.011473         0.974958          1.000000       1   \n",
      "13       1.557380         0.029964         0.936004          0.963953       1   \n",
      "14       0.506382         0.011941         0.978854          1.000000       1   \n",
      "15       2.067776         0.034712         0.913745          0.947074       1   \n",
      "16       0.529862         0.010892         0.976071          1.000000       1   \n",
      "17       2.802163         0.041835         0.864775          0.893649       1   \n",
      "18       0.525556         0.010540         0.973289          1.000000       1   \n",
      "19       2.959917         0.036225         0.451308          0.469216       1   \n",
      "20       0.472632         0.010523         0.972176          1.000000      10   \n",
      "21       0.733670         0.017069         0.966611          0.992951      10   \n",
      "22       0.526234         0.012951         0.978854          1.000000      10   \n",
      "23       0.732928         0.015468         0.964385          0.990416      10   \n",
      "24       0.482948         0.009621         0.976071          1.000000      10   \n",
      "25       1.024789         0.019723         0.953812          0.982872      10   \n",
      "26       0.499072         0.009128         0.973289          1.000000      10   \n",
      "27       1.756561         0.026975         0.920423          0.957028      10   \n",
      "28       0.553628         0.013048         0.972176          1.000000     100   \n",
      "29       0.477024         0.014416         0.974958          1.000000     100   \n",
      "30       0.476905         0.012296         0.978854          1.000000     100   \n",
      "31       0.483911         0.010883         0.978297          0.999938     100   \n",
      "32       0.494045         0.010232         0.976071          1.000000     100   \n",
      "33       0.543686         0.012580         0.973289          0.998825     100   \n",
      "34       0.516541         0.010934         0.973289          1.000000     100   \n",
      "35       0.689287         0.014218         0.966055          0.994374     100   \n",
      "36       0.441427         0.011606         0.972176          1.000000    1000   \n",
      "37       0.436226         0.010798         0.972176          1.000000    1000   \n",
      "38       0.475635         0.010386         0.978854          1.000000    1000   \n",
      "39       0.472586         0.009861         0.978854          1.000000    1000   \n",
      "40       0.500642         0.010343         0.976071          1.000000    1000   \n",
      "41       0.491085         0.011370         0.976071          1.000000    1000   \n",
      "42       0.489110         0.010038         0.973289          1.000000    1000   \n",
      "43       0.525997         0.009719         0.974402          1.000000    1000   \n",
      "\n",
      "   param_degree param_gamma param_kernel  \\\n",
      "0           NaN         NaN       linear   \n",
      "1           NaN         NaN       linear   \n",
      "2           NaN         NaN       linear   \n",
      "3           NaN         NaN       linear   \n",
      "4           NaN       0.001          rbf   \n",
      "5           NaN      0.0001          rbf   \n",
      "6           NaN       0.001          rbf   \n",
      "7           NaN      0.0001          rbf   \n",
      "8           NaN       0.001          rbf   \n",
      "9           NaN      0.0001          rbf   \n",
      "10          NaN       0.001          rbf   \n",
      "11          NaN      0.0001          rbf   \n",
      "12            2       0.001         poly   \n",
      "13            2      0.0001         poly   \n",
      "14            3       0.001         poly   \n",
      "15            3      0.0001         poly   \n",
      "16            4       0.001         poly   \n",
      "17            4      0.0001         poly   \n",
      "18            5       0.001         poly   \n",
      "19            5      0.0001         poly   \n",
      "20            2       0.001         poly   \n",
      "21            2      0.0001         poly   \n",
      "22            3       0.001         poly   \n",
      "23            3      0.0001         poly   \n",
      "24            4       0.001         poly   \n",
      "25            4      0.0001         poly   \n",
      "26            5       0.001         poly   \n",
      "27            5      0.0001         poly   \n",
      "28            2       0.001         poly   \n",
      "29            2      0.0001         poly   \n",
      "30            3       0.001         poly   \n",
      "31            3      0.0001         poly   \n",
      "32            4       0.001         poly   \n",
      "33            4      0.0001         poly   \n",
      "34            5       0.001         poly   \n",
      "35            5      0.0001         poly   \n",
      "36            2       0.001         poly   \n",
      "37            2      0.0001         poly   \n",
      "38            3       0.001         poly   \n",
      "39            3      0.0001         poly   \n",
      "40            4       0.001         poly   \n",
      "41            4      0.0001         poly   \n",
      "42            5       0.001         poly   \n",
      "43            5      0.0001         poly   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0                        {'C': 1, 'kernel': 'linear'}               34   \n",
      "1                       {'C': 10, 'kernel': 'linear'}               34   \n",
      "2                      {'C': 100, 'kernel': 'linear'}               34   \n",
      "3                     {'C': 1000, 'kernel': 'linear'}               34   \n",
      "4           {'C': 1, 'kernel': 'rbf', 'gamma': 0.001}                4   \n",
      "5          {'C': 1, 'kernel': 'rbf', 'gamma': 0.0001}               38   \n",
      "6          {'C': 10, 'kernel': 'rbf', 'gamma': 0.001}                1   \n",
      "7         {'C': 10, 'kernel': 'rbf', 'gamma': 0.0001}               30   \n",
      "8         {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}                1   \n",
      "9        {'C': 100, 'kernel': 'rbf', 'gamma': 0.0001}               28   \n",
      "10       {'C': 1000, 'kernel': 'rbf', 'gamma': 0.001}                1   \n",
      "11      {'C': 1000, 'kernel': 'rbf', 'gamma': 0.0001}               28   \n",
      "12  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               16   \n",
      "13  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               40   \n",
      "14  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...                4   \n",
      "15  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               42   \n",
      "16  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               11   \n",
      "17  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               43   \n",
      "18  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               19   \n",
      "19  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               44   \n",
      "20  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               24   \n",
      "21  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               31   \n",
      "22  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...                4   \n",
      "23  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               33   \n",
      "24  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               11   \n",
      "25  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               39   \n",
      "26  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               19   \n",
      "27  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               41   \n",
      "28  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               24   \n",
      "29  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               16   \n",
      "30  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...                4   \n",
      "31  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               10   \n",
      "32  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               11   \n",
      "33  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               19   \n",
      "34  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               19   \n",
      "35  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               32   \n",
      "36  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               24   \n",
      "37  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               24   \n",
      "38  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...                4   \n",
      "39  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...                4   \n",
      "40  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               11   \n",
      "41  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               11   \n",
      "42  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               19   \n",
      "43  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               18   \n",
      "\n",
      "         ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0        ...                  0.977528            1.000000           0.932203   \n",
      "1        ...                  0.977528            1.000000           0.932203   \n",
      "2        ...                  0.977528            1.000000           0.932203   \n",
      "3        ...                  0.977528            1.000000           0.932203   \n",
      "4        ...                  0.994382            0.998765           0.966102   \n",
      "5        ...                  0.988764            0.982088           0.898305   \n",
      "6        ...                  0.994382            1.000000           0.971751   \n",
      "7        ...                  0.994382            0.996912           0.937853   \n",
      "8        ...                  0.994382            1.000000           0.971751   \n",
      "9        ...                  0.994382            1.000000           0.949153   \n",
      "10       ...                  0.994382            1.000000           0.971751   \n",
      "11       ...                  0.994382            1.000000           0.949153   \n",
      "12       ...                  0.994382            1.000000           0.949153   \n",
      "13       ...                  0.971910            0.959234           0.875706   \n",
      "14       ...                  0.994382            1.000000           0.960452   \n",
      "15       ...                  0.932584            0.945028           0.853107   \n",
      "16       ...                  0.994382            1.000000           0.954802   \n",
      "17       ...                  0.887640            0.890056           0.785311   \n",
      "18       ...                  0.983146            1.000000           0.954802   \n",
      "19       ...                  0.393258            0.448425           0.389831   \n",
      "20       ...                  0.994382            1.000000           0.949153   \n",
      "21       ...                  0.994382            0.992588           0.937853   \n",
      "22       ...                  0.994382            1.000000           0.960452   \n",
      "23       ...                  0.994382            0.989500           0.926554   \n",
      "24       ...                  0.994382            1.000000           0.954802   \n",
      "25       ...                  0.983146            0.982088           0.909605   \n",
      "26       ...                  0.983146            1.000000           0.954802   \n",
      "27       ...                  0.932584            0.957999           0.875706   \n",
      "28       ...                  0.994382            1.000000           0.949153   \n",
      "29       ...                  0.994382            1.000000           0.949153   \n",
      "30       ...                  0.994382            1.000000           0.960452   \n",
      "31       ...                  0.994382            1.000000           0.960452   \n",
      "32       ...                  0.994382            1.000000           0.954802   \n",
      "33       ...                  0.994382            0.998765           0.937853   \n",
      "34       ...                  0.983146            1.000000           0.954802   \n",
      "35       ...                  1.000000            0.994441           0.937853   \n",
      "36       ...                  0.994382            1.000000           0.949153   \n",
      "37       ...                  0.994382            1.000000           0.949153   \n",
      "38       ...                  0.994382            1.000000           0.960452   \n",
      "39       ...                  0.994382            1.000000           0.960452   \n",
      "40       ...                  0.994382            1.000000           0.954802   \n",
      "41       ...                  0.994382            1.000000           0.954802   \n",
      "42       ...                  0.983146            1.000000           0.954802   \n",
      "43       ...                  0.988764            1.000000           0.954802   \n",
      "\n",
      "    split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0             1.000000           0.965909            1.000000      0.025909   \n",
      "1             1.000000           0.965909            1.000000      0.033031   \n",
      "2             1.000000           0.965909            1.000000      0.035942   \n",
      "3             1.000000           0.965909            1.000000      0.027016   \n",
      "4             0.998765           0.965909            0.999383      0.038385   \n",
      "5             0.980864           0.931818            0.983344      0.038139   \n",
      "6             1.000000           0.965909            1.000000      0.021669   \n",
      "7             0.997531           0.965909            0.998149      0.030927   \n",
      "8             1.000000           0.965909            1.000000      0.027856   \n",
      "9             1.000000           0.965909            1.000000      0.020317   \n",
      "10            1.000000           0.965909            1.000000      0.140871   \n",
      "11            1.000000           0.965909            1.000000      0.066836   \n",
      "12            1.000000           0.965909            1.000000      0.045359   \n",
      "13            0.966049           0.914773            0.965453      0.145972   \n",
      "14            1.000000           0.965909            1.000000      0.041766   \n",
      "15            0.952469           0.914773            0.943862      0.112343   \n",
      "16            1.000000           0.965909            1.000000      0.039268   \n",
      "17            0.900617           0.886364            0.895743      0.084848   \n",
      "18            1.000000           0.965909            1.000000      0.036091   \n",
      "19            0.490123           0.545455            0.479334      0.073781   \n",
      "20            1.000000           0.965909            1.000000      0.051060   \n",
      "21            0.993827           0.954545            0.993214      0.200025   \n",
      "22            1.000000           0.965909            1.000000      0.020663   \n",
      "23            0.992593           0.954545            0.991363      0.065271   \n",
      "24            1.000000           0.965909            1.000000      0.020464   \n",
      "25            0.985185           0.943182            0.982110      0.052269   \n",
      "26            1.000000           0.965909            1.000000      0.014676   \n",
      "27            0.963580           0.909091            0.951265      0.144183   \n",
      "28            1.000000           0.965909            1.000000      0.072841   \n",
      "29            1.000000           0.965909            1.000000      0.037209   \n",
      "30            1.000000           0.965909            1.000000      0.018032   \n",
      "31            1.000000           0.965909            1.000000      0.033581   \n",
      "32            1.000000           0.965909            1.000000      0.018078   \n",
      "33            0.998148           0.960227            1.000000      0.028369   \n",
      "34            1.000000           0.965909            1.000000      0.033146   \n",
      "35            0.996296           0.960227            0.993831      0.028051   \n",
      "36            1.000000           0.965909            1.000000      0.022288   \n",
      "37            1.000000           0.965909            1.000000      0.018617   \n",
      "38            1.000000           0.965909            1.000000      0.033292   \n",
      "39            1.000000           0.965909            1.000000      0.023800   \n",
      "40            1.000000           0.965909            1.000000      0.029098   \n",
      "41            1.000000           0.965909            1.000000      0.021357   \n",
      "42            1.000000           0.965909            1.000000      0.015308   \n",
      "43            1.000000           0.965909            1.000000      0.042568   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.002538        0.021980         0.000000  \n",
      "1         0.002111        0.021980         0.000000  \n",
      "2         0.001496        0.021980         0.000000  \n",
      "3         0.001520        0.021980         0.000000  \n",
      "4         0.003164        0.017952         0.000247  \n",
      "5         0.003994        0.027588         0.001387  \n",
      "6         0.004668        0.015540         0.000000  \n",
      "7         0.002242        0.025213         0.000568  \n",
      "8         0.009110        0.015540         0.000000  \n",
      "9         0.002268        0.020497         0.000000  \n",
      "10        0.008735        0.015540         0.000000  \n",
      "11        0.001718        0.020497         0.000000  \n",
      "12        0.002010        0.021610         0.000000  \n",
      "13        0.007912        0.031711         0.001988  \n",
      "14        0.001693        0.019347         0.000000  \n",
      "15        0.009644        0.031604         0.002627  \n",
      "16        0.001295        0.020023         0.000000  \n",
      "17        0.006567        0.036656         0.004636  \n",
      "18        0.001326        0.019145         0.000000  \n",
      "19        0.004100        0.059380         0.024371  \n",
      "20        0.001477        0.020555         0.000000  \n",
      "21        0.008601        0.022883         0.001304  \n",
      "22        0.002118        0.019347         0.000000  \n",
      "23        0.002493        0.024129         0.001183  \n",
      "24        0.001417        0.020023         0.000000  \n",
      "25        0.003792        0.023615         0.001040  \n",
      "26        0.001693        0.019145         0.000000  \n",
      "27        0.002638        0.025802         0.003813  \n",
      "28        0.004446        0.020555         0.000000  \n",
      "29        0.011960        0.021610         0.000000  \n",
      "30        0.002577        0.019347         0.000000  \n",
      "31        0.002096        0.019130         0.000186  \n",
      "32        0.002136        0.020023         0.000000  \n",
      "33        0.003391        0.022923         0.000513  \n",
      "34        0.001028        0.019145         0.000000  \n",
      "35        0.001812        0.022772         0.001085  \n",
      "36        0.002271        0.020555         0.000000  \n",
      "37        0.001829        0.020555         0.000000  \n",
      "38        0.001951        0.019347         0.000000  \n",
      "39        0.001623        0.019347         0.000000  \n",
      "40        0.001197        0.020023         0.000000  \n",
      "41        0.000945        0.020023         0.000000  \n",
      "42        0.001386        0.019145         0.000000  \n",
      "43        0.001181        0.019523         0.000000  \n",
      "\n",
      "[44 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "digits_cv = GridSearchCV(SVC(probability=True, decision_function_shape=\"ovr\"), param_svm, cv=10, n_jobs=job)\n",
    "digits_cv.fit(digits.data, digits.target)\n",
    "\n",
    "df_digits = pd.DataFrame(digits_cv.cv_results_)\n",
    "print(df_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.981079577073\n",
      "best param: {'C': 10, 'kernel': 'rbf', 'gamma': 0.001}\n",
      "best score's index: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %digits_cv.best_estimator_)\n",
    "print(\"best socre: %s\" %digits_cv.best_score_)\n",
    "print(\"best param: %s\" %digits_cv.best_params_)\n",
    "print(\"best score's index: %s\" %digits_cv.best_index_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最良パラメータに基づいて分類器を作成してF値で評価する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict results\n",
      "[1 3 9 7 9 1 3 5 7 9 1 3 5 7 9 9 5 5 5 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 7 5 9\n",
      " 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 1 1 3 5 7 9 1 3 5 7\n",
      " 9 1 3 5 7 9 9 5 5 9 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 3 3 1\n",
      " 6 4 1 0 3 9 1 5 4 2 2 5 4 8 9 8 8 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 9 5 5 9 9\n",
      " 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2\n",
      " 2 5 9 4 8 9 8 3 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 9 5 9 9 9 4 7 3 1 0 2 8 0 2\n",
      " 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 8 1\n",
      " 3 5 7 9 1 3 5 7 9 1 3 5 7 9 8 5 5 9 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2\n",
      " 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 8 1 3 5 7 9 1 3 5 7 9\n",
      " 1 3 5 7 9 9 5 5 9 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1\n",
      " 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 8 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 9 5 5 9\n",
      " 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4\n",
      " 2 2 5 9 4 8 9 8 8 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7 5 2 8 0 2 3\n",
      " 7 3 6 6 9 5 9 2 2 0 7 3 1 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7 5 4 0 9 0 2 4 6\n",
      " 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7 5 0 7 2 1 6 3 3 4 6 4 1 0 5 8 0 1 6\n",
      " 2 7 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7 5 8 4 0 9 0 2 4 6 8 0 2 4 6 8 0 2 4 6\n",
      " 8 0 5 6 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4 6 4 1 0 5 8 0 1 6 2 7 6 1 9 7 8 3 4\n",
      " 5 6 6 7 4 7 8 2 7 5 8 4 0 9 0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7\n",
      " 5 0 2 7 2 1 6 3 3 4 6 4 1 0 6 8 0 1 6 2 7 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7\n",
      " 5 8 4 0 0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4\n",
      " 6 4 1 0 5 8 0 1 6 2 7 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7 5 8 4 0 9 0 2 4 6 1\n",
      " 0 2 4 6 0 2 4 6 8 4 9 6 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4 6 4 1 0 5 8 1 6 2 7\n",
      " 6 1 9 7 8 3 4 5 6 6 7 4 7 2 7 5 4 0 9 0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6\n",
      " 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4 6 4 1 0 5 8 0 1 6 2 7 6 1 9 7 8 3 4 5 6 6 7\n",
      " 4 7 8 2 7 5 8 4 0 9]\n",
      "confusion matrix\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 89  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 91  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 93  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 87  1  0  0  3]\n",
      " [ 0  0  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 91  0  0]\n",
      " [ 0  2  0  0  0  0  0  0 84  0]\n",
      " [ 0  0  0  0  0  1  0  1  1 88]]\n",
      "F-measure\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.98      1.00      0.99        89\n",
      "          2       1.00      1.00      1.00        91\n",
      "          3       1.00      1.00      1.00        93\n",
      "          4       0.99      1.00      0.99        88\n",
      "          5       0.99      0.96      0.97        91\n",
      "          6       0.99      1.00      0.99        90\n",
      "          7       0.99      1.00      0.99        91\n",
      "          8       0.99      0.98      0.98        86\n",
      "          9       0.97      0.97      0.97        91\n",
      "\n",
      "avg / total       0.99      0.99      0.99       898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_digits = SVC(C=10, kernel=\"rbf\", gamma=0.001, probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "\n",
    "xd_train = digits.data[range(0, len(digits.data), 2)]\n",
    "yd_train = digits.target[range(0, len(digits.data), 2)]\n",
    "\n",
    "xd_test = digits.data[range(1, len(digits.data), 2)]\n",
    "yd_test = digits.target[range(1, len(digits.data), 2)]\n",
    "\n",
    "svm_digits.fit(xd_train, yd_train)\n",
    "\n",
    "predict_digits = svm_digits.predict(xd_test)\n",
    "matrix_digits = confusion_matrix(yd_test, predict_digits)\n",
    "report_digits = classification_report(yd_test, predict_digits)\n",
    "\n",
    "print(\"predict results\")\n",
    "print(predict_digits)\n",
    "print(\"confusion matrix\")\n",
    "print(matrix_digits)\n",
    "print(\"F-measure\")\n",
    "print(report_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次元削減\n",
    "\n",
    "特徴量が多いということは，計算コストの増大やトラッシュデータを含んでいるということに繋がる<br>\n",
    "トラッシュデータは，推定率の低下に繋がる→削ろう！\n",
    "\n",
    "### RandomForest\n",
    "決定木学習の一種で，ランダムフォレストは決定木を複数組み合わせて、各決定木の予測結果を多数決することによって結果を得る方法．<br>\n",
    "ランダムフォレストのメリットとして，相対的な特徴量の重要度を取得することができる．\n",
    "\n",
    "### PCA：主成分分析\n",
    "特徴量をまとめて，新しい特徴量を作り出す方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   importance\n",
      "sepal length (cm)    0.098198\n",
      "sepal width (cm)     0.023140\n",
      "petal length (cm)    0.436171\n",
      "petal width (cm)     0.442490\n"
     ]
    }
   ],
   "source": [
    "# ランダムフォレストで次元削減を行なう\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "\n",
    "# irisデータをランダムフォレストに学習させる\n",
    "forest = rf(n_estimators=10000, n_jobs=job)\n",
    "forest.fit(iris.data, iris.target)\n",
    "\n",
    "# 重要度を取得\n",
    "importance = pd.DataFrame(forest.feature_importances_, index=iris.feature_names, columns=[\"importance\"])\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
      "0        0.002947         0.000783         0.980000          0.982963       1   \n",
      "1        0.002088         0.000445         0.973333          0.982963      10   \n",
      "2        0.004307         0.000555         0.973333          0.980741     100   \n",
      "3        0.010002         0.000623         0.966667          0.983704    1000   \n",
      "4        0.008575         0.000634         0.900000          0.902963       1   \n",
      "5        0.008366         0.000627         0.900000          0.902963       1   \n",
      "6        0.006418         0.000905         0.940000          0.942222      10   \n",
      "7        0.008506         0.000629         0.900000          0.902963      10   \n",
      "8        0.003138         0.000544         0.973333          0.972593     100   \n",
      "9        0.005177         0.000611         0.940000          0.942222     100   \n",
      "10       0.001644         0.000332         0.973333          0.974074    1000   \n",
      "11       0.003266         0.000569         0.973333          0.972593    1000   \n",
      "12       0.007067         0.000627         0.853333          0.854074       1   \n",
      "13       0.007177         0.001063         0.853333          0.854074       1   \n",
      "14       0.006251         0.000805         0.733333          0.737037       1   \n",
      "15       0.006965         0.001755         0.733333          0.737037       1   \n",
      "16       0.011167         0.000726         0.613333          0.618519       1   \n",
      "17       0.010140         0.000708         0.613333          0.618519       1   \n",
      "18       0.006604         0.000582         0.566667          0.568889       1   \n",
      "19       0.005509         0.000497         0.566667          0.568889       1   \n",
      "20       0.004725         0.000463         0.853333          0.854074      10   \n",
      "21       0.005823         0.000565         0.853333          0.854074      10   \n",
      "22       0.007796         0.000681         0.733333          0.737037      10   \n",
      "23       0.004867         0.000476         0.733333          0.737037      10   \n",
      "24       0.005343         0.000487         0.613333          0.618519      10   \n",
      "25       0.004656         0.000448         0.613333          0.618519      10   \n",
      "26       0.004287         0.000418         0.566667          0.568889      10   \n",
      "27       0.006177         0.000566         0.566667          0.568889      10   \n",
      "28       0.004453         0.000516         0.886667          0.889630     100   \n",
      "29       0.004742         0.000482         0.853333          0.854074     100   \n",
      "30       0.004186         0.000426         0.733333          0.737037     100   \n",
      "31       0.004870         0.000481         0.733333          0.737037     100   \n",
      "32       0.005160         0.000487         0.613333          0.618519     100   \n",
      "33       0.004480         0.000445         0.613333          0.618519     100   \n",
      "34       0.004440         0.000430         0.566667          0.568889     100   \n",
      "35       0.004048         0.000405         0.566667          0.568889     100   \n",
      "36       0.001707         0.000337         0.953333          0.954815    1000   \n",
      "37       0.003506         0.000361         0.853333          0.854074    1000   \n",
      "38       0.002552         0.000348         0.860000          0.874074    1000   \n",
      "39       0.003860         0.000419         0.733333          0.737037    1000   \n",
      "40       0.003994         0.000397         0.613333          0.618519    1000   \n",
      "41       0.003662         0.000352         0.613333          0.618519    1000   \n",
      "42       0.003780         0.000361         0.566667          0.568889    1000   \n",
      "43       0.003811         0.000382         0.566667          0.568889    1000   \n",
      "\n",
      "   param_degree param_gamma param_kernel  \\\n",
      "0           NaN         NaN       linear   \n",
      "1           NaN         NaN       linear   \n",
      "2           NaN         NaN       linear   \n",
      "3           NaN         NaN       linear   \n",
      "4           NaN       0.001          rbf   \n",
      "5           NaN      0.0001          rbf   \n",
      "6           NaN       0.001          rbf   \n",
      "7           NaN      0.0001          rbf   \n",
      "8           NaN       0.001          rbf   \n",
      "9           NaN      0.0001          rbf   \n",
      "10          NaN       0.001          rbf   \n",
      "11          NaN      0.0001          rbf   \n",
      "12            2       0.001         poly   \n",
      "13            2      0.0001         poly   \n",
      "14            3       0.001         poly   \n",
      "15            3      0.0001         poly   \n",
      "16            4       0.001         poly   \n",
      "17            4      0.0001         poly   \n",
      "18            5       0.001         poly   \n",
      "19            5      0.0001         poly   \n",
      "20            2       0.001         poly   \n",
      "21            2      0.0001         poly   \n",
      "22            3       0.001         poly   \n",
      "23            3      0.0001         poly   \n",
      "24            4       0.001         poly   \n",
      "25            4      0.0001         poly   \n",
      "26            5       0.001         poly   \n",
      "27            5      0.0001         poly   \n",
      "28            2       0.001         poly   \n",
      "29            2      0.0001         poly   \n",
      "30            3       0.001         poly   \n",
      "31            3      0.0001         poly   \n",
      "32            4       0.001         poly   \n",
      "33            4      0.0001         poly   \n",
      "34            5       0.001         poly   \n",
      "35            5      0.0001         poly   \n",
      "36            2       0.001         poly   \n",
      "37            2      0.0001         poly   \n",
      "38            3       0.001         poly   \n",
      "39            3      0.0001         poly   \n",
      "40            4       0.001         poly   \n",
      "41            4      0.0001         poly   \n",
      "42            5       0.001         poly   \n",
      "43            5      0.0001         poly   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0                        {'C': 1, 'kernel': 'linear'}                1   \n",
      "1                       {'C': 10, 'kernel': 'linear'}                2   \n",
      "2                      {'C': 100, 'kernel': 'linear'}                2   \n",
      "3                     {'C': 1000, 'kernel': 'linear'}                7   \n",
      "4           {'C': 1, 'kernel': 'rbf', 'gamma': 0.001}               11   \n",
      "5          {'C': 1, 'kernel': 'rbf', 'gamma': 0.0001}               11   \n",
      "6          {'C': 10, 'kernel': 'rbf', 'gamma': 0.001}                9   \n",
      "7         {'C': 10, 'kernel': 'rbf', 'gamma': 0.0001}               11   \n",
      "8         {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}                2   \n",
      "9        {'C': 100, 'kernel': 'rbf', 'gamma': 0.0001}                9   \n",
      "10       {'C': 1000, 'kernel': 'rbf', 'gamma': 0.001}                2   \n",
      "11      {'C': 1000, 'kernel': 'rbf', 'gamma': 0.0001}                2   \n",
      "12  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               16   \n",
      "13  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               16   \n",
      "14  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               22   \n",
      "15  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               22   \n",
      "16  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               29   \n",
      "17  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               29   \n",
      "18  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               37   \n",
      "19  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               37   \n",
      "20  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               16   \n",
      "21  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               16   \n",
      "22  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               22   \n",
      "23  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               22   \n",
      "24  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               29   \n",
      "25  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               29   \n",
      "26  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               37   \n",
      "27  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               37   \n",
      "28  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               14   \n",
      "29  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               16   \n",
      "30  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               22   \n",
      "31  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               22   \n",
      "32  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               29   \n",
      "33  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               29   \n",
      "34  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               37   \n",
      "35  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               37   \n",
      "36  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...                8   \n",
      "37  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               16   \n",
      "38  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               15   \n",
      "39  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               22   \n",
      "40  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               29   \n",
      "41  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               29   \n",
      "42  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               37   \n",
      "43  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               37   \n",
      "\n",
      "         ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0        ...                  1.000000            0.985185           1.000000   \n",
      "1        ...                  1.000000            0.977778           1.000000   \n",
      "2        ...                  1.000000            0.985185           1.000000   \n",
      "3        ...                  1.000000            0.977778           1.000000   \n",
      "4        ...                  0.933333            0.896296           0.933333   \n",
      "5        ...                  0.933333            0.896296           0.933333   \n",
      "6        ...                  0.933333            0.940741           1.000000   \n",
      "7        ...                  0.933333            0.896296           0.933333   \n",
      "8        ...                  1.000000            0.970370           1.000000   \n",
      "9        ...                  0.933333            0.940741           1.000000   \n",
      "10       ...                  1.000000            0.970370           1.000000   \n",
      "11       ...                  1.000000            0.970370           1.000000   \n",
      "12       ...                  0.933333            0.844444           0.866667   \n",
      "13       ...                  0.933333            0.844444           0.866667   \n",
      "14       ...                  0.733333            0.733333           0.800000   \n",
      "15       ...                  0.733333            0.733333           0.800000   \n",
      "16       ...                  0.600000            0.614815           0.533333   \n",
      "17       ...                  0.600000            0.614815           0.533333   \n",
      "18       ...                  0.600000            0.562963           0.400000   \n",
      "19       ...                  0.600000            0.562963           0.400000   \n",
      "20       ...                  0.933333            0.844444           0.866667   \n",
      "21       ...                  0.933333            0.844444           0.866667   \n",
      "22       ...                  0.733333            0.733333           0.800000   \n",
      "23       ...                  0.733333            0.733333           0.800000   \n",
      "24       ...                  0.600000            0.614815           0.533333   \n",
      "25       ...                  0.600000            0.614815           0.533333   \n",
      "26       ...                  0.600000            0.562963           0.400000   \n",
      "27       ...                  0.600000            0.562963           0.400000   \n",
      "28       ...                  0.933333            0.881481           0.866667   \n",
      "29       ...                  0.933333            0.844444           0.866667   \n",
      "30       ...                  0.733333            0.733333           0.800000   \n",
      "31       ...                  0.733333            0.733333           0.800000   \n",
      "32       ...                  0.600000            0.614815           0.533333   \n",
      "33       ...                  0.600000            0.614815           0.533333   \n",
      "34       ...                  0.600000            0.562963           0.400000   \n",
      "35       ...                  0.600000            0.562963           0.400000   \n",
      "36       ...                  0.933333            0.955556           1.000000   \n",
      "37       ...                  0.933333            0.844444           0.866667   \n",
      "38       ...                  0.933333            0.866667           0.866667   \n",
      "39       ...                  0.733333            0.733333           0.800000   \n",
      "40       ...                  0.600000            0.614815           0.533333   \n",
      "41       ...                  0.600000            0.614815           0.533333   \n",
      "42       ...                  0.600000            0.562963           0.400000   \n",
      "43       ...                  0.600000            0.562963           0.400000   \n",
      "\n",
      "    split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0             0.985185           1.000000            0.977778      0.001535   \n",
      "1             0.985185           1.000000            0.985185      0.000433   \n",
      "2             0.977778           1.000000            0.977778      0.003539   \n",
      "3             0.985185           1.000000            0.985185      0.003747   \n",
      "4             0.896296           0.866667            0.903704      0.000747   \n",
      "5             0.896296           0.866667            0.903704      0.000434   \n",
      "6             0.940741           1.000000            0.933333      0.003007   \n",
      "7             0.896296           0.866667            0.903704      0.001429   \n",
      "8             0.970370           1.000000            0.955556      0.000062   \n",
      "9             0.940741           1.000000            0.933333      0.000132   \n",
      "10            0.970370           1.000000            0.962963      0.000082   \n",
      "11            0.970370           1.000000            0.955556      0.000119   \n",
      "12            0.851852           0.733333            0.866667      0.001657   \n",
      "13            0.851852           0.733333            0.866667      0.001926   \n",
      "14            0.725926           0.600000            0.748148      0.001800   \n",
      "15            0.725926           0.600000            0.748148      0.001358   \n",
      "16            0.622222           0.400000            0.637037      0.004195   \n",
      "17            0.622222           0.400000            0.637037      0.003306   \n",
      "18            0.585185           0.400000            0.585185      0.000994   \n",
      "19            0.585185           0.400000            0.585185      0.001030   \n",
      "20            0.851852           0.733333            0.866667      0.000984   \n",
      "21            0.851852           0.733333            0.866667      0.000272   \n",
      "22            0.725926           0.600000            0.748148      0.003231   \n",
      "23            0.725926           0.600000            0.748148      0.001323   \n",
      "24            0.622222           0.400000            0.637037      0.001067   \n",
      "25            0.622222           0.400000            0.637037      0.001069   \n",
      "26            0.585185           0.400000            0.585185      0.000996   \n",
      "27            0.585185           0.400000            0.585185      0.001274   \n",
      "28            0.888889           0.866667            0.888889      0.001997   \n",
      "29            0.851852           0.733333            0.866667      0.001107   \n",
      "30            0.725926           0.600000            0.748148      0.000945   \n",
      "31            0.725926           0.600000            0.748148      0.001053   \n",
      "32            0.622222           0.400000            0.637037      0.001081   \n",
      "33            0.622222           0.400000            0.637037      0.001114   \n",
      "34            0.585185           0.400000            0.585185      0.001089   \n",
      "35            0.585185           0.400000            0.585185      0.000764   \n",
      "36            0.948148           1.000000            0.940741      0.000040   \n",
      "37            0.851852           0.733333            0.866667      0.000072   \n",
      "38            0.866667           0.800000            0.874074      0.000027   \n",
      "39            0.725926           0.600000            0.748148      0.000624   \n",
      "40            0.622222           0.400000            0.637037      0.000777   \n",
      "41            0.622222           0.400000            0.637037      0.000025   \n",
      "42            0.585185           0.400000            0.585185      0.000140   \n",
      "43            0.585185           0.400000            0.585185      0.000366   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.000515        0.030551         0.007444  \n",
      "1         0.000103        0.044222         0.005785  \n",
      "2         0.000061        0.032660         0.005926  \n",
      "3         0.000079        0.044721         0.005543  \n",
      "4         0.000063        0.044721         0.009042  \n",
      "5         0.000028        0.044721         0.009042  \n",
      "6         0.000674        0.055377         0.006458  \n",
      "7         0.000048        0.044721         0.009042  \n",
      "8         0.000029        0.032660         0.010502  \n",
      "9         0.000017        0.055377         0.006458  \n",
      "10        0.000008        0.032660         0.008920  \n",
      "11        0.000052        0.032660         0.010502  \n",
      "12        0.000084        0.083267         0.007444  \n",
      "13        0.000779        0.083267         0.007444  \n",
      "14        0.000548        0.084327         0.014534  \n",
      "15        0.002084        0.084327         0.014534  \n",
      "16        0.000308        0.122202         0.019102  \n",
      "17        0.000120        0.122202         0.019102  \n",
      "18        0.000083        0.120185         0.014363  \n",
      "19        0.000085        0.120185         0.014363  \n",
      "20        0.000104        0.083267         0.007444  \n",
      "21        0.000016        0.083267         0.007444  \n",
      "22        0.000220        0.084327         0.014534  \n",
      "23        0.000117        0.084327         0.014534  \n",
      "24        0.000094        0.122202         0.019102  \n",
      "25        0.000086        0.122202         0.019102  \n",
      "26        0.000080        0.120185         0.014363  \n",
      "27        0.000061        0.120185         0.014363  \n",
      "28        0.000098        0.042687         0.007734  \n",
      "29        0.000083        0.083267         0.007444  \n",
      "30        0.000091        0.084327         0.014534  \n",
      "31        0.000106        0.084327         0.014534  \n",
      "32        0.000106        0.122202         0.019102  \n",
      "33        0.000082        0.122202         0.019102  \n",
      "34        0.000098        0.120185         0.014363  \n",
      "35        0.000101        0.120185         0.014363  \n",
      "36        0.000006        0.052068         0.010709  \n",
      "37        0.000012        0.083267         0.007444  \n",
      "38        0.000004        0.055377         0.005738  \n",
      "39        0.000124        0.084327         0.014534  \n",
      "40        0.000099        0.122202         0.019102  \n",
      "41        0.000005        0.122202         0.019102  \n",
      "42        0.000011        0.120185         0.014363  \n",
      "43        0.000077        0.120185         0.014363  \n",
      "\n",
      "[44 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# sepal widthの重要度が低いので除外してSVMで分類してみる\n",
    "\n",
    "# sepal widthを除いた特徴量のnparrayを作成する\n",
    "rf_data = np.append(iris.data[:, :1], iris.data[:, 2:], axis=1)\n",
    "rf_train = np.append(x_train[:, :1], x_train[:, 2:], axis=1)\n",
    "rf_test = np.append(x_test[:, :1], x_test[:, 2:], axis=1)\n",
    "\n",
    "# 先ほどと同じ条件でグリッドサーチを行なう\n",
    "svm_rf = GridSearchCV(SVC(probability=True, decision_function_shape=\"ovr\"), param_svm, cv=10, n_jobs=job)\n",
    "svm_rf.fit(rf_data, iris.target)\n",
    "\n",
    "df_rf = pd.DataFrame(svm_rf.cv_results_)\n",
    "print(df_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.98\n",
      "best param: {'C': 1, 'kernel': 'linear'}\n",
      "best score's index: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %svm_rf.best_estimator_)\n",
    "print(\"best socre: %s\" %svm_rf.best_score_)\n",
    "print(\"best param: %s\" %svm_rf.best_params_)\n",
    "print(\"best score's index: %s\" %svm_rf.best_index_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  0 25]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       1.00      0.96      0.98        25\n",
      "  virginica       0.96      1.00      0.98        25\n",
      "\n",
      "avg / total       0.99      0.99      0.99        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_bestrf = SVC(C=1, kernel=\"linear\", probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "svm_bestrf.fit(rf_train, y_train)\n",
    "\n",
    "predict_bestrf = svm_bestrf.predict(rf_test)\n",
    "matrix_bestrf = confusion_matrix(y_test, predict_bestrf)\n",
    "report_bestrf = classification_report(y_test, predict_bestrf, target_names=iris.target_names)\n",
    "\n",
    "print(predict_bestrf)\n",
    "print(matrix_bestrf)\n",
    "print(report_bestrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ↑F値が0.97から0.99に上昇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
