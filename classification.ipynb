{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythonを使った機械学習：Classification（分類）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習（Machine Learning）とは？\n",
    "与えられたデータ群から規則性を見つけ出して，人間の学習能力をコンピュータ上で再現すること\n",
    "\n",
    "## 教師あり学習\n",
    "人間が正解データ（教師データ）を事前に与えて，それに基づいて学習を行う手法．<br>\n",
    "Classification（分類）やRegresion（回帰）など\n",
    "\n",
    "### Classification: Suport Vector Machine（SVM）\n",
    "複数のデータ群を分類する境界線を作り出すことで，与えられたデータがどの分類に属するのかがわかる<br>\n",
    "境界線の引き方にも色々と種類がある<br>\n",
    "![](./images/svms.png) <br>\n",
    "http://scikit-learn.org/stable/auto_examples/exercises/plot_iris_exercise.html\n",
    "\n",
    "### Classification: K-Nearest Neighbor Algorithm(KNN法）\n",
    "教師データ上に与えられたデータを配置した時，教師データに近いk個のデータの割合で与えられたデータの割合を決める<br>\n",
    "![](./images/knn.png)\n",
    "\n",
    "## 教師なし学習\n",
    "人間から正解データを付与されず，アルゴリズムによってコンピュータが答え（分類）を計算する手法<br>\n",
    "Clustering（クラスタリング）など\n",
    "\n",
    "## 半教師あり学習\n",
    "教師ありとなしのいいとこ取りみたいな感じ\n",
    "\n",
    "# ここでは，Classificationを扱う\n",
    "\n",
    "# 特徴量（Features）とは？\n",
    "分類のためには特徴量が必要<br>\n",
    "特徴量＝コンピュータが理解できるデータ上の違い<br>\n",
    "この違いが分類の決めてになる\n",
    "\n",
    "## Irisデータ\n",
    "有名なデータセットの一つで，Iris（あやめ）の花の萼片（Sepal）と花びら（Petal）の長さ（Length）と幅（Width）が三種類分（Setosa・Versicolour・Virginica）格納されている<br>\n",
    "![](./images/iris.jpg)\n",
    "<br>\n",
    "データの種類は次元と言われる<br>\n",
    "つまり，Irisデータの場合四種類のデータなので，「四次元」のデータということになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learnとは？\n",
    "![](http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png)\n",
    "Pythonで提供されている機械学習のライブラリ<br>\n",
    "http://scikit-learn.org/stable/index.html\n",
    "<br>\n",
    "importするときは，sklearnとして扱われる<br>\n",
    "anacondaに標準インストールされている<br>\n",
    "<br>\n",
    "anacondaを使っていない場合は\n",
    "* pip install scikit-learn\n",
    "\n",
    "<br>で導入可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# では，実際にやってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 必要な環境をimportする\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n', 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
      "      dtype='<U10'), 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
      "       [ 4.9,  3. ,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.3,  0.2],\n",
      "       [ 4.6,  3.1,  1.5,  0.2],\n",
      "       [ 5. ,  3.6,  1.4,  0.2],\n",
      "       [ 5.4,  3.9,  1.7,  0.4],\n",
      "       [ 4.6,  3.4,  1.4,  0.3],\n",
      "       [ 5. ,  3.4,  1.5,  0.2],\n",
      "       [ 4.4,  2.9,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5.4,  3.7,  1.5,  0.2],\n",
      "       [ 4.8,  3.4,  1.6,  0.2],\n",
      "       [ 4.8,  3. ,  1.4,  0.1],\n",
      "       [ 4.3,  3. ,  1.1,  0.1],\n",
      "       [ 5.8,  4. ,  1.2,  0.2],\n",
      "       [ 5.7,  4.4,  1.5,  0.4],\n",
      "       [ 5.4,  3.9,  1.3,  0.4],\n",
      "       [ 5.1,  3.5,  1.4,  0.3],\n",
      "       [ 5.7,  3.8,  1.7,  0.3],\n",
      "       [ 5.1,  3.8,  1.5,  0.3],\n",
      "       [ 5.4,  3.4,  1.7,  0.2],\n",
      "       [ 5.1,  3.7,  1.5,  0.4],\n",
      "       [ 4.6,  3.6,  1. ,  0.2],\n",
      "       [ 5.1,  3.3,  1.7,  0.5],\n",
      "       [ 4.8,  3.4,  1.9,  0.2],\n",
      "       [ 5. ,  3. ,  1.6,  0.2],\n",
      "       [ 5. ,  3.4,  1.6,  0.4],\n",
      "       [ 5.2,  3.5,  1.5,  0.2],\n",
      "       [ 5.2,  3.4,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.6,  0.2],\n",
      "       [ 4.8,  3.1,  1.6,  0.2],\n",
      "       [ 5.4,  3.4,  1.5,  0.4],\n",
      "       [ 5.2,  4.1,  1.5,  0.1],\n",
      "       [ 5.5,  4.2,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5. ,  3.2,  1.2,  0.2],\n",
      "       [ 5.5,  3.5,  1.3,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 4.4,  3. ,  1.3,  0.2],\n",
      "       [ 5.1,  3.4,  1.5,  0.2],\n",
      "       [ 5. ,  3.5,  1.3,  0.3],\n",
      "       [ 4.5,  2.3,  1.3,  0.3],\n",
      "       [ 4.4,  3.2,  1.3,  0.2],\n",
      "       [ 5. ,  3.5,  1.6,  0.6],\n",
      "       [ 5.1,  3.8,  1.9,  0.4],\n",
      "       [ 4.8,  3. ,  1.4,  0.3],\n",
      "       [ 5.1,  3.8,  1.6,  0.2],\n",
      "       [ 4.6,  3.2,  1.4,  0.2],\n",
      "       [ 5.3,  3.7,  1.5,  0.2],\n",
      "       [ 5. ,  3.3,  1.4,  0.2],\n",
      "       [ 7. ,  3.2,  4.7,  1.4],\n",
      "       [ 6.4,  3.2,  4.5,  1.5],\n",
      "       [ 6.9,  3.1,  4.9,  1.5],\n",
      "       [ 5.5,  2.3,  4. ,  1.3],\n",
      "       [ 6.5,  2.8,  4.6,  1.5],\n",
      "       [ 5.7,  2.8,  4.5,  1.3],\n",
      "       [ 6.3,  3.3,  4.7,  1.6],\n",
      "       [ 4.9,  2.4,  3.3,  1. ],\n",
      "       [ 6.6,  2.9,  4.6,  1.3],\n",
      "       [ 5.2,  2.7,  3.9,  1.4],\n",
      "       [ 5. ,  2. ,  3.5,  1. ],\n",
      "       [ 5.9,  3. ,  4.2,  1.5],\n",
      "       [ 6. ,  2.2,  4. ,  1. ],\n",
      "       [ 6.1,  2.9,  4.7,  1.4],\n",
      "       [ 5.6,  2.9,  3.6,  1.3],\n",
      "       [ 6.7,  3.1,  4.4,  1.4],\n",
      "       [ 5.6,  3. ,  4.5,  1.5],\n",
      "       [ 5.8,  2.7,  4.1,  1. ],\n",
      "       [ 6.2,  2.2,  4.5,  1.5],\n",
      "       [ 5.6,  2.5,  3.9,  1.1],\n",
      "       [ 5.9,  3.2,  4.8,  1.8],\n",
      "       [ 6.1,  2.8,  4. ,  1.3],\n",
      "       [ 6.3,  2.5,  4.9,  1.5],\n",
      "       [ 6.1,  2.8,  4.7,  1.2],\n",
      "       [ 6.4,  2.9,  4.3,  1.3],\n",
      "       [ 6.6,  3. ,  4.4,  1.4],\n",
      "       [ 6.8,  2.8,  4.8,  1.4],\n",
      "       [ 6.7,  3. ,  5. ,  1.7],\n",
      "       [ 6. ,  2.9,  4.5,  1.5],\n",
      "       [ 5.7,  2.6,  3.5,  1. ],\n",
      "       [ 5.5,  2.4,  3.8,  1.1],\n",
      "       [ 5.5,  2.4,  3.7,  1. ],\n",
      "       [ 5.8,  2.7,  3.9,  1.2],\n",
      "       [ 6. ,  2.7,  5.1,  1.6],\n",
      "       [ 5.4,  3. ,  4.5,  1.5],\n",
      "       [ 6. ,  3.4,  4.5,  1.6],\n",
      "       [ 6.7,  3.1,  4.7,  1.5],\n",
      "       [ 6.3,  2.3,  4.4,  1.3],\n",
      "       [ 5.6,  3. ,  4.1,  1.3],\n",
      "       [ 5.5,  2.5,  4. ,  1.3],\n",
      "       [ 5.5,  2.6,  4.4,  1.2],\n",
      "       [ 6.1,  3. ,  4.6,  1.4],\n",
      "       [ 5.8,  2.6,  4. ,  1.2],\n",
      "       [ 5. ,  2.3,  3.3,  1. ],\n",
      "       [ 5.6,  2.7,  4.2,  1.3],\n",
      "       [ 5.7,  3. ,  4.2,  1.2],\n",
      "       [ 5.7,  2.9,  4.2,  1.3],\n",
      "       [ 6.2,  2.9,  4.3,  1.3],\n",
      "       [ 5.1,  2.5,  3. ,  1.1],\n",
      "       [ 5.7,  2.8,  4.1,  1.3],\n",
      "       [ 6.3,  3.3,  6. ,  2.5],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 7.1,  3. ,  5.9,  2.1],\n",
      "       [ 6.3,  2.9,  5.6,  1.8],\n",
      "       [ 6.5,  3. ,  5.8,  2.2],\n",
      "       [ 7.6,  3. ,  6.6,  2.1],\n",
      "       [ 4.9,  2.5,  4.5,  1.7],\n",
      "       [ 7.3,  2.9,  6.3,  1.8],\n",
      "       [ 6.7,  2.5,  5.8,  1.8],\n",
      "       [ 7.2,  3.6,  6.1,  2.5],\n",
      "       [ 6.5,  3.2,  5.1,  2. ],\n",
      "       [ 6.4,  2.7,  5.3,  1.9],\n",
      "       [ 6.8,  3. ,  5.5,  2.1],\n",
      "       [ 5.7,  2.5,  5. ,  2. ],\n",
      "       [ 5.8,  2.8,  5.1,  2.4],\n",
      "       [ 6.4,  3.2,  5.3,  2.3],\n",
      "       [ 6.5,  3. ,  5.5,  1.8],\n",
      "       [ 7.7,  3.8,  6.7,  2.2],\n",
      "       [ 7.7,  2.6,  6.9,  2.3],\n",
      "       [ 6. ,  2.2,  5. ,  1.5],\n",
      "       [ 6.9,  3.2,  5.7,  2.3],\n",
      "       [ 5.6,  2.8,  4.9,  2. ],\n",
      "       [ 7.7,  2.8,  6.7,  2. ],\n",
      "       [ 6.3,  2.7,  4.9,  1.8],\n",
      "       [ 6.7,  3.3,  5.7,  2.1],\n",
      "       [ 7.2,  3.2,  6. ,  1.8],\n",
      "       [ 6.2,  2.8,  4.8,  1.8],\n",
      "       [ 6.1,  3. ,  4.9,  1.8],\n",
      "       [ 6.4,  2.8,  5.6,  2.1],\n",
      "       [ 7.2,  3. ,  5.8,  1.6],\n",
      "       [ 7.4,  2.8,  6.1,  1.9],\n",
      "       [ 7.9,  3.8,  6.4,  2. ],\n",
      "       [ 6.4,  2.8,  5.6,  2.2],\n",
      "       [ 6.3,  2.8,  5.1,  1.5],\n",
      "       [ 6.1,  2.6,  5.6,  1.4],\n",
      "       [ 7.7,  3. ,  6.1,  2.3],\n",
      "       [ 6.3,  3.4,  5.6,  2.4],\n",
      "       [ 6.4,  3.1,  5.5,  1.8],\n",
      "       [ 6. ,  3. ,  4.8,  1.8],\n",
      "       [ 6.9,  3.1,  5.4,  2.1],\n",
      "       [ 6.7,  3.1,  5.6,  2.4],\n",
      "       [ 6.9,  3.1,  5.1,  2.3],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 6.8,  3.2,  5.9,  2.3],\n",
      "       [ 6.7,  3.3,  5.7,  2.5],\n",
      "       [ 6.7,  3. ,  5.2,  2.3],\n",
      "       [ 6.3,  2.5,  5. ,  1.9],\n",
      "       [ 6.5,  3. ,  5.2,  2. ],\n",
      "       [ 6.2,  3.4,  5.4,  2.3],\n",
      "       [ 5.9,  3. ,  5.1,  1.8]])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "#  irisデータを読み込む\n",
    "iris = datasets.load_iris()\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# irisデータを学習データとテストデータに分割する\n",
    "# データの奇数番目を学習データに，偶数番目をテストデータにする\n",
    "\n",
    "x_train = iris.data[range(0, len(iris.data), 2)]\n",
    "y_train = iris.target[range(0, len(iris.data), 2)]\n",
    "\n",
    "x_test = iris.data[range(1, len(iris.data), 2)]\n",
    "y_test = iris.target[range(1, len(iris.data), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': True,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#　学習の用意\n",
    "svm = SVC(probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "# 分類器の設定を確認する\n",
    "svm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習器に教師データを与えて学習させる\n",
    "# 引数は特徴量，教師データ（ラベル）\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "# 分類器にテストデータを分類させる\n",
    "predict = svm.predict(x_test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作成した分類器を評価する\n",
    "### 適合率（Precion）と再現率（Recall）とは？\n",
    "#### 適合率\n",
    "検索結果の中で，どの程度が正解に含まれるか\n",
    "#### 再現率\n",
    "正解の中で，どの程度が検索にヒットするのか\n",
    "![](http://cdn-ak.f.st-hatena.com/images/fotolife/Z/Zellij/20120214/20120214075315.png)\n",
    "<br>http://f.hatena.ne.jp/Zellij/20120214075315<br>\n",
    "\n",
    "# わからん！\n",
    "ということで，混合行列\n",
    "### 混合行列（Confusion Matrix）とは？\n",
    "テストデータがどのラベルにどれだけ分類されたかを表す行列<br>\n",
    "![](./images/cm1.png)<br>\n",
    "![](./images/cm2.png)<br>\n",
    "![](./images/cm3.png)<br>\n",
    "![](./images/cm4.png)<br>\n",
    "\n",
    "### F値（F-measure）とは？\n",
    "適合率と再現率は負の相関関係にあることが多い＝トレードオフの関係にある<br>\n",
    "ということで，分類器の制度を適合率と再現率の調和平均＝F値で評価する<br>\n",
    "$\n",
    "F-measure = \\displaystyle　\\frac{2\\dot precion \\times recall}{precion + recall}\n",
    "$<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  0,  0],\n",
       "       [ 0, 24,  1],\n",
       "       [ 0,  4, 21]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先ほどの分類器の混合行列を表示する\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 引数は，正解データと予測結果\n",
    "matrix = confusion_matrix(y_test, predict)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.86      0.96      0.91        25\n",
      "  virginica       0.95      0.84      0.89        25\n",
      "\n",
      "avg / total       0.94      0.93      0.93        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F値を計算する\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 引数は，正解データと予測結果\n",
    "# オプションとして，target_namesを利用可能\n",
    "report = classification_report(y_test, predict, target_names=iris.target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-分割交差検定（K-fold Cross-Validation）による分類器の検証\n",
    "データ数があまり多くなくて，学習データとテストデータにわけると数が足りない場合などに利用される\n",
    "![](./images/kfcv.png)\n",
    "\n",
    "### グリッドサーチとは？\n",
    "機械学習には，学習の際のパラメータが存在し，そのパラメータをチューニングして最良な分類器を作成する<br>\n",
    "以下では，k分割交差検定法とグリッドサーチが同時に実装されている関数を用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
      "0        0.003272         0.001308         0.973333          0.988148       1   \n",
      "1        0.002560         0.000476         0.980000          0.980000      10   \n",
      "2        0.003118         0.000501         0.973333          0.981481     100   \n",
      "3        0.011820         0.000682         0.980000          0.986667    1000   \n",
      "4        0.008885         0.000581         0.906667          0.921481       1   \n",
      "5        0.010018         0.000755         0.906667          0.921481       1   \n",
      "6        0.006084         0.000592         0.933333          0.945185      10   \n",
      "7        0.008402         0.000597         0.906667          0.921481      10   \n",
      "8        0.003332         0.000525         0.980000          0.979259     100   \n",
      "9        0.005177         0.000942         0.933333          0.945185     100   \n",
      "10       0.002790         0.000490         0.980000          0.980000    1000   \n",
      "11       0.003461         0.000493         0.980000          0.979259    1000   \n",
      "12       0.006286         0.000898         0.866667          0.865926       1   \n",
      "13       0.006830         0.000602         0.866667          0.865926       1   \n",
      "14       0.009934         0.001761         0.746667          0.748889       1   \n",
      "15       0.008144         0.000698         0.746667          0.748889       1   \n",
      "16       0.005258         0.000475         0.640000          0.642222       1   \n",
      "17       0.006006         0.000538         0.640000          0.642222       1   \n",
      "18       0.009951         0.000819         0.573333          0.576296       1   \n",
      "19       0.010013         0.000634         0.573333          0.576296       1   \n",
      "20       0.005246         0.000483         0.866667          0.865926      10   \n",
      "21       0.005094         0.000454         0.866667          0.865926      10   \n",
      "22       0.005356         0.000500         0.746667          0.748889      10   \n",
      "23       0.009826         0.001016         0.746667          0.748889      10   \n",
      "24       0.008616         0.000946         0.640000          0.642222      10   \n",
      "25       0.005063         0.000486         0.640000          0.642222      10   \n",
      "26       0.005076         0.000471         0.573333          0.576296      10   \n",
      "27       0.005548         0.000477         0.573333          0.576296      10   \n",
      "28       0.003258         0.000493         0.886667          0.898519     100   \n",
      "29       0.005941         0.000569         0.866667          0.865926     100   \n",
      "30       0.006065         0.000553         0.746667          0.748889     100   \n",
      "31       0.005709         0.000540         0.746667          0.748889     100   \n",
      "32       0.005259         0.000496         0.640000          0.642222     100   \n",
      "33       0.005502         0.000476         0.640000          0.642222     100   \n",
      "34       0.005954         0.000566         0.573333          0.576296     100   \n",
      "35       0.005109         0.000511         0.573333          0.576296     100   \n",
      "36       0.002037         0.000370         0.960000          0.961481    1000   \n",
      "37       0.005135         0.000495         0.866667          0.865926    1000   \n",
      "38       0.003706         0.000546         0.866667          0.871111    1000   \n",
      "39       0.005291         0.000537         0.746667          0.748889    1000   \n",
      "40       0.005891         0.000570         0.653333          0.656296    1000   \n",
      "41       0.005681         0.000479         0.640000          0.642222    1000   \n",
      "42       0.005005         0.000479         0.573333          0.576296    1000   \n",
      "43       0.003793         0.000336         0.573333          0.576296    1000   \n",
      "\n",
      "   param_degree param_gamma param_kernel  \\\n",
      "0           NaN         NaN       linear   \n",
      "1           NaN         NaN       linear   \n",
      "2           NaN         NaN       linear   \n",
      "3           NaN         NaN       linear   \n",
      "4           NaN       0.001          rbf   \n",
      "5           NaN      0.0001          rbf   \n",
      "6           NaN       0.001          rbf   \n",
      "7           NaN      0.0001          rbf   \n",
      "8           NaN       0.001          rbf   \n",
      "9           NaN      0.0001          rbf   \n",
      "10          NaN       0.001          rbf   \n",
      "11          NaN      0.0001          rbf   \n",
      "12            2       0.001         poly   \n",
      "13            2      0.0001         poly   \n",
      "14            3       0.001         poly   \n",
      "15            3      0.0001         poly   \n",
      "16            4       0.001         poly   \n",
      "17            4      0.0001         poly   \n",
      "18            5       0.001         poly   \n",
      "19            5      0.0001         poly   \n",
      "20            2       0.001         poly   \n",
      "21            2      0.0001         poly   \n",
      "22            3       0.001         poly   \n",
      "23            3      0.0001         poly   \n",
      "24            4       0.001         poly   \n",
      "25            4      0.0001         poly   \n",
      "26            5       0.001         poly   \n",
      "27            5      0.0001         poly   \n",
      "28            2       0.001         poly   \n",
      "29            2      0.0001         poly   \n",
      "30            3       0.001         poly   \n",
      "31            3      0.0001         poly   \n",
      "32            4       0.001         poly   \n",
      "33            4      0.0001         poly   \n",
      "34            5       0.001         poly   \n",
      "35            5      0.0001         poly   \n",
      "36            2       0.001         poly   \n",
      "37            2      0.0001         poly   \n",
      "38            3       0.001         poly   \n",
      "39            3      0.0001         poly   \n",
      "40            4       0.001         poly   \n",
      "41            4      0.0001         poly   \n",
      "42            5       0.001         poly   \n",
      "43            5      0.0001         poly   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0                        {'kernel': 'linear', 'C': 1}                6   \n",
      "1                       {'kernel': 'linear', 'C': 10}                1   \n",
      "2                      {'kernel': 'linear', 'C': 100}                6   \n",
      "3                     {'kernel': 'linear', 'C': 1000}                1   \n",
      "4           {'kernel': 'rbf', 'gamma': 0.001, 'C': 1}               11   \n",
      "5          {'kernel': 'rbf', 'gamma': 0.0001, 'C': 1}               11   \n",
      "6          {'kernel': 'rbf', 'gamma': 0.001, 'C': 10}                9   \n",
      "7         {'kernel': 'rbf', 'gamma': 0.0001, 'C': 10}               11   \n",
      "8         {'kernel': 'rbf', 'gamma': 0.001, 'C': 100}                1   \n",
      "9        {'kernel': 'rbf', 'gamma': 0.0001, 'C': 100}                9   \n",
      "10       {'kernel': 'rbf', 'gamma': 0.001, 'C': 1000}                1   \n",
      "11      {'kernel': 'rbf', 'gamma': 0.0001, 'C': 1000}                1   \n",
      "12  {'degree': 2, 'kernel': 'poly', 'gamma': 0.001...               15   \n",
      "13  {'degree': 2, 'kernel': 'poly', 'gamma': 0.000...               15   \n",
      "14  {'degree': 3, 'kernel': 'poly', 'gamma': 0.001...               22   \n",
      "15  {'degree': 3, 'kernel': 'poly', 'gamma': 0.000...               22   \n",
      "16  {'degree': 4, 'kernel': 'poly', 'gamma': 0.001...               30   \n",
      "17  {'degree': 4, 'kernel': 'poly', 'gamma': 0.000...               30   \n",
      "18  {'degree': 5, 'kernel': 'poly', 'gamma': 0.001...               37   \n",
      "19  {'degree': 5, 'kernel': 'poly', 'gamma': 0.000...               37   \n",
      "20  {'degree': 2, 'kernel': 'poly', 'gamma': 0.001...               15   \n",
      "21  {'degree': 2, 'kernel': 'poly', 'gamma': 0.000...               15   \n",
      "22  {'degree': 3, 'kernel': 'poly', 'gamma': 0.001...               22   \n",
      "23  {'degree': 3, 'kernel': 'poly', 'gamma': 0.000...               22   \n",
      "24  {'degree': 4, 'kernel': 'poly', 'gamma': 0.001...               30   \n",
      "25  {'degree': 4, 'kernel': 'poly', 'gamma': 0.000...               30   \n",
      "26  {'degree': 5, 'kernel': 'poly', 'gamma': 0.001...               37   \n",
      "27  {'degree': 5, 'kernel': 'poly', 'gamma': 0.000...               37   \n",
      "28  {'degree': 2, 'kernel': 'poly', 'gamma': 0.001...               14   \n",
      "29  {'degree': 2, 'kernel': 'poly', 'gamma': 0.000...               15   \n",
      "30  {'degree': 3, 'kernel': 'poly', 'gamma': 0.001...               22   \n",
      "31  {'degree': 3, 'kernel': 'poly', 'gamma': 0.000...               22   \n",
      "32  {'degree': 4, 'kernel': 'poly', 'gamma': 0.001...               30   \n",
      "33  {'degree': 4, 'kernel': 'poly', 'gamma': 0.000...               30   \n",
      "34  {'degree': 5, 'kernel': 'poly', 'gamma': 0.001...               37   \n",
      "35  {'degree': 5, 'kernel': 'poly', 'gamma': 0.000...               37   \n",
      "36  {'degree': 2, 'kernel': 'poly', 'gamma': 0.001...                8   \n",
      "37  {'degree': 2, 'kernel': 'poly', 'gamma': 0.000...               15   \n",
      "38  {'degree': 3, 'kernel': 'poly', 'gamma': 0.001...               15   \n",
      "39  {'degree': 3, 'kernel': 'poly', 'gamma': 0.000...               22   \n",
      "40  {'degree': 4, 'kernel': 'poly', 'gamma': 0.001...               29   \n",
      "41  {'degree': 4, 'kernel': 'poly', 'gamma': 0.000...               30   \n",
      "42  {'degree': 5, 'kernel': 'poly', 'gamma': 0.001...               37   \n",
      "43  {'degree': 5, 'kernel': 'poly', 'gamma': 0.000...               37   \n",
      "\n",
      "         ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0        ...                  1.000000            0.992593           1.000000   \n",
      "1        ...                  1.000000            0.985185           1.000000   \n",
      "2        ...                  0.933333            0.985185           1.000000   \n",
      "3        ...                  1.000000            0.985185           1.000000   \n",
      "4        ...                  0.933333            0.918519           0.933333   \n",
      "5        ...                  0.933333            0.918519           0.933333   \n",
      "6        ...                  0.933333            0.948148           1.000000   \n",
      "7        ...                  0.933333            0.918519           0.933333   \n",
      "8        ...                  1.000000            0.977778           1.000000   \n",
      "9        ...                  0.933333            0.948148           1.000000   \n",
      "10       ...                  1.000000            0.985185           1.000000   \n",
      "11       ...                  1.000000            0.977778           1.000000   \n",
      "12       ...                  0.933333            0.859259           0.866667   \n",
      "13       ...                  0.933333            0.859259           0.866667   \n",
      "14       ...                  0.800000            0.740741           0.866667   \n",
      "15       ...                  0.800000            0.740741           0.866667   \n",
      "16       ...                  0.600000            0.644444           0.600000   \n",
      "17       ...                  0.600000            0.644444           0.600000   \n",
      "18       ...                  0.600000            0.570370           0.466667   \n",
      "19       ...                  0.600000            0.570370           0.466667   \n",
      "20       ...                  0.933333            0.859259           0.866667   \n",
      "21       ...                  0.933333            0.859259           0.866667   \n",
      "22       ...                  0.800000            0.740741           0.866667   \n",
      "23       ...                  0.800000            0.740741           0.866667   \n",
      "24       ...                  0.600000            0.644444           0.600000   \n",
      "25       ...                  0.600000            0.644444           0.600000   \n",
      "26       ...                  0.600000            0.570370           0.466667   \n",
      "27       ...                  0.600000            0.570370           0.466667   \n",
      "28       ...                  0.933333            0.896296           0.933333   \n",
      "29       ...                  0.933333            0.859259           0.866667   \n",
      "30       ...                  0.800000            0.740741           0.866667   \n",
      "31       ...                  0.800000            0.740741           0.866667   \n",
      "32       ...                  0.600000            0.644444           0.600000   \n",
      "33       ...                  0.600000            0.644444           0.600000   \n",
      "34       ...                  0.600000            0.570370           0.466667   \n",
      "35       ...                  0.600000            0.570370           0.466667   \n",
      "36       ...                  0.933333            0.962963           1.000000   \n",
      "37       ...                  0.933333            0.859259           0.866667   \n",
      "38       ...                  0.933333            0.866667           0.866667   \n",
      "39       ...                  0.800000            0.740741           0.866667   \n",
      "40       ...                  0.666667            0.651852           0.600000   \n",
      "41       ...                  0.600000            0.644444           0.600000   \n",
      "42       ...                  0.600000            0.570370           0.466667   \n",
      "43       ...                  0.600000            0.570370           0.466667   \n",
      "\n",
      "    split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0             0.992593           1.000000            0.985185      0.001904   \n",
      "1             0.977778           1.000000            0.977778      0.000534   \n",
      "2             0.977778           1.000000            0.977778      0.000659   \n",
      "3             0.985185           1.000000            0.985185      0.008750   \n",
      "4             0.918519           0.933333            0.903704      0.001475   \n",
      "5             0.918519           0.933333            0.903704      0.004096   \n",
      "6             0.940741           1.000000            0.933333      0.001887   \n",
      "7             0.918519           0.933333            0.903704      0.001795   \n",
      "8             0.985185           1.000000            0.970370      0.000138   \n",
      "9             0.940741           1.000000            0.933333      0.000157   \n",
      "10            0.977778           1.000000            0.985185      0.000096   \n",
      "11            0.985185           1.000000            0.970370      0.001139   \n",
      "12            0.866667           0.800000            0.874074      0.000656   \n",
      "13            0.866667           0.800000            0.874074      0.001473   \n",
      "14            0.733333           0.600000            0.762963      0.003822   \n",
      "15            0.733333           0.600000            0.762963      0.003191   \n",
      "16            0.644444           0.400000            0.666667      0.000939   \n",
      "17            0.644444           0.400000            0.666667      0.000547   \n",
      "18            0.585185           0.400000            0.592593      0.002187   \n",
      "19            0.585185           0.400000            0.592593      0.003951   \n",
      "20            0.866667           0.800000            0.874074      0.000795   \n",
      "21            0.866667           0.800000            0.874074      0.001871   \n",
      "22            0.733333           0.600000            0.762963      0.000895   \n",
      "23            0.733333           0.600000            0.762963      0.003946   \n",
      "24            0.644444           0.400000            0.666667      0.002625   \n",
      "25            0.644444           0.400000            0.666667      0.001116   \n",
      "26            0.585185           0.400000            0.592593      0.001175   \n",
      "27            0.585185           0.400000            0.592593      0.001496   \n",
      "28            0.888889           0.800000            0.903704      0.000548   \n",
      "29            0.866667           0.800000            0.874074      0.000821   \n",
      "30            0.733333           0.600000            0.762963      0.000757   \n",
      "31            0.733333           0.600000            0.762963      0.000583   \n",
      "32            0.644444           0.400000            0.666667      0.001214   \n",
      "33            0.644444           0.400000            0.666667      0.000771   \n",
      "34            0.585185           0.400000            0.592593      0.000742   \n",
      "35            0.585185           0.400000            0.592593      0.000881   \n",
      "36            0.955556           1.000000            0.948148      0.000399   \n",
      "37            0.866667           0.800000            0.874074      0.001026   \n",
      "38            0.874074           0.800000            0.881481      0.000890   \n",
      "39            0.733333           0.600000            0.762963      0.001231   \n",
      "40            0.659259           0.400000            0.681481      0.000900   \n",
      "41            0.644444           0.400000            0.666667      0.000854   \n",
      "42            0.585185           0.400000            0.592593      0.000863   \n",
      "43            0.585185           0.400000            0.592593      0.000547   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.001667        0.044222         0.004914  \n",
      "1         0.000090        0.042687         0.006667  \n",
      "2         0.000035        0.044222         0.004969  \n",
      "3         0.000286        0.042687         0.005543  \n",
      "4         0.000071        0.061101         0.007554  \n",
      "5         0.000408        0.061101         0.007554  \n",
      "6         0.000104        0.051640         0.008249  \n",
      "7         0.000074        0.061101         0.007554  \n",
      "8         0.000027        0.030551         0.007258  \n",
      "9         0.001092        0.051640         0.008249  \n",
      "10        0.000016        0.042687         0.005785  \n",
      "11        0.000086        0.030551         0.007258  \n",
      "12        0.000946        0.059628         0.007734  \n",
      "13        0.000042        0.059628         0.007734  \n",
      "14        0.002980        0.093333         0.012593  \n",
      "15        0.000292        0.093333         0.012593  \n",
      "16        0.000087        0.130639         0.013679  \n",
      "17        0.000075        0.130639         0.013679  \n",
      "18        0.000303        0.112349         0.012744  \n",
      "19        0.000086        0.112349         0.012744  \n",
      "20        0.000092        0.059628         0.007734  \n",
      "21        0.000122        0.059628         0.007734  \n",
      "22        0.000077        0.093333         0.012593  \n",
      "23        0.000736        0.093333         0.012593  \n",
      "24        0.000828        0.130639         0.013679  \n",
      "25        0.000112        0.130639         0.013679  \n",
      "26        0.000111        0.112349         0.012744  \n",
      "27        0.000089        0.112349         0.012744  \n",
      "28        0.000132        0.060000         0.009966  \n",
      "29        0.000183        0.059628         0.007734  \n",
      "30        0.000091        0.093333         0.012593  \n",
      "31        0.000084        0.093333         0.012593  \n",
      "32        0.000105        0.130639         0.013679  \n",
      "33        0.000100        0.130639         0.013679  \n",
      "34        0.000085        0.112349         0.012744  \n",
      "35        0.000114        0.112349         0.012744  \n",
      "36        0.000077        0.053333         0.009827  \n",
      "37        0.000098        0.059628         0.007734  \n",
      "38        0.000162        0.051640         0.005926  \n",
      "39        0.000131        0.093333         0.012593  \n",
      "40        0.000069        0.135974         0.012915  \n",
      "41        0.000095        0.130639         0.013679  \n",
      "42        0.000117        0.112349         0.012744  \n",
      "43        0.000059        0.112349         0.012744  \n",
      "\n",
      "[44 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# グリッドサーチのために，パラメータの選択肢を決定する\n",
    "param_svm = [\n",
    "{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel':['poly'], 'degree': [2, 3, 4, 5], }\n",
    " ] \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# グリッドサーチ&交差検定用の学習器を設定する\n",
    "# 引数に，用いる分類器，パラメータ選択肢\n",
    "# オプションとして，cvはk分割交差検定の回数（つまり，k）\n",
    "# オプションとして，n_jobsは並列スレッド数\n",
    "from multiprocessing import cpu_count\n",
    "job = cpu_count() -1\n",
    "svm_cv = GridSearchCV(SVC(probability=True, decision_function_shape=\"ovr\"), param_svm, cv=10, n_jobs=job)\n",
    "\n",
    "# 交差検定を用いたグリッドサーチを行う\n",
    "# 引数に，特徴量と正解データ\n",
    "svm_cv.fit(iris.data, iris.target)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(svm_cv.cv_results_)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.98\n",
      "best param: {'kernel': 'linear', 'C': 10}\n",
      "best score's index: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %svm_cv.best_estimator_)\n",
    "print(\"best socre: %s\" %svm_cv.best_score_)\n",
    "print(\"best param: %s\" %svm_cv.best_params_)\n",
    "print(\"best score's index: %s\" %svm_cv.best_index_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 得られた最良パラメータでもう一度学習してF値を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  1 24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.96      0.96      0.96        25\n",
      "  virginica       0.96      0.96      0.96        25\n",
      "\n",
      "avg / total       0.97      0.97      0.97        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_best = SVC(C=10, kernel=\"linear\", probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "svm_best.fit(x_train, y_train)\n",
    "\n",
    "predict_best = svm_best.predict(x_test)\n",
    "matrix_best = confusion_matrix(y_test, predict_best)\n",
    "report_best = classification_report(y_test, predict_best, target_names=iris.target_names)\n",
    "\n",
    "print(predict_best)\n",
    "print(matrix_best)\n",
    "print(report_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ↑F値が0.93から0.97に上昇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN法でirisデータを分類してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.001294         0.002078         0.960000          1.000000   \n",
      "1       0.000680         0.001313         0.960000          1.000000   \n",
      "2       0.000709         0.001215         0.953333          0.978519   \n",
      "3       0.000733         0.001389         0.960000          1.000000   \n",
      "4       0.000610         0.001051         0.966667          0.960741   \n",
      "5       0.000796         0.001484         0.966667          1.000000   \n",
      "6       0.000711         0.001261         0.966667          0.963704   \n",
      "7       0.000690         0.001222         0.966667          1.000000   \n",
      "8       0.000617         0.001066         0.966667          0.968889   \n",
      "9       0.001273         0.001404         0.966667          1.000000   \n",
      "\n",
      "  param_n_neighbors param_weights                                     params  \\\n",
      "0                 1       uniform   {'weights': 'uniform', 'n_neighbors': 1}   \n",
      "1                 1      distance  {'weights': 'distance', 'n_neighbors': 1}   \n",
      "2                 2       uniform   {'weights': 'uniform', 'n_neighbors': 2}   \n",
      "3                 2      distance  {'weights': 'distance', 'n_neighbors': 2}   \n",
      "4                 3       uniform   {'weights': 'uniform', 'n_neighbors': 3}   \n",
      "5                 3      distance  {'weights': 'distance', 'n_neighbors': 3}   \n",
      "6                 4       uniform   {'weights': 'uniform', 'n_neighbors': 4}   \n",
      "7                 4      distance  {'weights': 'distance', 'n_neighbors': 4}   \n",
      "8                 5       uniform   {'weights': 'uniform', 'n_neighbors': 5}   \n",
      "9                 5      distance  {'weights': 'distance', 'n_neighbors': 5}   \n",
      "\n",
      "   rank_test_score  split0_test_score  split0_train_score       ...         \\\n",
      "0                7                1.0            1.000000       ...          \n",
      "1                7                1.0            1.000000       ...          \n",
      "2               10                1.0            0.970370       ...          \n",
      "3                7                1.0            1.000000       ...          \n",
      "4                1                1.0            0.955556       ...          \n",
      "5                1                1.0            1.000000       ...          \n",
      "6                1                1.0            0.955556       ...          \n",
      "7                1                1.0            1.000000       ...          \n",
      "8                1                1.0            0.962963       ...          \n",
      "9                1                1.0            1.000000       ...          \n",
      "\n",
      "   split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0           1.000000            1.000000                1.0   \n",
      "1           1.000000            1.000000                1.0   \n",
      "2           0.933333            0.977778                1.0   \n",
      "3           1.000000            1.000000                1.0   \n",
      "4           1.000000            0.955556                1.0   \n",
      "5           1.000000            1.000000                1.0   \n",
      "6           1.000000            0.962963                1.0   \n",
      "7           1.000000            1.000000                1.0   \n",
      "8           1.000000            0.962963                1.0   \n",
      "9           1.000000            1.000000                1.0   \n",
      "\n",
      "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0            1.000000                1.0            1.000000      0.000969   \n",
      "1            1.000000                1.0            1.000000      0.000142   \n",
      "2            0.977778                1.0            0.977778      0.000138   \n",
      "3            1.000000                1.0            1.000000      0.000146   \n",
      "4            0.955556                1.0            0.955556      0.000146   \n",
      "5            1.000000                1.0            1.000000      0.000030   \n",
      "6            0.955556                1.0            0.970370      0.000148   \n",
      "7            1.000000                1.0            1.000000      0.000166   \n",
      "8            0.962963                1.0            0.970370      0.000137   \n",
      "9            1.000000                1.0            1.000000      0.001772   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.001345        0.053333         0.000000  \n",
      "1        0.000227        0.053333         0.000000  \n",
      "2        0.000222        0.052068         0.005185  \n",
      "3        0.000245        0.053333         0.000000  \n",
      "4        0.000276        0.044721         0.007444  \n",
      "5        0.000109        0.044721         0.000000  \n",
      "6        0.000241        0.044721         0.006988  \n",
      "7        0.000289        0.044721         0.000000  \n",
      "8        0.000199        0.044721         0.007258  \n",
      "9        0.000437        0.044721         0.000000  \n",
      "\n",
      "[10 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_param = [\n",
    "    {'n_neighbors': [1, 2, 3, 4, 5],'weights': ['uniform', 'distance'], }\n",
    "]\n",
    "\n",
    "knn_cv = GridSearchCV(KNeighborsClassifier(), knn_param, cv=10, n_jobs=job)\n",
    "knn_cv.fit(iris.data, iris.target)\n",
    "\n",
    "df_knn = pd.DataFrame(knn_cv.cv_results_)\n",
    "print(df_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "best socre: 0.966666666667\n",
      "best param: {'weights': 'uniform', 'n_neighbors': 3}\n",
      "best score's index: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %knn_cv.best_estimator_)\n",
    "print(\"best socre: %s\" %knn_cv.best_score_)\n",
    "print(\"best param: %s\" %knn_cv.best_params_)\n",
    "print(\"best score's index: %s\" %knn_cv.best_index_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 23  2]\n",
      " [ 0  1 24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.96      0.92      0.94        25\n",
      "  virginica       0.92      0.96      0.94        25\n",
      "\n",
      "avg / total       0.96      0.96      0.96        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\")\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "predict_knn = knn.predict(x_test)\n",
    "matrix_knn = confusion_matrix(y_test, predict_knn)\n",
    "report_knn = classification_report(y_test, predict_knn, target_names=iris.target_names)\n",
    "\n",
    "print(predict_knn)\n",
    "print(matrix_knn)\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMでdigitsデータを分類してみる\n",
    "（おそらく）数字の手書き画像データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DESCR': \"Optical Recognition of Handwritten Digits Data Set\\n===================================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\nReferences\\n----------\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\", 'data': array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
      "       ..., \n",
      "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
      "       [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'images': array([[[  0.,   0.,   5., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,  15.,   5.,   0.],\n",
      "        [  0.,   3.,  15., ...,  11.,   8.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  11., ...,  12.,   7.,   0.],\n",
      "        [  0.,   2.,  14., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   6., ...,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,   5.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,   9.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,   6.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,  10.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,  14.,   0.,   0.],\n",
      "        [  0.,   0.,   8., ...,  16.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   9.,  16., ...,   0.,   0.,   0.],\n",
      "        [  0.,   3.,  13., ...,  11.,   5.,   0.],\n",
      "        [  0.,   0.,   0., ...,  16.,   9.,   0.]],\n",
      "\n",
      "       ..., \n",
      "       [[  0.,   0.,   1., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,   2.,   1.,   0.],\n",
      "        [  0.,   0.,  16., ...,  16.,   5.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,  16., ...,  15.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  16.,   0.,   0.],\n",
      "        [  0.,   0.,   2., ...,   6.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  14., ...,  15.,   1.,   0.],\n",
      "        [  0.,   4.,  16., ...,  16.,   7.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   0., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   4., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   5., ...,  12.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,  10., ...,   1.,   0.,   0.],\n",
      "        [  0.,   2.,  16., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  15.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  16., ...,  16.,   6.,   0.],\n",
      "        [  0.,   8.,  16., ...,  16.,   8.,   0.],\n",
      "        [  0.,   1.,   8., ...,  12.,   1.,   0.]]]), 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'target': array([0, 1, 2, ..., 8, 9, 8])}\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "print(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### とりあえず表示してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11576eb70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9l+8Q5/pEyhkXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113118b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11558f1d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwIHECBxIjMCBxAgcSIzAgcT+B4HUgSjOZJ3sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112791588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1156339b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4EBiBA4kRuBAYv8DcXyiwTBlA4QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115561550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11573b2e8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/Rfz76g6gKD+6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1156524a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11593c320>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACulJREFUeJzt3X+o3XUdx/HXy7vN69SU8geyO9piNtBAJ5fFWBhtGDNF\nI/pjA4UkuGAoWoFo//VP/wRmkAoyZ4ZTq+lAxBQzzQRbbnOZd3eTNZXdoU4RU1ftOvfuj/sdTLlx\nvnfn++u8fT7gsvvjcD/vw/bc93vPPef7cUQIQE4ntD0AgPoQOJAYgQOJETiQGIEDiRE4kBiBA4kR\nOJAYgQOJzanjm87ziTGsk+v41p8pnlPLX8+Mjnypuf/r/cpUY2tl9V8d1FQccq/b1fIvaFgn66te\nXce3/kwZOuOsxtb6zx0nNbbWvEteb2ytrLbEU6Vuxyk6kBiBA4kROJAYgQOJETiQGIEDiRE4kBiB\nA4mVCtz2Gtu7be+xfXPdQwGoRs/AbQ9Jul3SpZLOk7TO9nl1Dwagf2WO4Msl7YmIvRExJelBSVfW\nOxaAKpQJfIGkfcd8PFl8DkDHVfZiE9tjksYkaVjzq/q2APpQ5gi+X9LCYz4eKT73CRFxV0SMRsTo\nXJ1Y1XwA+lAm8BcknWt7se15ktZKeqTesQBUoecpekQctn2dpCckDUnaEBHjtU8GoG+lfgaPiMck\nPVbzLAAqxjPZgMQIHEiMwIHECBxIjMCBxAgcSIzAgcQIHEisub1xMGuvXruksbWmXj7S2FpLxM4m\nTeEIDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kVmZnkw22D9h+uYmBAFSnzBH815LW1DwH\ngBr0DDwinpX0bgOzAKgYP4MDibF1EZBYZUdwti4CuodTdCCxMr8me0DS85KW2p60/f36xwJQhTJ7\nk61rYhAA1eMUHUiMwIHECBxIjMCBxAgcSIzAgcQIHEiMwIHE2LpoFobOPqvR9a7+zlONrfXbe1Y3\nttbQ+UsbW6tpH4/vbnuET+AIDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYmUuurjQ\n9tO2d9oet31DE4MB6F+Z56IflvTjiNhu+1RJ22w/GRE7a54NQJ/K7E32RkRsL97/QNKEpAV1Dwag\nf7N6NZntRZKWSdoyw9fYugjomNIPstk+RdJDkm6MiPc//XW2LgK6p1TgtudqOu6NEfFwvSMBqEqZ\nR9Et6W5JExFxa/0jAahKmSP4SklXS1ple0fx9q2a5wJQgTJ7kz0nyQ3MAqBiPJMNSIzAgcQIHEiM\nwIHECBxIjMCBxAgcSIzAgcTYm2wWXr12SaPr3Xba5sbW+vMvTmpsrYkNo42tdcK/mv0nvuSHjS7X\nE0dwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCCxMhddHLb9N9t/L7Yu+mkTgwHoX5nn8R2S\ntCoiPiwun/yc7T9ExF9rng1An8pcdDEkfVh8OLd4izqHAlCNshsfDNneIemApCcjYsati2xvtb31\nIx2qek4Ax6FU4BHxcURcKGlE0nLbX5nhNmxdBHTMrB5Fj4j3JD0taU094wCoUplH0c+0fXrx/kmS\nLpG0q+7BAPSvzKPo50i61/aQpv9D+F1EPFrvWACqUOZR9Jc0vSc4gAHDM9mAxAgcSIzAgcQIHEiM\nwIHECBxIjMCBxAgcSGzgty5695oVja01MXZHY2tJ0vnPjzW21ojGG1vr1TXrG1vrgp//oLG1uogj\nOJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQWOnAi2ujv2ib67EBA2I2R/AbJE3UNQiA6pXd\n2WRE0mWSmnsSMYC+lT2C3ybpJklHapwFQMXKbHxwuaQDEbGtx+3YmwzomDJH8JWSrrD9mqQHJa2y\nfd+nb8TeZED39Aw8Im6JiJGIWCRpraQ/RcRVtU8GoG/8HhxIbFZXdImIZyQ9U8skACrHERxIjMCB\nxAgcSIzAgcQIHEiMwIHECBxIjMCBxAZ+66Lh95p7gdsrHx1sbC1JGl+xsbG1fvbS0sbWatKC+/c0\nut7Hja7WG0dwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCCxUs9kK66o+oGmn6hzOCJG6xwK\nQDVm81TVb0TEO7VNAqBynKIDiZUNPCT90fY222N1DgSgOmVP0b8WEfttnyXpSdu7IuLZY29QhD8m\nScOaX/GYAI5HqSN4ROwv/jwgabOk5TPchq2LgI4ps/ngybZPPfq+pG9KernuwQD0r8wp+tmSNts+\nevv7I+LxWqcCUImegUfEXkkXNDALgIrxazIgMQIHEiNwIDECBxIjcCAxAgcSI3AgMQIHEhv4rYvm\nb97S2FrXb17Z2FqSdOTryxpb6/bf/Kqxtc5/vrkXJI68Nd7YWl3EERxIjMCBxAgcSIzAgcQIHEiM\nwIHECBxIjMCBxAgcSKxU4LZPt73J9i7bE7ZX1D0YgP6VfarqLyU9HhHftT1P4sLnwCDoGbjt0yRd\nLOl7khQRU5Km6h0LQBXKnKIvlvS2pHtsv2h7fXF9dAAdVybwOZIuknRnRCyTdFDSzZ++ke0x21tt\nb/1IhyoeE8DxKBP4pKTJiDj6usxNmg7+E9i6COienoFHxJuS9tleWnxqtaSdtU4FoBJlH0W/XtLG\n4hH0vZKuqW8kAFUpFXhE7JA0WvMsACrGM9mAxAgcSIzAgcQIHEiMwIHECBxIjMCBxAgcSIzAgcQG\nfm+yzOa+8+/G1vry3OZeAfz5+05pbK3POo7gQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBi\nPQO3vdT2jmPe3rd9YxPDAehPz6eqRsRuSRdKku0hSfslba55LgAVmO0p+mpJ/4yI1+sYBkC1Zvti\nk7WSHpjpC7bHJI1J0jCbjwKdUPoIXmx6cIWk38/0dbYuArpnNqfol0raHhFv1TUMgGrNJvB1+j+n\n5wC6qVTgxX7gl0h6uN5xAFSp7N5kByV9oeZZAFSMZ7IBiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4\nkJgjovpvar8tabYvKT1D0juVD9MNWe8b96s9X4yIM3vdqJbAj4ftrREx2vYcdch637hf3ccpOpAY\ngQOJdSnwu9oeoEZZ7xv3q+M68zM4gOp16QgOoGKdCNz2Gtu7be+xfXPb81TB9kLbT9veaXvc9g1t\nz1Ql20O2X7T9aNuzVMn26bY32d5le8L2irZn6kfrp+jFtdZf0fQVYyYlvSBpXUTsbHWwPtk+R9I5\nEbHd9qmStkn69qDfr6Ns/0jSqKTPRcTlbc9TFdv3SvpLRKwvLjQ6PyLea3uu49WFI/hySXsiYm9E\nTEl6UNKVLc/Ut4h4IyK2F+9/IGlC0oJ2p6qG7RFJl0la3/YsVbJ9mqSLJd0tSRExNchxS90IfIGk\nfcd8PKkkIRxle5GkZZK2tDtJZW6TdJOkI20PUrHFkt6WdE/x48f64nqEA6sLgadm+xRJD0m6MSLe\nb3ueftm+XNKBiNjW9iw1mCPpIkl3RsQySQclDfRjQl0IfL+khcd8PFJ8buDZnqvpuDdGRJYr0q6U\ndIXt1zT949Qq2/e1O1JlJiVNRsTRM61Nmg5+YHUh8BcknWt7cfGgxlpJj7Q8U99sW9M/y01ExK1t\nz1OViLglIkYiYpGm/67+FBFXtTxWJSLiTUn7bC8tPrVa0kA/KDrbvckqFxGHbV8n6QlJQ5I2RMR4\ny2NVYaWkqyX9w/aO4nM/iYjHWpwJvV0vaWNxsNkr6ZqW5+lL678mA1CfLpyiA6gJgQOJETiQGIED\niRE4kBiBA4kROJAYgQOJ/Q/5To9+jLRiggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11574f400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115a369b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEruQnAHP/g0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11597c278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1159cb1d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11573bbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115c1d438>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1159eaac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115d207f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQGIEDiRG4EBiBA4k9l++F6rjLxcbNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115bf6160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115c4f9e8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115d30b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最良パラメータをチューニングして，その評価を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
      "0        0.426283         0.009931         0.961046          1.000000       1   \n",
      "1        0.442262         0.011539         0.961046          1.000000      10   \n",
      "2        0.396747         0.009436         0.961046          1.000000     100   \n",
      "3        0.403054         0.008936         0.961046          1.000000    1000   \n",
      "4        1.010304         0.022444         0.978854          0.998887       1   \n",
      "5        0.867185         0.026060         0.954925          0.981883       1   \n",
      "6        1.002598         0.022435         0.981080          1.000000      10   \n",
      "7        0.505829         0.014482         0.969393          0.997836      10   \n",
      "8        1.006637         0.019954         0.981080          1.000000     100   \n",
      "9        0.469150         0.013731         0.971619          1.000000     100   \n",
      "10       1.003917         0.020371         0.981080          1.000000    1000   \n",
      "11       0.476784         0.014056         0.971619          1.000000    1000   \n",
      "12       0.432606         0.010141         0.974958          1.000000       1   \n",
      "13       1.345833         0.024354         0.936004          0.963953       1   \n",
      "14       0.508310         0.011867         0.978854          1.000000       1   \n",
      "15       2.327781         0.036843         0.913745          0.947074       1   \n",
      "16       0.623019         0.011928         0.976071          1.000000       1   \n",
      "17       3.326377         0.040776         0.864775          0.893649       1   \n",
      "18       0.583483         0.010673         0.973289          1.000000       1   \n",
      "19       3.526036         0.040720         0.451308          0.469216       1   \n",
      "20       0.437538         0.010663         0.972176          1.000000      10   \n",
      "21       0.589629         0.015253         0.966611          0.992951      10   \n",
      "22       0.599988         0.014636         0.978854          1.000000      10   \n",
      "23       0.810899         0.018026         0.964385          0.990416      10   \n",
      "24       0.491833         0.009761         0.976071          1.000000      10   \n",
      "25       1.216943         0.022739         0.953812          0.982872      10   \n",
      "26       0.666809         0.010824         0.973289          1.000000      10   \n",
      "27       1.649639         0.024766         0.920423          0.957028      10   \n",
      "28       0.448619         0.010550         0.972176          1.000000     100   \n",
      "29       0.460759         0.011493         0.974958          1.000000     100   \n",
      "30       0.488419         0.011632         0.978854          1.000000     100   \n",
      "31       0.572919         0.012853         0.978297          0.999938     100   \n",
      "32       0.521301         0.011203         0.976071          1.000000     100   \n",
      "33       0.629896         0.012908         0.973289          0.998825     100   \n",
      "34       0.621316         0.011912         0.973289          1.000000     100   \n",
      "35       0.856527         0.013874         0.966055          0.994374     100   \n",
      "36       0.468053         0.011386         0.972176          1.000000    1000   \n",
      "37       0.580182         0.013993         0.972176          1.000000    1000   \n",
      "38       0.506363         0.010944         0.978854          1.000000    1000   \n",
      "39       0.535619         0.012800         0.978854          1.000000    1000   \n",
      "40       0.492273         0.010595         0.976071          1.000000    1000   \n",
      "41       0.640777         0.013478         0.976071          1.000000    1000   \n",
      "42       0.694779         0.011254         0.973289          1.000000    1000   \n",
      "43       0.597184         0.012169         0.974402          1.000000    1000   \n",
      "\n",
      "   param_degree param_gamma param_kernel  \\\n",
      "0           NaN         NaN       linear   \n",
      "1           NaN         NaN       linear   \n",
      "2           NaN         NaN       linear   \n",
      "3           NaN         NaN       linear   \n",
      "4           NaN       0.001          rbf   \n",
      "5           NaN      0.0001          rbf   \n",
      "6           NaN       0.001          rbf   \n",
      "7           NaN      0.0001          rbf   \n",
      "8           NaN       0.001          rbf   \n",
      "9           NaN      0.0001          rbf   \n",
      "10          NaN       0.001          rbf   \n",
      "11          NaN      0.0001          rbf   \n",
      "12            2       0.001         poly   \n",
      "13            2      0.0001         poly   \n",
      "14            3       0.001         poly   \n",
      "15            3      0.0001         poly   \n",
      "16            4       0.001         poly   \n",
      "17            4      0.0001         poly   \n",
      "18            5       0.001         poly   \n",
      "19            5      0.0001         poly   \n",
      "20            2       0.001         poly   \n",
      "21            2      0.0001         poly   \n",
      "22            3       0.001         poly   \n",
      "23            3      0.0001         poly   \n",
      "24            4       0.001         poly   \n",
      "25            4      0.0001         poly   \n",
      "26            5       0.001         poly   \n",
      "27            5      0.0001         poly   \n",
      "28            2       0.001         poly   \n",
      "29            2      0.0001         poly   \n",
      "30            3       0.001         poly   \n",
      "31            3      0.0001         poly   \n",
      "32            4       0.001         poly   \n",
      "33            4      0.0001         poly   \n",
      "34            5       0.001         poly   \n",
      "35            5      0.0001         poly   \n",
      "36            2       0.001         poly   \n",
      "37            2      0.0001         poly   \n",
      "38            3       0.001         poly   \n",
      "39            3      0.0001         poly   \n",
      "40            4       0.001         poly   \n",
      "41            4      0.0001         poly   \n",
      "42            5       0.001         poly   \n",
      "43            5      0.0001         poly   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0                        {'kernel': 'linear', 'C': 1}               34   \n",
      "1                       {'kernel': 'linear', 'C': 10}               34   \n",
      "2                      {'kernel': 'linear', 'C': 100}               34   \n",
      "3                     {'kernel': 'linear', 'C': 1000}               34   \n",
      "4           {'kernel': 'rbf', 'gamma': 0.001, 'C': 1}                4   \n",
      "5          {'kernel': 'rbf', 'gamma': 0.0001, 'C': 1}               38   \n",
      "6          {'kernel': 'rbf', 'gamma': 0.001, 'C': 10}                1   \n",
      "7         {'kernel': 'rbf', 'gamma': 0.0001, 'C': 10}               30   \n",
      "8         {'kernel': 'rbf', 'gamma': 0.001, 'C': 100}                1   \n",
      "9        {'kernel': 'rbf', 'gamma': 0.0001, 'C': 100}               28   \n",
      "10       {'kernel': 'rbf', 'gamma': 0.001, 'C': 1000}                1   \n",
      "11      {'kernel': 'rbf', 'gamma': 0.0001, 'C': 1000}               28   \n",
      "12  {'degree': 2, 'kernel': 'poly', 'gamma': 0.001...               16   \n",
      "13  {'degree': 2, 'kernel': 'poly', 'gamma': 0.000...               40   \n",
      "14  {'degree': 3, 'kernel': 'poly', 'gamma': 0.001...                4   \n",
      "15  {'degree': 3, 'kernel': 'poly', 'gamma': 0.000...               42   \n",
      "16  {'degree': 4, 'kernel': 'poly', 'gamma': 0.001...               11   \n",
      "17  {'degree': 4, 'kernel': 'poly', 'gamma': 0.000...               43   \n",
      "18  {'degree': 5, 'kernel': 'poly', 'gamma': 0.001...               19   \n",
      "19  {'degree': 5, 'kernel': 'poly', 'gamma': 0.000...               44   \n",
      "20  {'degree': 2, 'kernel': 'poly', 'gamma': 0.001...               24   \n",
      "21  {'degree': 2, 'kernel': 'poly', 'gamma': 0.000...               31   \n",
      "22  {'degree': 3, 'kernel': 'poly', 'gamma': 0.001...                4   \n",
      "23  {'degree': 3, 'kernel': 'poly', 'gamma': 0.000...               33   \n",
      "24  {'degree': 4, 'kernel': 'poly', 'gamma': 0.001...               11   \n",
      "25  {'degree': 4, 'kernel': 'poly', 'gamma': 0.000...               39   \n",
      "26  {'degree': 5, 'kernel': 'poly', 'gamma': 0.001...               19   \n",
      "27  {'degree': 5, 'kernel': 'poly', 'gamma': 0.000...               41   \n",
      "28  {'degree': 2, 'kernel': 'poly', 'gamma': 0.001...               24   \n",
      "29  {'degree': 2, 'kernel': 'poly', 'gamma': 0.000...               16   \n",
      "30  {'degree': 3, 'kernel': 'poly', 'gamma': 0.001...                4   \n",
      "31  {'degree': 3, 'kernel': 'poly', 'gamma': 0.000...               10   \n",
      "32  {'degree': 4, 'kernel': 'poly', 'gamma': 0.001...               11   \n",
      "33  {'degree': 4, 'kernel': 'poly', 'gamma': 0.000...               19   \n",
      "34  {'degree': 5, 'kernel': 'poly', 'gamma': 0.001...               19   \n",
      "35  {'degree': 5, 'kernel': 'poly', 'gamma': 0.000...               32   \n",
      "36  {'degree': 2, 'kernel': 'poly', 'gamma': 0.001...               24   \n",
      "37  {'degree': 2, 'kernel': 'poly', 'gamma': 0.000...               24   \n",
      "38  {'degree': 3, 'kernel': 'poly', 'gamma': 0.001...                4   \n",
      "39  {'degree': 3, 'kernel': 'poly', 'gamma': 0.000...                4   \n",
      "40  {'degree': 4, 'kernel': 'poly', 'gamma': 0.001...               11   \n",
      "41  {'degree': 4, 'kernel': 'poly', 'gamma': 0.000...               11   \n",
      "42  {'degree': 5, 'kernel': 'poly', 'gamma': 0.001...               19   \n",
      "43  {'degree': 5, 'kernel': 'poly', 'gamma': 0.000...               18   \n",
      "\n",
      "         ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0        ...                  0.977528            1.000000           0.932203   \n",
      "1        ...                  0.977528            1.000000           0.932203   \n",
      "2        ...                  0.977528            1.000000           0.932203   \n",
      "3        ...                  0.977528            1.000000           0.932203   \n",
      "4        ...                  0.994382            0.998765           0.966102   \n",
      "5        ...                  0.988764            0.982088           0.898305   \n",
      "6        ...                  0.994382            1.000000           0.971751   \n",
      "7        ...                  0.994382            0.996912           0.937853   \n",
      "8        ...                  0.994382            1.000000           0.971751   \n",
      "9        ...                  0.994382            1.000000           0.949153   \n",
      "10       ...                  0.994382            1.000000           0.971751   \n",
      "11       ...                  0.994382            1.000000           0.949153   \n",
      "12       ...                  0.994382            1.000000           0.949153   \n",
      "13       ...                  0.971910            0.959234           0.875706   \n",
      "14       ...                  0.994382            1.000000           0.960452   \n",
      "15       ...                  0.932584            0.945028           0.853107   \n",
      "16       ...                  0.994382            1.000000           0.954802   \n",
      "17       ...                  0.887640            0.890056           0.785311   \n",
      "18       ...                  0.983146            1.000000           0.954802   \n",
      "19       ...                  0.393258            0.448425           0.389831   \n",
      "20       ...                  0.994382            1.000000           0.949153   \n",
      "21       ...                  0.994382            0.992588           0.937853   \n",
      "22       ...                  0.994382            1.000000           0.960452   \n",
      "23       ...                  0.994382            0.989500           0.926554   \n",
      "24       ...                  0.994382            1.000000           0.954802   \n",
      "25       ...                  0.983146            0.982088           0.909605   \n",
      "26       ...                  0.983146            1.000000           0.954802   \n",
      "27       ...                  0.932584            0.957999           0.875706   \n",
      "28       ...                  0.994382            1.000000           0.949153   \n",
      "29       ...                  0.994382            1.000000           0.949153   \n",
      "30       ...                  0.994382            1.000000           0.960452   \n",
      "31       ...                  0.994382            1.000000           0.960452   \n",
      "32       ...                  0.994382            1.000000           0.954802   \n",
      "33       ...                  0.994382            0.998765           0.937853   \n",
      "34       ...                  0.983146            1.000000           0.954802   \n",
      "35       ...                  1.000000            0.994441           0.937853   \n",
      "36       ...                  0.994382            1.000000           0.949153   \n",
      "37       ...                  0.994382            1.000000           0.949153   \n",
      "38       ...                  0.994382            1.000000           0.960452   \n",
      "39       ...                  0.994382            1.000000           0.960452   \n",
      "40       ...                  0.994382            1.000000           0.954802   \n",
      "41       ...                  0.994382            1.000000           0.954802   \n",
      "42       ...                  0.983146            1.000000           0.954802   \n",
      "43       ...                  0.988764            1.000000           0.954802   \n",
      "\n",
      "    split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0             1.000000           0.965909            1.000000      0.028726   \n",
      "1             1.000000           0.965909            1.000000      0.047486   \n",
      "2             1.000000           0.965909            1.000000      0.020498   \n",
      "3             1.000000           0.965909            1.000000      0.026252   \n",
      "4             0.998765           0.965909            0.999383      0.042013   \n",
      "5             0.980864           0.931818            0.983344      0.029053   \n",
      "6             1.000000           0.965909            1.000000      0.024839   \n",
      "7             0.997531           0.965909            0.998149      0.017349   \n",
      "8             1.000000           0.965909            1.000000      0.033947   \n",
      "9             1.000000           0.965909            1.000000      0.023999   \n",
      "10            1.000000           0.965909            1.000000      0.031878   \n",
      "11            1.000000           0.965909            1.000000      0.024019   \n",
      "12            1.000000           0.965909            1.000000      0.016645   \n",
      "13            0.966049           0.914773            0.965453      0.117034   \n",
      "14            1.000000           0.965909            1.000000      0.020786   \n",
      "15            0.952469           0.914773            0.943862      0.182470   \n",
      "16            1.000000           0.965909            1.000000      0.116814   \n",
      "17            0.900617           0.886364            0.895743      0.192102   \n",
      "18            1.000000           0.965909            1.000000      0.039936   \n",
      "19            0.490123           0.545455            0.479334      0.298209   \n",
      "20            1.000000           0.965909            1.000000      0.024381   \n",
      "21            0.993827           0.954545            0.993214      0.046843   \n",
      "22            1.000000           0.965909            1.000000      0.076081   \n",
      "23            0.992593           0.954545            0.991363      0.153537   \n",
      "24            1.000000           0.965909            1.000000      0.031248   \n",
      "25            0.985185           0.943182            0.982110      0.232195   \n",
      "26            1.000000           0.965909            1.000000      0.098317   \n",
      "27            0.963580           0.909091            0.951265      0.061297   \n",
      "28            1.000000           0.965909            1.000000      0.027609   \n",
      "29            1.000000           0.965909            1.000000      0.017405   \n",
      "30            1.000000           0.965909            1.000000      0.020575   \n",
      "31            1.000000           0.965909            1.000000      0.075934   \n",
      "32            1.000000           0.965909            1.000000      0.043149   \n",
      "33            0.998148           0.960227            1.000000      0.055029   \n",
      "34            1.000000           0.965909            1.000000      0.100479   \n",
      "35            0.996296           0.960227            0.993831      0.161487   \n",
      "36            1.000000           0.965909            1.000000      0.017436   \n",
      "37            1.000000           0.965909            1.000000      0.051337   \n",
      "38            1.000000           0.965909            1.000000      0.024186   \n",
      "39            1.000000           0.965909            1.000000      0.036852   \n",
      "40            1.000000           0.965909            1.000000      0.013913   \n",
      "41            1.000000           0.965909            1.000000      0.116200   \n",
      "42            1.000000           0.965909            1.000000      0.113724   \n",
      "43            1.000000           0.965909            1.000000      0.088420   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.001688        0.021980         0.000000  \n",
      "1         0.005519        0.021980         0.000000  \n",
      "2         0.001507        0.021980         0.000000  \n",
      "3         0.001441        0.021980         0.000000  \n",
      "4         0.002577        0.017952         0.000247  \n",
      "5         0.003488        0.027588         0.001387  \n",
      "6         0.004418        0.015540         0.000000  \n",
      "7         0.002307        0.025213         0.000568  \n",
      "8         0.004443        0.015540         0.000000  \n",
      "9         0.002320        0.020497         0.000000  \n",
      "10        0.003371        0.015540         0.000000  \n",
      "11        0.002439        0.020497         0.000000  \n",
      "12        0.002127        0.021610         0.000000  \n",
      "13        0.002765        0.031711         0.001988  \n",
      "14        0.002369        0.019347         0.000000  \n",
      "15        0.012986        0.031604         0.002627  \n",
      "16        0.001202        0.020023         0.000000  \n",
      "17        0.007934        0.036656         0.004636  \n",
      "18        0.001815        0.019145         0.000000  \n",
      "19        0.006187        0.059380         0.024371  \n",
      "20        0.002182        0.020555         0.000000  \n",
      "21        0.002603        0.022883         0.001304  \n",
      "22        0.003583        0.019347         0.000000  \n",
      "23        0.003798        0.024129         0.001183  \n",
      "24        0.002322        0.020023         0.000000  \n",
      "25        0.006685        0.023615         0.001040  \n",
      "26        0.001587        0.019145         0.000000  \n",
      "27        0.003619        0.025802         0.003813  \n",
      "28        0.001447        0.020555         0.000000  \n",
      "29        0.001615        0.021610         0.000000  \n",
      "30        0.001251        0.019347         0.000000  \n",
      "31        0.004625        0.019130         0.000186  \n",
      "32        0.001431        0.020023         0.000000  \n",
      "33        0.001739        0.022923         0.000513  \n",
      "34        0.004172        0.019145         0.000000  \n",
      "35        0.003826        0.022772         0.001085  \n",
      "36        0.002078        0.020555         0.000000  \n",
      "37        0.004606        0.020555         0.000000  \n",
      "38        0.001981        0.019347         0.000000  \n",
      "39        0.003636        0.019347         0.000000  \n",
      "40        0.001363        0.020023         0.000000  \n",
      "41        0.003975        0.020023         0.000000  \n",
      "42        0.002468        0.019145         0.000000  \n",
      "43        0.005656        0.019523         0.000000  \n",
      "\n",
      "[44 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "digits_cv = GridSearchCV(SVC(probability=True, decision_function_shape=\"ovr\"), param_svm, cv=10, n_jobs=job)\n",
    "digits_cv.fit(digits.data, digits.target)\n",
    "\n",
    "df_digits = pd.DataFrame(digits_cv.cv_results_)\n",
    "print(df_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.981079577073\n",
      "best param: {'kernel': 'rbf', 'gamma': 0.001, 'C': 10}\n",
      "best score's index: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %digits_cv.best_estimator_)\n",
    "print(\"best socre: %s\" %digits_cv.best_score_)\n",
    "print(\"best param: %s\" %digits_cv.best_params_)\n",
    "print(\"best score's index: %s\" %digits_cv.best_index_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最良パラメータに基づいて分類器を作成してF値で評価する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 9 7 9 1 3 5 7 9 1 3 5 7 9 9 5 5 5 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 7 5 9\n",
      " 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 1 1 3 5 7 9 1 3 5 7\n",
      " 9 1 3 5 7 9 9 5 5 9 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 3 3 1\n",
      " 6 4 1 0 3 9 1 5 4 2 2 5 4 8 9 8 8 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 9 5 5 9 9\n",
      " 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2\n",
      " 2 5 9 4 8 9 8 3 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 9 5 9 9 9 4 7 3 1 0 2 8 0 2\n",
      " 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 8 1\n",
      " 3 5 7 9 1 3 5 7 9 1 3 5 7 9 8 5 5 9 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2\n",
      " 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 8 1 3 5 7 9 1 3 5 7 9\n",
      " 1 3 5 7 9 9 5 5 9 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1\n",
      " 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 8 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 9 5 5 9\n",
      " 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4\n",
      " 2 2 5 9 4 8 9 8 8 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7 5 2 8 0 2 3\n",
      " 7 3 6 6 9 5 9 2 2 0 7 3 1 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7 5 4 0 9 0 2 4 6\n",
      " 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7 5 0 7 2 1 6 3 3 4 6 4 1 0 5 8 0 1 6\n",
      " 2 7 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7 5 8 4 0 9 0 2 4 6 8 0 2 4 6 8 0 2 4 6\n",
      " 8 0 5 6 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4 6 4 1 0 5 8 0 1 6 2 7 6 1 9 7 8 3 4\n",
      " 5 6 6 7 4 7 8 2 7 5 8 4 0 9 0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7\n",
      " 5 0 2 7 2 1 6 3 3 4 6 4 1 0 6 8 0 1 6 2 7 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7\n",
      " 5 8 4 0 0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4\n",
      " 6 4 1 0 5 8 0 1 6 2 7 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7 5 8 4 0 9 0 2 4 6 1\n",
      " 0 2 4 6 0 2 4 6 8 4 9 6 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4 6 4 1 0 5 8 1 6 2 7\n",
      " 6 1 9 7 8 3 4 5 6 6 7 4 7 2 7 5 4 0 9 0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6\n",
      " 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4 6 4 1 0 5 8 0 1 6 2 7 6 1 9 7 8 3 4 5 6 6 7\n",
      " 4 7 8 2 7 5 8 4 0 9]\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 89  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 91  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 93  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 87  1  0  0  3]\n",
      " [ 0  0  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 91  0  0]\n",
      " [ 0  2  0  0  0  0  0  0 84  0]\n",
      " [ 0  0  0  0  0  1  0  1  1 88]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.98      1.00      0.99        89\n",
      "          2       1.00      1.00      1.00        91\n",
      "          3       1.00      1.00      1.00        93\n",
      "          4       0.99      1.00      0.99        88\n",
      "          5       0.99      0.96      0.97        91\n",
      "          6       0.99      1.00      0.99        90\n",
      "          7       0.99      1.00      0.99        91\n",
      "          8       0.99      0.98      0.98        86\n",
      "          9       0.97      0.97      0.97        91\n",
      "\n",
      "avg / total       0.99      0.99      0.99       898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_digits = SVC(C=10, kernel=\"rbf\", gamma=0.001, probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "\n",
    "xd_train = digits.data[range(0, len(digits.data), 2)]\n",
    "yd_train = digits.target[range(0, len(digits.data), 2)]\n",
    "\n",
    "xd_test = digits.data[range(1, len(digits.data), 2)]\n",
    "yd_test = digits.target[range(1, len(digits.data), 2)]\n",
    "\n",
    "svm_digits.fit(xd_train, yd_train)\n",
    "\n",
    "predict_digits = svm_digits.predict(xd_test)\n",
    "matrix_digits = confusion_matrix(yd_test, predict_digits)\n",
    "report_digits = classification_report(yd_test, predict_digits)\n",
    "\n",
    "print(predict_digits)\n",
    "print(matrix_digits)\n",
    "print(report_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
