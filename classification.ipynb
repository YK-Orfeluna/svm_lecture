{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythonを使った機械学習：Classification（分類）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習（Machine Learning）とは？\n",
    "与えられたデータ群から規則性を見つけ出して，人間の学習能力をコンピュータ上で再現すること\n",
    "\n",
    "## 教師あり学習\n",
    "人間が正解データ（教師データ）を事前に与えて，それに基づいて学習を行う手法．<br>\n",
    "Classification（分類）やRegresion（回帰）など\n",
    "\n",
    "### Classification: Suport Vector Machine（SVM）\n",
    "複数のデータ群を分類する境界線を作り出すことで，与えられたデータがどの分類に属するのかがわかる<br>\n",
    "境界線の引き方にも色々と種類がある<br>\n",
    "![](./images/svms.png) <br>\n",
    "http://scikit-learn.org/stable/auto_examples/exercises/plot_iris_exercise.html\n",
    "\n",
    "### Classification: K-Nearest Neighbor Algorithm(KNN法）\n",
    "教師データ上に与えられたデータを配置した時，教師データに近いk個のデータの割合で与えられたデータの割合を決める<br>\n",
    "![](./images/knn.png)\n",
    "\n",
    "## 教師なし学習\n",
    "人間から正解データを付与されず，アルゴリズムによってコンピュータが答え（分類）を計算する手法<br>\n",
    "Clustering（クラスタリング）など\n",
    "\n",
    "## 半教師あり学習\n",
    "教師ありとなしのいいとこ取りみたいな感じ\n",
    "\n",
    "# ここでは，Classificationを扱う\n",
    "\n",
    "# 特徴量（Features）とは？\n",
    "分類のためには特徴量が必要<br>\n",
    "特徴量＝コンピュータが理解できるデータ上の違い<br>\n",
    "この違いが分類の決めてになる\n",
    "\n",
    "## Irisデータ\n",
    "有名なデータセットの一つで，あやめ（Iris）の花の萼片（Sepal）と花びら（Petal）の長さ（Length）と幅（Width）が三種類分（Setosa・Versicolour・Virginica）格納されている<br>\n",
    "![](./images/iris.jpg)\n",
    "<br>\n",
    "データの種類は次元と言われる<br>\n",
    "つまり，Irisデータの場合四種類のデータなので，「四次元」のデータということになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learnとは？\n",
    "![Scikit-Learn ロゴマーク](http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png)\n",
    "Pythonで提供されている機械学習のライブラリ<br>\n",
    "http://scikit-learn.org/stable/index.html\n",
    "<br>\n",
    "importするときは，sklearnとして扱われる<br>\n",
    "anacondaに標準インストールされている<br>\n",
    "<br>\n",
    "anacondaを使っていない場合は\n",
    "* pip install scikit-learn\n",
    "\n",
    "<br>で導入可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# では，実際にやってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
      "       [ 4.9,  3. ,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.3,  0.2],\n",
      "       [ 4.6,  3.1,  1.5,  0.2],\n",
      "       [ 5. ,  3.6,  1.4,  0.2],\n",
      "       [ 5.4,  3.9,  1.7,  0.4],\n",
      "       [ 4.6,  3.4,  1.4,  0.3],\n",
      "       [ 5. ,  3.4,  1.5,  0.2],\n",
      "       [ 4.4,  2.9,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5.4,  3.7,  1.5,  0.2],\n",
      "       [ 4.8,  3.4,  1.6,  0.2],\n",
      "       [ 4.8,  3. ,  1.4,  0.1],\n",
      "       [ 4.3,  3. ,  1.1,  0.1],\n",
      "       [ 5.8,  4. ,  1.2,  0.2],\n",
      "       [ 5.7,  4.4,  1.5,  0.4],\n",
      "       [ 5.4,  3.9,  1.3,  0.4],\n",
      "       [ 5.1,  3.5,  1.4,  0.3],\n",
      "       [ 5.7,  3.8,  1.7,  0.3],\n",
      "       [ 5.1,  3.8,  1.5,  0.3],\n",
      "       [ 5.4,  3.4,  1.7,  0.2],\n",
      "       [ 5.1,  3.7,  1.5,  0.4],\n",
      "       [ 4.6,  3.6,  1. ,  0.2],\n",
      "       [ 5.1,  3.3,  1.7,  0.5],\n",
      "       [ 4.8,  3.4,  1.9,  0.2],\n",
      "       [ 5. ,  3. ,  1.6,  0.2],\n",
      "       [ 5. ,  3.4,  1.6,  0.4],\n",
      "       [ 5.2,  3.5,  1.5,  0.2],\n",
      "       [ 5.2,  3.4,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.6,  0.2],\n",
      "       [ 4.8,  3.1,  1.6,  0.2],\n",
      "       [ 5.4,  3.4,  1.5,  0.4],\n",
      "       [ 5.2,  4.1,  1.5,  0.1],\n",
      "       [ 5.5,  4.2,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5. ,  3.2,  1.2,  0.2],\n",
      "       [ 5.5,  3.5,  1.3,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 4.4,  3. ,  1.3,  0.2],\n",
      "       [ 5.1,  3.4,  1.5,  0.2],\n",
      "       [ 5. ,  3.5,  1.3,  0.3],\n",
      "       [ 4.5,  2.3,  1.3,  0.3],\n",
      "       [ 4.4,  3.2,  1.3,  0.2],\n",
      "       [ 5. ,  3.5,  1.6,  0.6],\n",
      "       [ 5.1,  3.8,  1.9,  0.4],\n",
      "       [ 4.8,  3. ,  1.4,  0.3],\n",
      "       [ 5.1,  3.8,  1.6,  0.2],\n",
      "       [ 4.6,  3.2,  1.4,  0.2],\n",
      "       [ 5.3,  3.7,  1.5,  0.2],\n",
      "       [ 5. ,  3.3,  1.4,  0.2],\n",
      "       [ 7. ,  3.2,  4.7,  1.4],\n",
      "       [ 6.4,  3.2,  4.5,  1.5],\n",
      "       [ 6.9,  3.1,  4.9,  1.5],\n",
      "       [ 5.5,  2.3,  4. ,  1.3],\n",
      "       [ 6.5,  2.8,  4.6,  1.5],\n",
      "       [ 5.7,  2.8,  4.5,  1.3],\n",
      "       [ 6.3,  3.3,  4.7,  1.6],\n",
      "       [ 4.9,  2.4,  3.3,  1. ],\n",
      "       [ 6.6,  2.9,  4.6,  1.3],\n",
      "       [ 5.2,  2.7,  3.9,  1.4],\n",
      "       [ 5. ,  2. ,  3.5,  1. ],\n",
      "       [ 5.9,  3. ,  4.2,  1.5],\n",
      "       [ 6. ,  2.2,  4. ,  1. ],\n",
      "       [ 6.1,  2.9,  4.7,  1.4],\n",
      "       [ 5.6,  2.9,  3.6,  1.3],\n",
      "       [ 6.7,  3.1,  4.4,  1.4],\n",
      "       [ 5.6,  3. ,  4.5,  1.5],\n",
      "       [ 5.8,  2.7,  4.1,  1. ],\n",
      "       [ 6.2,  2.2,  4.5,  1.5],\n",
      "       [ 5.6,  2.5,  3.9,  1.1],\n",
      "       [ 5.9,  3.2,  4.8,  1.8],\n",
      "       [ 6.1,  2.8,  4. ,  1.3],\n",
      "       [ 6.3,  2.5,  4.9,  1.5],\n",
      "       [ 6.1,  2.8,  4.7,  1.2],\n",
      "       [ 6.4,  2.9,  4.3,  1.3],\n",
      "       [ 6.6,  3. ,  4.4,  1.4],\n",
      "       [ 6.8,  2.8,  4.8,  1.4],\n",
      "       [ 6.7,  3. ,  5. ,  1.7],\n",
      "       [ 6. ,  2.9,  4.5,  1.5],\n",
      "       [ 5.7,  2.6,  3.5,  1. ],\n",
      "       [ 5.5,  2.4,  3.8,  1.1],\n",
      "       [ 5.5,  2.4,  3.7,  1. ],\n",
      "       [ 5.8,  2.7,  3.9,  1.2],\n",
      "       [ 6. ,  2.7,  5.1,  1.6],\n",
      "       [ 5.4,  3. ,  4.5,  1.5],\n",
      "       [ 6. ,  3.4,  4.5,  1.6],\n",
      "       [ 6.7,  3.1,  4.7,  1.5],\n",
      "       [ 6.3,  2.3,  4.4,  1.3],\n",
      "       [ 5.6,  3. ,  4.1,  1.3],\n",
      "       [ 5.5,  2.5,  4. ,  1.3],\n",
      "       [ 5.5,  2.6,  4.4,  1.2],\n",
      "       [ 6.1,  3. ,  4.6,  1.4],\n",
      "       [ 5.8,  2.6,  4. ,  1.2],\n",
      "       [ 5. ,  2.3,  3.3,  1. ],\n",
      "       [ 5.6,  2.7,  4.2,  1.3],\n",
      "       [ 5.7,  3. ,  4.2,  1.2],\n",
      "       [ 5.7,  2.9,  4.2,  1.3],\n",
      "       [ 6.2,  2.9,  4.3,  1.3],\n",
      "       [ 5.1,  2.5,  3. ,  1.1],\n",
      "       [ 5.7,  2.8,  4.1,  1.3],\n",
      "       [ 6.3,  3.3,  6. ,  2.5],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 7.1,  3. ,  5.9,  2.1],\n",
      "       [ 6.3,  2.9,  5.6,  1.8],\n",
      "       [ 6.5,  3. ,  5.8,  2.2],\n",
      "       [ 7.6,  3. ,  6.6,  2.1],\n",
      "       [ 4.9,  2.5,  4.5,  1.7],\n",
      "       [ 7.3,  2.9,  6.3,  1.8],\n",
      "       [ 6.7,  2.5,  5.8,  1.8],\n",
      "       [ 7.2,  3.6,  6.1,  2.5],\n",
      "       [ 6.5,  3.2,  5.1,  2. ],\n",
      "       [ 6.4,  2.7,  5.3,  1.9],\n",
      "       [ 6.8,  3. ,  5.5,  2.1],\n",
      "       [ 5.7,  2.5,  5. ,  2. ],\n",
      "       [ 5.8,  2.8,  5.1,  2.4],\n",
      "       [ 6.4,  3.2,  5.3,  2.3],\n",
      "       [ 6.5,  3. ,  5.5,  1.8],\n",
      "       [ 7.7,  3.8,  6.7,  2.2],\n",
      "       [ 7.7,  2.6,  6.9,  2.3],\n",
      "       [ 6. ,  2.2,  5. ,  1.5],\n",
      "       [ 6.9,  3.2,  5.7,  2.3],\n",
      "       [ 5.6,  2.8,  4.9,  2. ],\n",
      "       [ 7.7,  2.8,  6.7,  2. ],\n",
      "       [ 6.3,  2.7,  4.9,  1.8],\n",
      "       [ 6.7,  3.3,  5.7,  2.1],\n",
      "       [ 7.2,  3.2,  6. ,  1.8],\n",
      "       [ 6.2,  2.8,  4.8,  1.8],\n",
      "       [ 6.1,  3. ,  4.9,  1.8],\n",
      "       [ 6.4,  2.8,  5.6,  2.1],\n",
      "       [ 7.2,  3. ,  5.8,  1.6],\n",
      "       [ 7.4,  2.8,  6.1,  1.9],\n",
      "       [ 7.9,  3.8,  6.4,  2. ],\n",
      "       [ 6.4,  2.8,  5.6,  2.2],\n",
      "       [ 6.3,  2.8,  5.1,  1.5],\n",
      "       [ 6.1,  2.6,  5.6,  1.4],\n",
      "       [ 7.7,  3. ,  6.1,  2.3],\n",
      "       [ 6.3,  3.4,  5.6,  2.4],\n",
      "       [ 6.4,  3.1,  5.5,  1.8],\n",
      "       [ 6. ,  3. ,  4.8,  1.8],\n",
      "       [ 6.9,  3.1,  5.4,  2.1],\n",
      "       [ 6.7,  3.1,  5.6,  2.4],\n",
      "       [ 6.9,  3.1,  5.1,  2.3],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 6.8,  3.2,  5.9,  2.3],\n",
      "       [ 6.7,  3.3,  5.7,  2.5],\n",
      "       [ 6.7,  3. ,  5.2,  2.3],\n",
      "       [ 6.3,  2.5,  5. ,  1.9],\n",
      "       [ 6.5,  3. ,  5.2,  2. ],\n",
      "       [ 6.2,  3.4,  5.4,  2.3],\n",
      "       [ 5.9,  3. ,  5.1,  1.8]]), 'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
      "      dtype='<U10'), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "#  irisデータを読み込む\n",
    "iris = datasets.load_iris()\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# irisデータを学習データとテストデータに分割する\n",
    "# データの奇数番目を学習データに，偶数番目をテストデータにする\n",
    "\n",
    "x_train = iris.data[range(0, len(iris.data), 2)]\n",
    "y_train = iris.target[range(0, len(iris.data), 2)]\n",
    "\n",
    "x_test = iris.data[range(1, len(iris.data), 2)]\n",
    "y_test = iris.target[range(1, len(iris.data), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': True,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#　学習の用意\n",
    "svm = SVC(probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "# 分類器の設定を確認する\n",
    "svm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習器に教師データを与えて学習させる\n",
    "# 引数は特徴量，教師データ（ラベル）\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "# 分類器にテストデータを分類させる\n",
    "predict = svm.predict(x_test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作成した分類器を評価する\n",
    "### 適合率（Precion）と再現率（Recall）とは？\n",
    "#### 適合率\n",
    "検索結果の中で，どの程度が正解に含まれるか\n",
    "#### 再現率\n",
    "正解の中で，どの程度が検索にヒットするのか\n",
    "![](http://cdn-ak.f.st-hatena.com/images/fotolife/Z/Zellij/20120214/20120214075315.png)\n",
    "<br>http://f.hatena.ne.jp/Zellij/20120214075315<br>\n",
    "\n",
    "# わからん！\n",
    "ということで，混合行列\n",
    "### 混合行列（Confusion Matrix）とは？\n",
    "テストデータがどのラベルにどれだけ分類されたかを表す行列<br>\n",
    "![](./images/cm1.png)<br>\n",
    "![](./images/cm2.png)<br>\n",
    "![](./images/cm3.png)<br>\n",
    "![](./images/cm4.png)<br>\n",
    "\n",
    "### F値（F-measure）とは？\n",
    "適合率と再現率は負の相関関係にあることが多い＝トレードオフの関係にある<br>\n",
    "ということで，分類器の制度を適合率と再現率の調和平均＝F値で評価する<br>\n",
    "$\n",
    "F-measure = \\displaystyle　\\frac{2\\dot precion \\times recall}{precion + recall}\n",
    "$<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  0,  0],\n",
       "       [ 0, 24,  1],\n",
       "       [ 0,  4, 21]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先ほどの分類器の混合行列を表示する\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 引数は，正解データと予測結果\n",
    "matrix = confusion_matrix(y_test, predict)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.86      0.96      0.91        25\n",
      "  virginica       0.95      0.84      0.89        25\n",
      "\n",
      "avg / total       0.94      0.93      0.93        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F値を計算する\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 引数は，正解データと予測結果\n",
    "# オプションとして，target_namesを利用可能\n",
    "report = classification_report(y_test, predict, target_names=iris.target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-分割交差検定（K-fold Cross-Validation）による分類器の検証\n",
    "データ数があまり多くなくて，学習データとテストデータにわけると数が足りない場合などに利用される\n",
    "![](./images/kfcv.png)\n",
    "\n",
    "### グリッドサーチとは？\n",
    "機械学習には，学習の際のパラメータが存在し，そのパラメータをチューニングして最良な分類器を作成する<br>\n",
    "以下では，k分割交差検定法とグリッドサーチが同時に実装されている関数を用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
      "0        0.003235         0.000795         0.973333          0.988148       1   \n",
      "1        0.002500         0.000582         0.980000          0.980000      10   \n",
      "2        0.003121         0.000449         0.973333          0.981481     100   \n",
      "3        0.013818         0.000492         0.980000          0.986667    1000   \n",
      "4        0.008527         0.000631         0.906667          0.921481       1   \n",
      "5        0.007739         0.000500         0.906667          0.921481       1   \n",
      "6        0.006816         0.001451         0.933333          0.945185      10   \n",
      "7        0.008251         0.000563         0.906667          0.921481      10   \n",
      "8        0.003693         0.000810         0.980000          0.979259     100   \n",
      "9        0.007258         0.000794         0.933333          0.945185     100   \n",
      "10       0.002858         0.000570         0.980000          0.980000    1000   \n",
      "11       0.006493         0.000791         0.980000          0.979259    1000   \n",
      "12       0.010302         0.001074         0.866667          0.865926       1   \n",
      "13       0.010076         0.000902         0.866667          0.865926       1   \n",
      "14       0.005584         0.000498         0.746667          0.748889       1   \n",
      "15       0.007534         0.000780         0.746667          0.748889       1   \n",
      "16       0.010575         0.000677         0.640000          0.642222       1   \n",
      "17       0.004879         0.000445         0.640000          0.642222       1   \n",
      "18       0.006218         0.001662         0.573333          0.576296       1   \n",
      "19       0.004990         0.000469         0.573333          0.576296       1   \n",
      "20       0.006043         0.000585         0.866667          0.865926      10   \n",
      "21       0.006092         0.000551         0.866667          0.865926      10   \n",
      "22       0.005238         0.000484         0.746667          0.748889      10   \n",
      "23       0.005828         0.000542         0.746667          0.748889      10   \n",
      "24       0.005450         0.000509         0.640000          0.642222      10   \n",
      "25       0.005938         0.000540         0.640000          0.642222      10   \n",
      "26       0.005040         0.000458         0.573333          0.576296      10   \n",
      "27       0.005947         0.000549         0.573333          0.576296      10   \n",
      "28       0.003641         0.000451         0.886667          0.898519     100   \n",
      "29       0.006148         0.000556         0.866667          0.865926     100   \n",
      "30       0.007115         0.000794         0.746667          0.748889     100   \n",
      "31       0.007591         0.000702         0.746667          0.748889     100   \n",
      "32       0.010643         0.001386         0.640000          0.642222     100   \n",
      "33       0.006259         0.000770         0.640000          0.642222     100   \n",
      "34       0.016422         0.000645         0.573333          0.576296     100   \n",
      "35       0.006913         0.000520         0.573333          0.576296     100   \n",
      "36       0.003403         0.000693         0.960000          0.961481    1000   \n",
      "37       0.008010         0.001069         0.866667          0.865926    1000   \n",
      "38       0.004394         0.000606         0.866667          0.871111    1000   \n",
      "39       0.005049         0.000470         0.746667          0.748889    1000   \n",
      "40       0.004182         0.000364         0.653333          0.656296    1000   \n",
      "41       0.003587         0.000321         0.640000          0.642222    1000   \n",
      "42       0.003790         0.000331         0.573333          0.576296    1000   \n",
      "43       0.003835         0.000343         0.573333          0.576296    1000   \n",
      "\n",
      "   param_degree param_gamma param_kernel  \\\n",
      "0           NaN         NaN       linear   \n",
      "1           NaN         NaN       linear   \n",
      "2           NaN         NaN       linear   \n",
      "3           NaN         NaN       linear   \n",
      "4           NaN       0.001          rbf   \n",
      "5           NaN      0.0001          rbf   \n",
      "6           NaN       0.001          rbf   \n",
      "7           NaN      0.0001          rbf   \n",
      "8           NaN       0.001          rbf   \n",
      "9           NaN      0.0001          rbf   \n",
      "10          NaN       0.001          rbf   \n",
      "11          NaN      0.0001          rbf   \n",
      "12            2       0.001         poly   \n",
      "13            2      0.0001         poly   \n",
      "14            3       0.001         poly   \n",
      "15            3      0.0001         poly   \n",
      "16            4       0.001         poly   \n",
      "17            4      0.0001         poly   \n",
      "18            5       0.001         poly   \n",
      "19            5      0.0001         poly   \n",
      "20            2       0.001         poly   \n",
      "21            2      0.0001         poly   \n",
      "22            3       0.001         poly   \n",
      "23            3      0.0001         poly   \n",
      "24            4       0.001         poly   \n",
      "25            4      0.0001         poly   \n",
      "26            5       0.001         poly   \n",
      "27            5      0.0001         poly   \n",
      "28            2       0.001         poly   \n",
      "29            2      0.0001         poly   \n",
      "30            3       0.001         poly   \n",
      "31            3      0.0001         poly   \n",
      "32            4       0.001         poly   \n",
      "33            4      0.0001         poly   \n",
      "34            5       0.001         poly   \n",
      "35            5      0.0001         poly   \n",
      "36            2       0.001         poly   \n",
      "37            2      0.0001         poly   \n",
      "38            3       0.001         poly   \n",
      "39            3      0.0001         poly   \n",
      "40            4       0.001         poly   \n",
      "41            4      0.0001         poly   \n",
      "42            5       0.001         poly   \n",
      "43            5      0.0001         poly   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0                        {'kernel': 'linear', 'C': 1}                6   \n",
      "1                       {'kernel': 'linear', 'C': 10}                1   \n",
      "2                      {'kernel': 'linear', 'C': 100}                6   \n",
      "3                     {'kernel': 'linear', 'C': 1000}                1   \n",
      "4           {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}               11   \n",
      "5          {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}               11   \n",
      "6          {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}                9   \n",
      "7         {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}               11   \n",
      "8         {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}                1   \n",
      "9        {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}                9   \n",
      "10       {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}                1   \n",
      "11      {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}                1   \n",
      "12  {'kernel': 'poly', 'gamma': 0.001, 'C': 1, 'de...               15   \n",
      "13  {'kernel': 'poly', 'gamma': 0.0001, 'C': 1, 'd...               15   \n",
      "14  {'kernel': 'poly', 'gamma': 0.001, 'C': 1, 'de...               22   \n",
      "15  {'kernel': 'poly', 'gamma': 0.0001, 'C': 1, 'd...               22   \n",
      "16  {'kernel': 'poly', 'gamma': 0.001, 'C': 1, 'de...               30   \n",
      "17  {'kernel': 'poly', 'gamma': 0.0001, 'C': 1, 'd...               30   \n",
      "18  {'kernel': 'poly', 'gamma': 0.001, 'C': 1, 'de...               37   \n",
      "19  {'kernel': 'poly', 'gamma': 0.0001, 'C': 1, 'd...               37   \n",
      "20  {'kernel': 'poly', 'gamma': 0.001, 'C': 10, 'd...               15   \n",
      "21  {'kernel': 'poly', 'gamma': 0.0001, 'C': 10, '...               15   \n",
      "22  {'kernel': 'poly', 'gamma': 0.001, 'C': 10, 'd...               22   \n",
      "23  {'kernel': 'poly', 'gamma': 0.0001, 'C': 10, '...               22   \n",
      "24  {'kernel': 'poly', 'gamma': 0.001, 'C': 10, 'd...               30   \n",
      "25  {'kernel': 'poly', 'gamma': 0.0001, 'C': 10, '...               30   \n",
      "26  {'kernel': 'poly', 'gamma': 0.001, 'C': 10, 'd...               37   \n",
      "27  {'kernel': 'poly', 'gamma': 0.0001, 'C': 10, '...               37   \n",
      "28  {'kernel': 'poly', 'gamma': 0.001, 'C': 100, '...               14   \n",
      "29  {'kernel': 'poly', 'gamma': 0.0001, 'C': 100, ...               15   \n",
      "30  {'kernel': 'poly', 'gamma': 0.001, 'C': 100, '...               22   \n",
      "31  {'kernel': 'poly', 'gamma': 0.0001, 'C': 100, ...               22   \n",
      "32  {'kernel': 'poly', 'gamma': 0.001, 'C': 100, '...               30   \n",
      "33  {'kernel': 'poly', 'gamma': 0.0001, 'C': 100, ...               30   \n",
      "34  {'kernel': 'poly', 'gamma': 0.001, 'C': 100, '...               37   \n",
      "35  {'kernel': 'poly', 'gamma': 0.0001, 'C': 100, ...               37   \n",
      "36  {'kernel': 'poly', 'gamma': 0.001, 'C': 1000, ...                8   \n",
      "37  {'kernel': 'poly', 'gamma': 0.0001, 'C': 1000,...               15   \n",
      "38  {'kernel': 'poly', 'gamma': 0.001, 'C': 1000, ...               15   \n",
      "39  {'kernel': 'poly', 'gamma': 0.0001, 'C': 1000,...               22   \n",
      "40  {'kernel': 'poly', 'gamma': 0.001, 'C': 1000, ...               29   \n",
      "41  {'kernel': 'poly', 'gamma': 0.0001, 'C': 1000,...               30   \n",
      "42  {'kernel': 'poly', 'gamma': 0.001, 'C': 1000, ...               37   \n",
      "43  {'kernel': 'poly', 'gamma': 0.0001, 'C': 1000,...               37   \n",
      "\n",
      "         ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0        ...                  1.000000            0.992593           1.000000   \n",
      "1        ...                  1.000000            0.985185           1.000000   \n",
      "2        ...                  0.933333            0.985185           1.000000   \n",
      "3        ...                  1.000000            0.985185           1.000000   \n",
      "4        ...                  0.933333            0.918519           0.933333   \n",
      "5        ...                  0.933333            0.918519           0.933333   \n",
      "6        ...                  0.933333            0.948148           1.000000   \n",
      "7        ...                  0.933333            0.918519           0.933333   \n",
      "8        ...                  1.000000            0.977778           1.000000   \n",
      "9        ...                  0.933333            0.948148           1.000000   \n",
      "10       ...                  1.000000            0.985185           1.000000   \n",
      "11       ...                  1.000000            0.977778           1.000000   \n",
      "12       ...                  0.933333            0.859259           0.866667   \n",
      "13       ...                  0.933333            0.859259           0.866667   \n",
      "14       ...                  0.800000            0.740741           0.866667   \n",
      "15       ...                  0.800000            0.740741           0.866667   \n",
      "16       ...                  0.600000            0.644444           0.600000   \n",
      "17       ...                  0.600000            0.644444           0.600000   \n",
      "18       ...                  0.600000            0.570370           0.466667   \n",
      "19       ...                  0.600000            0.570370           0.466667   \n",
      "20       ...                  0.933333            0.859259           0.866667   \n",
      "21       ...                  0.933333            0.859259           0.866667   \n",
      "22       ...                  0.800000            0.740741           0.866667   \n",
      "23       ...                  0.800000            0.740741           0.866667   \n",
      "24       ...                  0.600000            0.644444           0.600000   \n",
      "25       ...                  0.600000            0.644444           0.600000   \n",
      "26       ...                  0.600000            0.570370           0.466667   \n",
      "27       ...                  0.600000            0.570370           0.466667   \n",
      "28       ...                  0.933333            0.896296           0.933333   \n",
      "29       ...                  0.933333            0.859259           0.866667   \n",
      "30       ...                  0.800000            0.740741           0.866667   \n",
      "31       ...                  0.800000            0.740741           0.866667   \n",
      "32       ...                  0.600000            0.644444           0.600000   \n",
      "33       ...                  0.600000            0.644444           0.600000   \n",
      "34       ...                  0.600000            0.570370           0.466667   \n",
      "35       ...                  0.600000            0.570370           0.466667   \n",
      "36       ...                  0.933333            0.962963           1.000000   \n",
      "37       ...                  0.933333            0.859259           0.866667   \n",
      "38       ...                  0.933333            0.866667           0.866667   \n",
      "39       ...                  0.800000            0.740741           0.866667   \n",
      "40       ...                  0.666667            0.651852           0.600000   \n",
      "41       ...                  0.600000            0.644444           0.600000   \n",
      "42       ...                  0.600000            0.570370           0.466667   \n",
      "43       ...                  0.600000            0.570370           0.466667   \n",
      "\n",
      "    split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0             0.992593           1.000000            0.985185      0.001121   \n",
      "1             0.977778           1.000000            0.977778      0.000239   \n",
      "2             0.977778           1.000000            0.977778      0.001534   \n",
      "3             0.985185           1.000000            0.985185      0.025344   \n",
      "4             0.918519           0.933333            0.903704      0.000220   \n",
      "5             0.918519           0.933333            0.903704      0.003165   \n",
      "6             0.940741           1.000000            0.933333      0.002283   \n",
      "7             0.918519           0.933333            0.903704      0.000833   \n",
      "8             0.985185           1.000000            0.970370      0.000460   \n",
      "9             0.940741           1.000000            0.933333      0.002313   \n",
      "10            0.977778           1.000000            0.985185      0.000622   \n",
      "11            0.985185           1.000000            0.970370      0.003492   \n",
      "12            0.866667           0.800000            0.874074      0.002503   \n",
      "13            0.866667           0.800000            0.874074      0.003755   \n",
      "14            0.733333           0.600000            0.762963      0.000839   \n",
      "15            0.733333           0.600000            0.762963      0.003600   \n",
      "16            0.644444           0.400000            0.666667      0.004592   \n",
      "17            0.644444           0.400000            0.666667      0.000865   \n",
      "18            0.585185           0.400000            0.592593      0.002792   \n",
      "19            0.585185           0.400000            0.592593      0.000952   \n",
      "20            0.866667           0.800000            0.874074      0.000169   \n",
      "21            0.866667           0.800000            0.874074      0.000158   \n",
      "22            0.733333           0.600000            0.762963      0.000961   \n",
      "23            0.733333           0.600000            0.762963      0.000587   \n",
      "24            0.644444           0.400000            0.666667      0.001074   \n",
      "25            0.644444           0.400000            0.666667      0.000986   \n",
      "26            0.585185           0.400000            0.592593      0.001051   \n",
      "27            0.585185           0.400000            0.592593      0.000957   \n",
      "28            0.888889           0.800000            0.903704      0.000631   \n",
      "29            0.866667           0.800000            0.874074      0.000183   \n",
      "30            0.733333           0.600000            0.762963      0.002445   \n",
      "31            0.733333           0.600000            0.762963      0.002975   \n",
      "32            0.644444           0.400000            0.666667      0.003229   \n",
      "33            0.644444           0.400000            0.666667      0.001030   \n",
      "34            0.585185           0.400000            0.592593      0.005292   \n",
      "35            0.585185           0.400000            0.592593      0.003390   \n",
      "36            0.955556           1.000000            0.948148      0.001245   \n",
      "37            0.866667           0.800000            0.874074      0.001396   \n",
      "38            0.874074           0.800000            0.881481      0.000793   \n",
      "39            0.733333           0.600000            0.762963      0.000829   \n",
      "40            0.659259           0.400000            0.681481      0.000820   \n",
      "41            0.644444           0.400000            0.666667      0.000131   \n",
      "42            0.585185           0.400000            0.592593      0.000511   \n",
      "43            0.585185           0.400000            0.592593      0.000114   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.000402        0.044222         0.004914  \n",
      "1         0.000115        0.042687         0.006667  \n",
      "2         0.000088        0.044222         0.004969  \n",
      "3         0.000090        0.042687         0.005543  \n",
      "4         0.000038        0.061101         0.007554  \n",
      "5         0.000136        0.061101         0.007554  \n",
      "6         0.001957        0.051640         0.008249  \n",
      "7         0.000069        0.061101         0.007554  \n",
      "8         0.000657        0.030551         0.007258  \n",
      "9         0.000254        0.051640         0.008249  \n",
      "10        0.000195        0.042687         0.005785  \n",
      "11        0.000402        0.030551         0.007258  \n",
      "12        0.000705        0.059628         0.007734  \n",
      "13        0.000424        0.059628         0.007734  \n",
      "14        0.000095        0.093333         0.012593  \n",
      "15        0.000421        0.093333         0.012593  \n",
      "16        0.000136        0.130639         0.013679  \n",
      "17        0.000103        0.130639         0.013679  \n",
      "18        0.002217        0.112349         0.012744  \n",
      "19        0.000084        0.112349         0.012744  \n",
      "20        0.000074        0.059628         0.007734  \n",
      "21        0.000029        0.059628         0.007734  \n",
      "22        0.000098        0.093333         0.012593  \n",
      "23        0.000102        0.093333         0.012593  \n",
      "24        0.000098        0.130639         0.013679  \n",
      "25        0.000070        0.130639         0.013679  \n",
      "26        0.000101        0.112349         0.012744  \n",
      "27        0.000087        0.112349         0.012744  \n",
      "28        0.000090        0.060000         0.009966  \n",
      "29        0.000033        0.059628         0.007734  \n",
      "30        0.000295        0.093333         0.012593  \n",
      "31        0.000269        0.093333         0.012593  \n",
      "32        0.001000        0.130639         0.013679  \n",
      "33        0.000640        0.130639         0.013679  \n",
      "34        0.000080        0.112349         0.012744  \n",
      "35        0.000182        0.112349         0.012744  \n",
      "36        0.000388        0.053333         0.009827  \n",
      "37        0.000722        0.059628         0.007734  \n",
      "38        0.000070        0.051640         0.005926  \n",
      "39        0.000093        0.093333         0.012593  \n",
      "40        0.000063        0.135974         0.012915  \n",
      "41        0.000018        0.130639         0.013679  \n",
      "42        0.000030        0.112349         0.012744  \n",
      "43        0.000014        0.112349         0.012744  \n",
      "\n",
      "[44 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# グリッドサーチのために，パラメータの選択肢を決定する\n",
    "# polyは多項式の非線形SVMで，degreeで次数=n次関数を決定する（当然，1はlinearと変わりないので行わない）\n",
    "# この他にも各パラメータについてグリッドサーチを行える\n",
    "param_svm = [\n",
    "{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel':['poly'], 'degree': [2, 3, 4, 5], }\n",
    " ] \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# グリッドサーチ&交差検定用の学習器を設定する\n",
    "# 引数に，用いる分類器，パラメータ選択肢\n",
    "# オプションとして，cvはk分割交差検定の回数（つまり，k）\n",
    "# オプションとして，n_jobsは並列スレッド数\n",
    "from multiprocessing import cpu_count\n",
    "job = cpu_count() -1\n",
    "svm_cv = GridSearchCV(SVC(probability=True, decision_function_shape=\"ovr\"), param_svm, cv=10, n_jobs=job)\n",
    "\n",
    "# 交差検定を用いたグリッドサーチを行う\n",
    "# 引数に，特徴量と正解データ\n",
    "svm_cv.fit(iris.data, iris.target)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(svm_cv.cv_results_)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.98\n",
      "best param: {'C': 10, 'kernel': 'linear'}\n",
      "best score's index: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %svm_cv.best_estimator_)\n",
    "print(\"best socre: %s\" %svm_cv.best_score_)\n",
    "print(\"best param: %s\" %svm_cv.best_params_)\n",
    "print(\"best score's index: %s\" %svm_cv.best_index_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 得られた最良パラメータでもう一度学習してF値を見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  1 24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.96      0.96      0.96        25\n",
      "  virginica       0.96      0.96      0.96        25\n",
      "\n",
      "avg / total       0.97      0.97      0.97        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_best = SVC(C=10, kernel=\"linear\", probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "svm_best.fit(x_train, y_train)\n",
    "\n",
    "predict_best = svm_best.predict(x_test)\n",
    "matrix_best = confusion_matrix(y_test, predict_best)\n",
    "report_best = classification_report(y_test, predict_best, target_names=iris.target_names)\n",
    "\n",
    "print(predict_best)\n",
    "print(matrix_best)\n",
    "print(report_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ↑F値が0.93から0.97に上昇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN法でirisデータを分類してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.023446         0.002437         0.960000          1.000000   \n",
      "1       0.000774         0.001546         0.960000          1.000000   \n",
      "2       0.000810         0.001390         0.953333          0.978519   \n",
      "3       0.000646         0.001168         0.960000          1.000000   \n",
      "4       0.000493         0.000912         0.966667          0.960741   \n",
      "5       0.000486         0.000913         0.966667          1.000000   \n",
      "6       0.000474         0.000928         0.966667          0.963704   \n",
      "7       0.000491         0.000936         0.966667          1.000000   \n",
      "8       0.000490         0.000855         0.966667          0.968889   \n",
      "9       0.000516         0.001040         0.966667          1.000000   \n",
      "\n",
      "  param_n_neighbors param_weights                                     params  \\\n",
      "0                 1       uniform   {'n_neighbors': 1, 'weights': 'uniform'}   \n",
      "1                 1      distance  {'n_neighbors': 1, 'weights': 'distance'}   \n",
      "2                 2       uniform   {'n_neighbors': 2, 'weights': 'uniform'}   \n",
      "3                 2      distance  {'n_neighbors': 2, 'weights': 'distance'}   \n",
      "4                 3       uniform   {'n_neighbors': 3, 'weights': 'uniform'}   \n",
      "5                 3      distance  {'n_neighbors': 3, 'weights': 'distance'}   \n",
      "6                 4       uniform   {'n_neighbors': 4, 'weights': 'uniform'}   \n",
      "7                 4      distance  {'n_neighbors': 4, 'weights': 'distance'}   \n",
      "8                 5       uniform   {'n_neighbors': 5, 'weights': 'uniform'}   \n",
      "9                 5      distance  {'n_neighbors': 5, 'weights': 'distance'}   \n",
      "\n",
      "   rank_test_score  split0_test_score  split0_train_score       ...         \\\n",
      "0                7                1.0            1.000000       ...          \n",
      "1                7                1.0            1.000000       ...          \n",
      "2               10                1.0            0.970370       ...          \n",
      "3                7                1.0            1.000000       ...          \n",
      "4                1                1.0            0.955556       ...          \n",
      "5                1                1.0            1.000000       ...          \n",
      "6                1                1.0            0.955556       ...          \n",
      "7                1                1.0            1.000000       ...          \n",
      "8                1                1.0            0.962963       ...          \n",
      "9                1                1.0            1.000000       ...          \n",
      "\n",
      "   split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0           1.000000            1.000000                1.0   \n",
      "1           1.000000            1.000000                1.0   \n",
      "2           0.933333            0.977778                1.0   \n",
      "3           1.000000            1.000000                1.0   \n",
      "4           1.000000            0.955556                1.0   \n",
      "5           1.000000            1.000000                1.0   \n",
      "6           1.000000            0.962963                1.0   \n",
      "7           1.000000            1.000000                1.0   \n",
      "8           1.000000            0.962963                1.0   \n",
      "9           1.000000            1.000000                1.0   \n",
      "\n",
      "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0            1.000000                1.0            1.000000      0.034549   \n",
      "1            1.000000                1.0            1.000000      0.000122   \n",
      "2            0.977778                1.0            0.977778      0.000030   \n",
      "3            1.000000                1.0            1.000000      0.000230   \n",
      "4            0.955556                1.0            0.955556      0.000041   \n",
      "5            1.000000                1.0            1.000000      0.000039   \n",
      "6            0.955556                1.0            0.970370      0.000058   \n",
      "7            1.000000                1.0            1.000000      0.000103   \n",
      "8            0.962963                1.0            0.970370      0.000115   \n",
      "9            1.000000                1.0            1.000000      0.000022   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.001684        0.053333         0.000000  \n",
      "1        0.000117        0.053333         0.000000  \n",
      "2        0.000168        0.052068         0.005185  \n",
      "3        0.000386        0.053333         0.000000  \n",
      "4        0.000066        0.044721         0.007444  \n",
      "5        0.000082        0.044721         0.000000  \n",
      "6        0.000239        0.044721         0.006988  \n",
      "7        0.000128        0.044721         0.000000  \n",
      "8        0.000069        0.044721         0.007258  \n",
      "9        0.000174        0.044721         0.000000  \n",
      "\n",
      "[10 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_param = [\n",
    "    {'n_neighbors': [1, 2, 3, 4, 5],'weights': ['uniform', 'distance'], }\n",
    "]\n",
    "\n",
    "knn_cv = GridSearchCV(KNeighborsClassifier(), knn_param, cv=10, n_jobs=job)\n",
    "knn_cv.fit(iris.data, iris.target)\n",
    "\n",
    "df_knn = pd.DataFrame(knn_cv.cv_results_)\n",
    "print(df_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "best socre: 0.966666666667\n",
      "best param: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "best score's index: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %knn_cv.best_estimator_)\n",
    "print(\"best socre: %s\" %knn_cv.best_score_)\n",
    "print(\"best param: %s\" %knn_cv.best_params_)\n",
    "print(\"best score's index: %s\" %knn_cv.best_index_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 23  2]\n",
      " [ 0  1 24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.96      0.92      0.94        25\n",
      "  virginica       0.92      0.96      0.94        25\n",
      "\n",
      "avg / total       0.96      0.96      0.96        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, weights=\"uniform\")\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "predict_knn = knn.predict(x_test)\n",
    "matrix_knn = confusion_matrix(y_test, predict_knn)\n",
    "report_knn = classification_report(y_test, predict_knn, target_names=iris.target_names)\n",
    "\n",
    "print(predict_knn)\n",
    "print(matrix_knn)\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMでdigitsデータを分類してみる\n",
    "（おそらく）数字の手書き画像データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': array([0, 1, 2, ..., 8, 9, 8]), 'DESCR': \"Optical Recognition of Handwritten Digits Data Set\\n===================================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\nReferences\\n----------\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\", 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'data': array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
      "       ..., \n",
      "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
      "       [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'images': array([[[  0.,   0.,   5., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,  15.,   5.,   0.],\n",
      "        [  0.,   3.,  15., ...,  11.,   8.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  11., ...,  12.,   7.,   0.],\n",
      "        [  0.,   2.,  14., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   6., ...,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,   5.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,   9.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,   6.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,  10.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,  14.,   0.,   0.],\n",
      "        [  0.,   0.,   8., ...,  16.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   9.,  16., ...,   0.,   0.,   0.],\n",
      "        [  0.,   3.,  13., ...,  11.,   5.,   0.],\n",
      "        [  0.,   0.,   0., ...,  16.,   9.,   0.]],\n",
      "\n",
      "       ..., \n",
      "       [[  0.,   0.,   1., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,   2.,   1.,   0.],\n",
      "        [  0.,   0.,  16., ...,  16.,   5.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,  16., ...,  15.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  16.,   0.,   0.],\n",
      "        [  0.,   0.,   2., ...,   6.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  14., ...,  15.,   1.,   0.],\n",
      "        [  0.,   4.,  16., ...,  16.,   7.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   0., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   4., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   5., ...,  12.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,  10., ...,   1.,   0.,   0.],\n",
      "        [  0.,   2.,  16., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  15.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  16., ...,  16.,   6.,   0.],\n",
      "        [  0.,   8.,  16., ...,  16.,   8.,   0.],\n",
      "        [  0.,   1.,   8., ...,  12.,   1.,   0.]]])}\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "print(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### とりあえず表示してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADTCAYAAAChgfmQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVM64zpoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10758d978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(10) :\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(digits.images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最良パラメータをチューニングして，その評価を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
      "0        0.443201         0.012105         0.961046          1.000000       1   \n",
      "1        0.446827         0.010360         0.961046          1.000000      10   \n",
      "2        0.447012         0.009788         0.961046          1.000000     100   \n",
      "3        0.409671         0.011310         0.961046          1.000000    1000   \n",
      "4        1.058371         0.020059         0.978854          0.998887       1   \n",
      "5        0.913919         0.025540         0.954925          0.981883       1   \n",
      "6        1.059373         0.022501         0.981080          1.000000      10   \n",
      "7        0.511332         0.015265         0.969393          0.997836      10   \n",
      "8        1.033091         0.024513         0.981080          1.000000     100   \n",
      "9        0.467656         0.013597         0.971619          1.000000     100   \n",
      "10       1.139972         0.025953         0.981080          1.000000    1000   \n",
      "11       0.536867         0.012285         0.971619          1.000000    1000   \n",
      "12       0.466599         0.011473         0.974958          1.000000       1   \n",
      "13       1.557380         0.029964         0.936004          0.963953       1   \n",
      "14       0.506382         0.011941         0.978854          1.000000       1   \n",
      "15       2.067776         0.034712         0.913745          0.947074       1   \n",
      "16       0.529862         0.010892         0.976071          1.000000       1   \n",
      "17       2.802163         0.041835         0.864775          0.893649       1   \n",
      "18       0.525556         0.010540         0.973289          1.000000       1   \n",
      "19       2.959917         0.036225         0.451308          0.469216       1   \n",
      "20       0.472632         0.010523         0.972176          1.000000      10   \n",
      "21       0.733670         0.017069         0.966611          0.992951      10   \n",
      "22       0.526234         0.012951         0.978854          1.000000      10   \n",
      "23       0.732928         0.015468         0.964385          0.990416      10   \n",
      "24       0.482948         0.009621         0.976071          1.000000      10   \n",
      "25       1.024789         0.019723         0.953812          0.982872      10   \n",
      "26       0.499072         0.009128         0.973289          1.000000      10   \n",
      "27       1.756561         0.026975         0.920423          0.957028      10   \n",
      "28       0.553628         0.013048         0.972176          1.000000     100   \n",
      "29       0.477024         0.014416         0.974958          1.000000     100   \n",
      "30       0.476905         0.012296         0.978854          1.000000     100   \n",
      "31       0.483911         0.010883         0.978297          0.999938     100   \n",
      "32       0.494045         0.010232         0.976071          1.000000     100   \n",
      "33       0.543686         0.012580         0.973289          0.998825     100   \n",
      "34       0.516541         0.010934         0.973289          1.000000     100   \n",
      "35       0.689287         0.014218         0.966055          0.994374     100   \n",
      "36       0.441427         0.011606         0.972176          1.000000    1000   \n",
      "37       0.436226         0.010798         0.972176          1.000000    1000   \n",
      "38       0.475635         0.010386         0.978854          1.000000    1000   \n",
      "39       0.472586         0.009861         0.978854          1.000000    1000   \n",
      "40       0.500642         0.010343         0.976071          1.000000    1000   \n",
      "41       0.491085         0.011370         0.976071          1.000000    1000   \n",
      "42       0.489110         0.010038         0.973289          1.000000    1000   \n",
      "43       0.525997         0.009719         0.974402          1.000000    1000   \n",
      "\n",
      "   param_degree param_gamma param_kernel  \\\n",
      "0           NaN         NaN       linear   \n",
      "1           NaN         NaN       linear   \n",
      "2           NaN         NaN       linear   \n",
      "3           NaN         NaN       linear   \n",
      "4           NaN       0.001          rbf   \n",
      "5           NaN      0.0001          rbf   \n",
      "6           NaN       0.001          rbf   \n",
      "7           NaN      0.0001          rbf   \n",
      "8           NaN       0.001          rbf   \n",
      "9           NaN      0.0001          rbf   \n",
      "10          NaN       0.001          rbf   \n",
      "11          NaN      0.0001          rbf   \n",
      "12            2       0.001         poly   \n",
      "13            2      0.0001         poly   \n",
      "14            3       0.001         poly   \n",
      "15            3      0.0001         poly   \n",
      "16            4       0.001         poly   \n",
      "17            4      0.0001         poly   \n",
      "18            5       0.001         poly   \n",
      "19            5      0.0001         poly   \n",
      "20            2       0.001         poly   \n",
      "21            2      0.0001         poly   \n",
      "22            3       0.001         poly   \n",
      "23            3      0.0001         poly   \n",
      "24            4       0.001         poly   \n",
      "25            4      0.0001         poly   \n",
      "26            5       0.001         poly   \n",
      "27            5      0.0001         poly   \n",
      "28            2       0.001         poly   \n",
      "29            2      0.0001         poly   \n",
      "30            3       0.001         poly   \n",
      "31            3      0.0001         poly   \n",
      "32            4       0.001         poly   \n",
      "33            4      0.0001         poly   \n",
      "34            5       0.001         poly   \n",
      "35            5      0.0001         poly   \n",
      "36            2       0.001         poly   \n",
      "37            2      0.0001         poly   \n",
      "38            3       0.001         poly   \n",
      "39            3      0.0001         poly   \n",
      "40            4       0.001         poly   \n",
      "41            4      0.0001         poly   \n",
      "42            5       0.001         poly   \n",
      "43            5      0.0001         poly   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0                        {'C': 1, 'kernel': 'linear'}               34   \n",
      "1                       {'C': 10, 'kernel': 'linear'}               34   \n",
      "2                      {'C': 100, 'kernel': 'linear'}               34   \n",
      "3                     {'C': 1000, 'kernel': 'linear'}               34   \n",
      "4           {'C': 1, 'kernel': 'rbf', 'gamma': 0.001}                4   \n",
      "5          {'C': 1, 'kernel': 'rbf', 'gamma': 0.0001}               38   \n",
      "6          {'C': 10, 'kernel': 'rbf', 'gamma': 0.001}                1   \n",
      "7         {'C': 10, 'kernel': 'rbf', 'gamma': 0.0001}               30   \n",
      "8         {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}                1   \n",
      "9        {'C': 100, 'kernel': 'rbf', 'gamma': 0.0001}               28   \n",
      "10       {'C': 1000, 'kernel': 'rbf', 'gamma': 0.001}                1   \n",
      "11      {'C': 1000, 'kernel': 'rbf', 'gamma': 0.0001}               28   \n",
      "12  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               16   \n",
      "13  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               40   \n",
      "14  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...                4   \n",
      "15  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               42   \n",
      "16  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               11   \n",
      "17  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               43   \n",
      "18  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               19   \n",
      "19  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               44   \n",
      "20  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               24   \n",
      "21  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               31   \n",
      "22  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...                4   \n",
      "23  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               33   \n",
      "24  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               11   \n",
      "25  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               39   \n",
      "26  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               19   \n",
      "27  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               41   \n",
      "28  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               24   \n",
      "29  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               16   \n",
      "30  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...                4   \n",
      "31  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               10   \n",
      "32  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               11   \n",
      "33  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               19   \n",
      "34  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               19   \n",
      "35  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               32   \n",
      "36  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               24   \n",
      "37  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               24   \n",
      "38  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...                4   \n",
      "39  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...                4   \n",
      "40  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               11   \n",
      "41  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               11   \n",
      "42  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               19   \n",
      "43  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               18   \n",
      "\n",
      "         ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0        ...                  0.977528            1.000000           0.932203   \n",
      "1        ...                  0.977528            1.000000           0.932203   \n",
      "2        ...                  0.977528            1.000000           0.932203   \n",
      "3        ...                  0.977528            1.000000           0.932203   \n",
      "4        ...                  0.994382            0.998765           0.966102   \n",
      "5        ...                  0.988764            0.982088           0.898305   \n",
      "6        ...                  0.994382            1.000000           0.971751   \n",
      "7        ...                  0.994382            0.996912           0.937853   \n",
      "8        ...                  0.994382            1.000000           0.971751   \n",
      "9        ...                  0.994382            1.000000           0.949153   \n",
      "10       ...                  0.994382            1.000000           0.971751   \n",
      "11       ...                  0.994382            1.000000           0.949153   \n",
      "12       ...                  0.994382            1.000000           0.949153   \n",
      "13       ...                  0.971910            0.959234           0.875706   \n",
      "14       ...                  0.994382            1.000000           0.960452   \n",
      "15       ...                  0.932584            0.945028           0.853107   \n",
      "16       ...                  0.994382            1.000000           0.954802   \n",
      "17       ...                  0.887640            0.890056           0.785311   \n",
      "18       ...                  0.983146            1.000000           0.954802   \n",
      "19       ...                  0.393258            0.448425           0.389831   \n",
      "20       ...                  0.994382            1.000000           0.949153   \n",
      "21       ...                  0.994382            0.992588           0.937853   \n",
      "22       ...                  0.994382            1.000000           0.960452   \n",
      "23       ...                  0.994382            0.989500           0.926554   \n",
      "24       ...                  0.994382            1.000000           0.954802   \n",
      "25       ...                  0.983146            0.982088           0.909605   \n",
      "26       ...                  0.983146            1.000000           0.954802   \n",
      "27       ...                  0.932584            0.957999           0.875706   \n",
      "28       ...                  0.994382            1.000000           0.949153   \n",
      "29       ...                  0.994382            1.000000           0.949153   \n",
      "30       ...                  0.994382            1.000000           0.960452   \n",
      "31       ...                  0.994382            1.000000           0.960452   \n",
      "32       ...                  0.994382            1.000000           0.954802   \n",
      "33       ...                  0.994382            0.998765           0.937853   \n",
      "34       ...                  0.983146            1.000000           0.954802   \n",
      "35       ...                  1.000000            0.994441           0.937853   \n",
      "36       ...                  0.994382            1.000000           0.949153   \n",
      "37       ...                  0.994382            1.000000           0.949153   \n",
      "38       ...                  0.994382            1.000000           0.960452   \n",
      "39       ...                  0.994382            1.000000           0.960452   \n",
      "40       ...                  0.994382            1.000000           0.954802   \n",
      "41       ...                  0.994382            1.000000           0.954802   \n",
      "42       ...                  0.983146            1.000000           0.954802   \n",
      "43       ...                  0.988764            1.000000           0.954802   \n",
      "\n",
      "    split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0             1.000000           0.965909            1.000000      0.025909   \n",
      "1             1.000000           0.965909            1.000000      0.033031   \n",
      "2             1.000000           0.965909            1.000000      0.035942   \n",
      "3             1.000000           0.965909            1.000000      0.027016   \n",
      "4             0.998765           0.965909            0.999383      0.038385   \n",
      "5             0.980864           0.931818            0.983344      0.038139   \n",
      "6             1.000000           0.965909            1.000000      0.021669   \n",
      "7             0.997531           0.965909            0.998149      0.030927   \n",
      "8             1.000000           0.965909            1.000000      0.027856   \n",
      "9             1.000000           0.965909            1.000000      0.020317   \n",
      "10            1.000000           0.965909            1.000000      0.140871   \n",
      "11            1.000000           0.965909            1.000000      0.066836   \n",
      "12            1.000000           0.965909            1.000000      0.045359   \n",
      "13            0.966049           0.914773            0.965453      0.145972   \n",
      "14            1.000000           0.965909            1.000000      0.041766   \n",
      "15            0.952469           0.914773            0.943862      0.112343   \n",
      "16            1.000000           0.965909            1.000000      0.039268   \n",
      "17            0.900617           0.886364            0.895743      0.084848   \n",
      "18            1.000000           0.965909            1.000000      0.036091   \n",
      "19            0.490123           0.545455            0.479334      0.073781   \n",
      "20            1.000000           0.965909            1.000000      0.051060   \n",
      "21            0.993827           0.954545            0.993214      0.200025   \n",
      "22            1.000000           0.965909            1.000000      0.020663   \n",
      "23            0.992593           0.954545            0.991363      0.065271   \n",
      "24            1.000000           0.965909            1.000000      0.020464   \n",
      "25            0.985185           0.943182            0.982110      0.052269   \n",
      "26            1.000000           0.965909            1.000000      0.014676   \n",
      "27            0.963580           0.909091            0.951265      0.144183   \n",
      "28            1.000000           0.965909            1.000000      0.072841   \n",
      "29            1.000000           0.965909            1.000000      0.037209   \n",
      "30            1.000000           0.965909            1.000000      0.018032   \n",
      "31            1.000000           0.965909            1.000000      0.033581   \n",
      "32            1.000000           0.965909            1.000000      0.018078   \n",
      "33            0.998148           0.960227            1.000000      0.028369   \n",
      "34            1.000000           0.965909            1.000000      0.033146   \n",
      "35            0.996296           0.960227            0.993831      0.028051   \n",
      "36            1.000000           0.965909            1.000000      0.022288   \n",
      "37            1.000000           0.965909            1.000000      0.018617   \n",
      "38            1.000000           0.965909            1.000000      0.033292   \n",
      "39            1.000000           0.965909            1.000000      0.023800   \n",
      "40            1.000000           0.965909            1.000000      0.029098   \n",
      "41            1.000000           0.965909            1.000000      0.021357   \n",
      "42            1.000000           0.965909            1.000000      0.015308   \n",
      "43            1.000000           0.965909            1.000000      0.042568   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.002538        0.021980         0.000000  \n",
      "1         0.002111        0.021980         0.000000  \n",
      "2         0.001496        0.021980         0.000000  \n",
      "3         0.001520        0.021980         0.000000  \n",
      "4         0.003164        0.017952         0.000247  \n",
      "5         0.003994        0.027588         0.001387  \n",
      "6         0.004668        0.015540         0.000000  \n",
      "7         0.002242        0.025213         0.000568  \n",
      "8         0.009110        0.015540         0.000000  \n",
      "9         0.002268        0.020497         0.000000  \n",
      "10        0.008735        0.015540         0.000000  \n",
      "11        0.001718        0.020497         0.000000  \n",
      "12        0.002010        0.021610         0.000000  \n",
      "13        0.007912        0.031711         0.001988  \n",
      "14        0.001693        0.019347         0.000000  \n",
      "15        0.009644        0.031604         0.002627  \n",
      "16        0.001295        0.020023         0.000000  \n",
      "17        0.006567        0.036656         0.004636  \n",
      "18        0.001326        0.019145         0.000000  \n",
      "19        0.004100        0.059380         0.024371  \n",
      "20        0.001477        0.020555         0.000000  \n",
      "21        0.008601        0.022883         0.001304  \n",
      "22        0.002118        0.019347         0.000000  \n",
      "23        0.002493        0.024129         0.001183  \n",
      "24        0.001417        0.020023         0.000000  \n",
      "25        0.003792        0.023615         0.001040  \n",
      "26        0.001693        0.019145         0.000000  \n",
      "27        0.002638        0.025802         0.003813  \n",
      "28        0.004446        0.020555         0.000000  \n",
      "29        0.011960        0.021610         0.000000  \n",
      "30        0.002577        0.019347         0.000000  \n",
      "31        0.002096        0.019130         0.000186  \n",
      "32        0.002136        0.020023         0.000000  \n",
      "33        0.003391        0.022923         0.000513  \n",
      "34        0.001028        0.019145         0.000000  \n",
      "35        0.001812        0.022772         0.001085  \n",
      "36        0.002271        0.020555         0.000000  \n",
      "37        0.001829        0.020555         0.000000  \n",
      "38        0.001951        0.019347         0.000000  \n",
      "39        0.001623        0.019347         0.000000  \n",
      "40        0.001197        0.020023         0.000000  \n",
      "41        0.000945        0.020023         0.000000  \n",
      "42        0.001386        0.019145         0.000000  \n",
      "43        0.001181        0.019523         0.000000  \n",
      "\n",
      "[44 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "digits_cv = GridSearchCV(SVC(probability=True, decision_function_shape=\"ovr\"), param_svm, cv=10, n_jobs=job)\n",
    "digits_cv.fit(digits.data, digits.target)\n",
    "\n",
    "df_digits = pd.DataFrame(digits_cv.cv_results_)\n",
    "print(df_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.981079577073\n",
      "best param: {'C': 10, 'kernel': 'rbf', 'gamma': 0.001}\n",
      "best score's index: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %digits_cv.best_estimator_)\n",
    "print(\"best socre: %s\" %digits_cv.best_score_)\n",
    "print(\"best param: %s\" %digits_cv.best_params_)\n",
    "print(\"best score's index: %s\" %digits_cv.best_index_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最良パラメータに基づいて分類器を作成してF値で評価する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict results\n",
      "[1 3 9 7 9 1 3 5 7 9 1 3 5 7 9 9 5 5 5 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 7 5 9\n",
      " 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 1 1 3 5 7 9 1 3 5 7\n",
      " 9 1 3 5 7 9 9 5 5 9 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 3 3 1\n",
      " 6 4 1 0 3 9 1 5 4 2 2 5 4 8 9 8 8 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 9 5 5 9 9\n",
      " 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2\n",
      " 2 5 9 4 8 9 8 3 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 9 5 9 9 9 4 7 3 1 0 2 8 0 2\n",
      " 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 8 1\n",
      " 3 5 7 9 1 3 5 7 9 1 3 5 7 9 8 5 5 9 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2\n",
      " 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 8 1 3 5 7 9 1 3 5 7 9\n",
      " 1 3 5 7 9 9 5 5 9 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1\n",
      " 6 4 1 0 3 9 1 5 4 2 2 5 9 4 8 9 8 8 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9 9 5 5 9\n",
      " 9 4 7 3 1 0 2 8 0 2 3 7 3 6 6 9 5 9 2 2 0 7 3 1 4 3 3 1 6 4 1 0 3 9 1 5 4\n",
      " 2 2 5 9 4 8 9 8 8 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7 5 2 8 0 2 3\n",
      " 7 3 6 6 9 5 9 2 2 0 7 3 1 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7 5 4 0 9 0 2 4 6\n",
      " 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7 5 0 7 2 1 6 3 3 4 6 4 1 0 5 8 0 1 6\n",
      " 2 7 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7 5 8 4 0 9 0 2 4 6 8 0 2 4 6 8 0 2 4 6\n",
      " 8 0 5 6 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4 6 4 1 0 5 8 0 1 6 2 7 6 1 9 7 8 3 4\n",
      " 5 6 6 7 4 7 8 2 7 5 8 4 0 9 0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7\n",
      " 5 0 2 7 2 1 6 3 3 4 6 4 1 0 6 8 0 1 6 2 7 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7\n",
      " 5 8 4 0 0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4\n",
      " 6 4 1 0 5 8 0 1 6 2 7 6 1 9 7 8 3 4 5 6 6 7 4 7 8 2 7 5 8 4 0 9 0 2 4 6 1\n",
      " 0 2 4 6 0 2 4 6 8 4 9 6 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4 6 4 1 0 5 8 1 6 2 7\n",
      " 6 1 9 7 8 3 4 5 6 6 7 4 7 2 7 5 4 0 9 0 2 4 6 8 0 2 4 6 8 0 2 4 6 8 0 5 6\n",
      " 0 8 8 1 7 5 0 2 7 2 1 6 3 3 4 6 4 1 0 5 8 0 1 6 2 7 6 1 9 7 8 3 4 5 6 6 7\n",
      " 4 7 8 2 7 5 8 4 0 9]\n",
      "confusion matrix\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 89  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 91  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 93  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 87  1  0  0  3]\n",
      " [ 0  0  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 91  0  0]\n",
      " [ 0  2  0  0  0  0  0  0 84  0]\n",
      " [ 0  0  0  0  0  1  0  1  1 88]]\n",
      "F-measure\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.98      1.00      0.99        89\n",
      "          2       1.00      1.00      1.00        91\n",
      "          3       1.00      1.00      1.00        93\n",
      "          4       0.99      1.00      0.99        88\n",
      "          5       0.99      0.96      0.97        91\n",
      "          6       0.99      1.00      0.99        90\n",
      "          7       0.99      1.00      0.99        91\n",
      "          8       0.99      0.98      0.98        86\n",
      "          9       0.97      0.97      0.97        91\n",
      "\n",
      "avg / total       0.99      0.99      0.99       898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_digits = SVC(C=10, kernel=\"rbf\", gamma=0.001, probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "\n",
    "xd_train = digits.data[range(0, len(digits.data), 2)]\n",
    "yd_train = digits.target[range(0, len(digits.data), 2)]\n",
    "\n",
    "xd_test = digits.data[range(1, len(digits.data), 2)]\n",
    "yd_test = digits.target[range(1, len(digits.data), 2)]\n",
    "\n",
    "svm_digits.fit(xd_train, yd_train)\n",
    "\n",
    "predict_digits = svm_digits.predict(xd_test)\n",
    "matrix_digits = confusion_matrix(yd_test, predict_digits)\n",
    "report_digits = classification_report(yd_test, predict_digits)\n",
    "\n",
    "print(\"predict results\")\n",
    "print(predict_digits)\n",
    "print(\"confusion matrix\")\n",
    "print(matrix_digits)\n",
    "print(\"F-measure\")\n",
    "print(report_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次元削減\n",
    "\n",
    "特徴量が多いということは，計算コストの増大やトラッシュデータを含んでいるということに繋がる<br>\n",
    "トラッシュデータは，推定率の低下に繋がる→削ろう！\n",
    "\n",
    "### RandomForest\n",
    "決定木学習の一種で，ランダムフォレストは決定木を複数組み合わせて、各決定木の予測結果を多数決することによって結果を得る方法．<br>\n",
    "ランダムフォレストのメリットとして，相対的な特徴量の重要度を取得することができる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   importance\n",
      "sepal length (cm)    0.098198\n",
      "sepal width (cm)     0.023140\n",
      "petal length (cm)    0.436171\n",
      "petal width (cm)     0.442490\n"
     ]
    }
   ],
   "source": [
    "# ランダムフォレストで次元削減を行なう\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "\n",
    "# irisデータをランダムフォレストに学習させる\n",
    "forest = rf(n_estimators=10000, n_jobs=job)\n",
    "forest.fit(iris.data, iris.target)\n",
    "\n",
    "# 重要度を取得\n",
    "importance = pd.DataFrame(forest.feature_importances_, index=iris.feature_names, columns=[\"importance\"])\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
      "0        0.002947         0.000783         0.980000          0.982963       1   \n",
      "1        0.002088         0.000445         0.973333          0.982963      10   \n",
      "2        0.004307         0.000555         0.973333          0.980741     100   \n",
      "3        0.010002         0.000623         0.966667          0.983704    1000   \n",
      "4        0.008575         0.000634         0.900000          0.902963       1   \n",
      "5        0.008366         0.000627         0.900000          0.902963       1   \n",
      "6        0.006418         0.000905         0.940000          0.942222      10   \n",
      "7        0.008506         0.000629         0.900000          0.902963      10   \n",
      "8        0.003138         0.000544         0.973333          0.972593     100   \n",
      "9        0.005177         0.000611         0.940000          0.942222     100   \n",
      "10       0.001644         0.000332         0.973333          0.974074    1000   \n",
      "11       0.003266         0.000569         0.973333          0.972593    1000   \n",
      "12       0.007067         0.000627         0.853333          0.854074       1   \n",
      "13       0.007177         0.001063         0.853333          0.854074       1   \n",
      "14       0.006251         0.000805         0.733333          0.737037       1   \n",
      "15       0.006965         0.001755         0.733333          0.737037       1   \n",
      "16       0.011167         0.000726         0.613333          0.618519       1   \n",
      "17       0.010140         0.000708         0.613333          0.618519       1   \n",
      "18       0.006604         0.000582         0.566667          0.568889       1   \n",
      "19       0.005509         0.000497         0.566667          0.568889       1   \n",
      "20       0.004725         0.000463         0.853333          0.854074      10   \n",
      "21       0.005823         0.000565         0.853333          0.854074      10   \n",
      "22       0.007796         0.000681         0.733333          0.737037      10   \n",
      "23       0.004867         0.000476         0.733333          0.737037      10   \n",
      "24       0.005343         0.000487         0.613333          0.618519      10   \n",
      "25       0.004656         0.000448         0.613333          0.618519      10   \n",
      "26       0.004287         0.000418         0.566667          0.568889      10   \n",
      "27       0.006177         0.000566         0.566667          0.568889      10   \n",
      "28       0.004453         0.000516         0.886667          0.889630     100   \n",
      "29       0.004742         0.000482         0.853333          0.854074     100   \n",
      "30       0.004186         0.000426         0.733333          0.737037     100   \n",
      "31       0.004870         0.000481         0.733333          0.737037     100   \n",
      "32       0.005160         0.000487         0.613333          0.618519     100   \n",
      "33       0.004480         0.000445         0.613333          0.618519     100   \n",
      "34       0.004440         0.000430         0.566667          0.568889     100   \n",
      "35       0.004048         0.000405         0.566667          0.568889     100   \n",
      "36       0.001707         0.000337         0.953333          0.954815    1000   \n",
      "37       0.003506         0.000361         0.853333          0.854074    1000   \n",
      "38       0.002552         0.000348         0.860000          0.874074    1000   \n",
      "39       0.003860         0.000419         0.733333          0.737037    1000   \n",
      "40       0.003994         0.000397         0.613333          0.618519    1000   \n",
      "41       0.003662         0.000352         0.613333          0.618519    1000   \n",
      "42       0.003780         0.000361         0.566667          0.568889    1000   \n",
      "43       0.003811         0.000382         0.566667          0.568889    1000   \n",
      "\n",
      "   param_degree param_gamma param_kernel  \\\n",
      "0           NaN         NaN       linear   \n",
      "1           NaN         NaN       linear   \n",
      "2           NaN         NaN       linear   \n",
      "3           NaN         NaN       linear   \n",
      "4           NaN       0.001          rbf   \n",
      "5           NaN      0.0001          rbf   \n",
      "6           NaN       0.001          rbf   \n",
      "7           NaN      0.0001          rbf   \n",
      "8           NaN       0.001          rbf   \n",
      "9           NaN      0.0001          rbf   \n",
      "10          NaN       0.001          rbf   \n",
      "11          NaN      0.0001          rbf   \n",
      "12            2       0.001         poly   \n",
      "13            2      0.0001         poly   \n",
      "14            3       0.001         poly   \n",
      "15            3      0.0001         poly   \n",
      "16            4       0.001         poly   \n",
      "17            4      0.0001         poly   \n",
      "18            5       0.001         poly   \n",
      "19            5      0.0001         poly   \n",
      "20            2       0.001         poly   \n",
      "21            2      0.0001         poly   \n",
      "22            3       0.001         poly   \n",
      "23            3      0.0001         poly   \n",
      "24            4       0.001         poly   \n",
      "25            4      0.0001         poly   \n",
      "26            5       0.001         poly   \n",
      "27            5      0.0001         poly   \n",
      "28            2       0.001         poly   \n",
      "29            2      0.0001         poly   \n",
      "30            3       0.001         poly   \n",
      "31            3      0.0001         poly   \n",
      "32            4       0.001         poly   \n",
      "33            4      0.0001         poly   \n",
      "34            5       0.001         poly   \n",
      "35            5      0.0001         poly   \n",
      "36            2       0.001         poly   \n",
      "37            2      0.0001         poly   \n",
      "38            3       0.001         poly   \n",
      "39            3      0.0001         poly   \n",
      "40            4       0.001         poly   \n",
      "41            4      0.0001         poly   \n",
      "42            5       0.001         poly   \n",
      "43            5      0.0001         poly   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0                        {'C': 1, 'kernel': 'linear'}                1   \n",
      "1                       {'C': 10, 'kernel': 'linear'}                2   \n",
      "2                      {'C': 100, 'kernel': 'linear'}                2   \n",
      "3                     {'C': 1000, 'kernel': 'linear'}                7   \n",
      "4           {'C': 1, 'kernel': 'rbf', 'gamma': 0.001}               11   \n",
      "5          {'C': 1, 'kernel': 'rbf', 'gamma': 0.0001}               11   \n",
      "6          {'C': 10, 'kernel': 'rbf', 'gamma': 0.001}                9   \n",
      "7         {'C': 10, 'kernel': 'rbf', 'gamma': 0.0001}               11   \n",
      "8         {'C': 100, 'kernel': 'rbf', 'gamma': 0.001}                2   \n",
      "9        {'C': 100, 'kernel': 'rbf', 'gamma': 0.0001}                9   \n",
      "10       {'C': 1000, 'kernel': 'rbf', 'gamma': 0.001}                2   \n",
      "11      {'C': 1000, 'kernel': 'rbf', 'gamma': 0.0001}                2   \n",
      "12  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               16   \n",
      "13  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               16   \n",
      "14  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               22   \n",
      "15  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               22   \n",
      "16  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               29   \n",
      "17  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               29   \n",
      "18  {'C': 1, 'kernel': 'poly', 'gamma': 0.001, 'de...               37   \n",
      "19  {'C': 1, 'kernel': 'poly', 'gamma': 0.0001, 'd...               37   \n",
      "20  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               16   \n",
      "21  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               16   \n",
      "22  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               22   \n",
      "23  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               22   \n",
      "24  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               29   \n",
      "25  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               29   \n",
      "26  {'C': 10, 'kernel': 'poly', 'gamma': 0.001, 'd...               37   \n",
      "27  {'C': 10, 'kernel': 'poly', 'gamma': 0.0001, '...               37   \n",
      "28  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               14   \n",
      "29  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               16   \n",
      "30  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               22   \n",
      "31  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               22   \n",
      "32  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               29   \n",
      "33  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               29   \n",
      "34  {'C': 100, 'kernel': 'poly', 'gamma': 0.001, '...               37   \n",
      "35  {'C': 100, 'kernel': 'poly', 'gamma': 0.0001, ...               37   \n",
      "36  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...                8   \n",
      "37  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               16   \n",
      "38  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               15   \n",
      "39  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               22   \n",
      "40  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               29   \n",
      "41  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               29   \n",
      "42  {'C': 1000, 'kernel': 'poly', 'gamma': 0.001, ...               37   \n",
      "43  {'C': 1000, 'kernel': 'poly', 'gamma': 0.0001,...               37   \n",
      "\n",
      "         ...         split7_test_score  split7_train_score  split8_test_score  \\\n",
      "0        ...                  1.000000            0.985185           1.000000   \n",
      "1        ...                  1.000000            0.977778           1.000000   \n",
      "2        ...                  1.000000            0.985185           1.000000   \n",
      "3        ...                  1.000000            0.977778           1.000000   \n",
      "4        ...                  0.933333            0.896296           0.933333   \n",
      "5        ...                  0.933333            0.896296           0.933333   \n",
      "6        ...                  0.933333            0.940741           1.000000   \n",
      "7        ...                  0.933333            0.896296           0.933333   \n",
      "8        ...                  1.000000            0.970370           1.000000   \n",
      "9        ...                  0.933333            0.940741           1.000000   \n",
      "10       ...                  1.000000            0.970370           1.000000   \n",
      "11       ...                  1.000000            0.970370           1.000000   \n",
      "12       ...                  0.933333            0.844444           0.866667   \n",
      "13       ...                  0.933333            0.844444           0.866667   \n",
      "14       ...                  0.733333            0.733333           0.800000   \n",
      "15       ...                  0.733333            0.733333           0.800000   \n",
      "16       ...                  0.600000            0.614815           0.533333   \n",
      "17       ...                  0.600000            0.614815           0.533333   \n",
      "18       ...                  0.600000            0.562963           0.400000   \n",
      "19       ...                  0.600000            0.562963           0.400000   \n",
      "20       ...                  0.933333            0.844444           0.866667   \n",
      "21       ...                  0.933333            0.844444           0.866667   \n",
      "22       ...                  0.733333            0.733333           0.800000   \n",
      "23       ...                  0.733333            0.733333           0.800000   \n",
      "24       ...                  0.600000            0.614815           0.533333   \n",
      "25       ...                  0.600000            0.614815           0.533333   \n",
      "26       ...                  0.600000            0.562963           0.400000   \n",
      "27       ...                  0.600000            0.562963           0.400000   \n",
      "28       ...                  0.933333            0.881481           0.866667   \n",
      "29       ...                  0.933333            0.844444           0.866667   \n",
      "30       ...                  0.733333            0.733333           0.800000   \n",
      "31       ...                  0.733333            0.733333           0.800000   \n",
      "32       ...                  0.600000            0.614815           0.533333   \n",
      "33       ...                  0.600000            0.614815           0.533333   \n",
      "34       ...                  0.600000            0.562963           0.400000   \n",
      "35       ...                  0.600000            0.562963           0.400000   \n",
      "36       ...                  0.933333            0.955556           1.000000   \n",
      "37       ...                  0.933333            0.844444           0.866667   \n",
      "38       ...                  0.933333            0.866667           0.866667   \n",
      "39       ...                  0.733333            0.733333           0.800000   \n",
      "40       ...                  0.600000            0.614815           0.533333   \n",
      "41       ...                  0.600000            0.614815           0.533333   \n",
      "42       ...                  0.600000            0.562963           0.400000   \n",
      "43       ...                  0.600000            0.562963           0.400000   \n",
      "\n",
      "    split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
      "0             0.985185           1.000000            0.977778      0.001535   \n",
      "1             0.985185           1.000000            0.985185      0.000433   \n",
      "2             0.977778           1.000000            0.977778      0.003539   \n",
      "3             0.985185           1.000000            0.985185      0.003747   \n",
      "4             0.896296           0.866667            0.903704      0.000747   \n",
      "5             0.896296           0.866667            0.903704      0.000434   \n",
      "6             0.940741           1.000000            0.933333      0.003007   \n",
      "7             0.896296           0.866667            0.903704      0.001429   \n",
      "8             0.970370           1.000000            0.955556      0.000062   \n",
      "9             0.940741           1.000000            0.933333      0.000132   \n",
      "10            0.970370           1.000000            0.962963      0.000082   \n",
      "11            0.970370           1.000000            0.955556      0.000119   \n",
      "12            0.851852           0.733333            0.866667      0.001657   \n",
      "13            0.851852           0.733333            0.866667      0.001926   \n",
      "14            0.725926           0.600000            0.748148      0.001800   \n",
      "15            0.725926           0.600000            0.748148      0.001358   \n",
      "16            0.622222           0.400000            0.637037      0.004195   \n",
      "17            0.622222           0.400000            0.637037      0.003306   \n",
      "18            0.585185           0.400000            0.585185      0.000994   \n",
      "19            0.585185           0.400000            0.585185      0.001030   \n",
      "20            0.851852           0.733333            0.866667      0.000984   \n",
      "21            0.851852           0.733333            0.866667      0.000272   \n",
      "22            0.725926           0.600000            0.748148      0.003231   \n",
      "23            0.725926           0.600000            0.748148      0.001323   \n",
      "24            0.622222           0.400000            0.637037      0.001067   \n",
      "25            0.622222           0.400000            0.637037      0.001069   \n",
      "26            0.585185           0.400000            0.585185      0.000996   \n",
      "27            0.585185           0.400000            0.585185      0.001274   \n",
      "28            0.888889           0.866667            0.888889      0.001997   \n",
      "29            0.851852           0.733333            0.866667      0.001107   \n",
      "30            0.725926           0.600000            0.748148      0.000945   \n",
      "31            0.725926           0.600000            0.748148      0.001053   \n",
      "32            0.622222           0.400000            0.637037      0.001081   \n",
      "33            0.622222           0.400000            0.637037      0.001114   \n",
      "34            0.585185           0.400000            0.585185      0.001089   \n",
      "35            0.585185           0.400000            0.585185      0.000764   \n",
      "36            0.948148           1.000000            0.940741      0.000040   \n",
      "37            0.851852           0.733333            0.866667      0.000072   \n",
      "38            0.866667           0.800000            0.874074      0.000027   \n",
      "39            0.725926           0.600000            0.748148      0.000624   \n",
      "40            0.622222           0.400000            0.637037      0.000777   \n",
      "41            0.622222           0.400000            0.637037      0.000025   \n",
      "42            0.585185           0.400000            0.585185      0.000140   \n",
      "43            0.585185           0.400000            0.585185      0.000366   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0         0.000515        0.030551         0.007444  \n",
      "1         0.000103        0.044222         0.005785  \n",
      "2         0.000061        0.032660         0.005926  \n",
      "3         0.000079        0.044721         0.005543  \n",
      "4         0.000063        0.044721         0.009042  \n",
      "5         0.000028        0.044721         0.009042  \n",
      "6         0.000674        0.055377         0.006458  \n",
      "7         0.000048        0.044721         0.009042  \n",
      "8         0.000029        0.032660         0.010502  \n",
      "9         0.000017        0.055377         0.006458  \n",
      "10        0.000008        0.032660         0.008920  \n",
      "11        0.000052        0.032660         0.010502  \n",
      "12        0.000084        0.083267         0.007444  \n",
      "13        0.000779        0.083267         0.007444  \n",
      "14        0.000548        0.084327         0.014534  \n",
      "15        0.002084        0.084327         0.014534  \n",
      "16        0.000308        0.122202         0.019102  \n",
      "17        0.000120        0.122202         0.019102  \n",
      "18        0.000083        0.120185         0.014363  \n",
      "19        0.000085        0.120185         0.014363  \n",
      "20        0.000104        0.083267         0.007444  \n",
      "21        0.000016        0.083267         0.007444  \n",
      "22        0.000220        0.084327         0.014534  \n",
      "23        0.000117        0.084327         0.014534  \n",
      "24        0.000094        0.122202         0.019102  \n",
      "25        0.000086        0.122202         0.019102  \n",
      "26        0.000080        0.120185         0.014363  \n",
      "27        0.000061        0.120185         0.014363  \n",
      "28        0.000098        0.042687         0.007734  \n",
      "29        0.000083        0.083267         0.007444  \n",
      "30        0.000091        0.084327         0.014534  \n",
      "31        0.000106        0.084327         0.014534  \n",
      "32        0.000106        0.122202         0.019102  \n",
      "33        0.000082        0.122202         0.019102  \n",
      "34        0.000098        0.120185         0.014363  \n",
      "35        0.000101        0.120185         0.014363  \n",
      "36        0.000006        0.052068         0.010709  \n",
      "37        0.000012        0.083267         0.007444  \n",
      "38        0.000004        0.055377         0.005738  \n",
      "39        0.000124        0.084327         0.014534  \n",
      "40        0.000099        0.122202         0.019102  \n",
      "41        0.000005        0.122202         0.019102  \n",
      "42        0.000011        0.120185         0.014363  \n",
      "43        0.000077        0.120185         0.014363  \n",
      "\n",
      "[44 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# sepal widthの重要度が低いので除外してSVMで分類してみる\n",
    "\n",
    "# sepal widthを除いた特徴量のnparrayを作成する\n",
    "rf_data = np.append(iris.data[:, :1], iris.data[:, 2:], axis=1)\n",
    "rf_train = np.append(x_train[:, :1], x_train[:, 2:], axis=1)\n",
    "rf_test = np.append(x_test[:, :1], x_test[:, 2:], axis=1)\n",
    "\n",
    "# 先ほどと同じ条件でグリッドサーチを行なう\n",
    "svm_rf = GridSearchCV(SVC(probability=True, decision_function_shape=\"ovr\"), param_svm, cv=10, n_jobs=job)\n",
    "svm_rf.fit(rf_data, iris.target)\n",
    "\n",
    "df_rf = pd.DataFrame(svm_rf.cv_results_)\n",
    "print(df_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.98\n",
      "best param: {'C': 1, 'kernel': 'linear'}\n",
      "best score's index: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"best estimator: %s\" %svm_rf.best_estimator_)\n",
    "print(\"best socre: %s\" %svm_rf.best_score_)\n",
    "print(\"best param: %s\" %svm_rf.best_params_)\n",
    "print(\"best score's index: %s\" %svm_rf.best_index_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  0 25]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       1.00      0.96      0.98        25\n",
      "  virginica       0.96      1.00      0.98        25\n",
      "\n",
      "avg / total       0.99      0.99      0.99        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_bestrf = SVC(C=1, kernel=\"linear\", probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "svm_bestrf.fit(rf_train, y_train)\n",
    "\n",
    "predict_bestrf = svm_bestrf.predict(rf_test)\n",
    "matrix_bestrf = confusion_matrix(y_test, predict_bestrf)\n",
    "report_bestrf = classification_report(y_test, predict_bestrf, target_names=iris.target_names)\n",
    "\n",
    "print(predict_bestrf)\n",
    "print(matrix_bestrf)\n",
    "print(report_bestrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ↑F値が0.97から0.99に上昇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### PCA：主成分分析\n",
    "特徴量をまとめて，新しい特徴量を作り出す方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      variance_ratio\n",
      "PCA1        0.924616\n",
      "PCA2        0.053016\n",
      "PCA3        0.017185\n",
      "PCA4        0.005183\n"
     ]
    }
   ],
   "source": [
    "# PCAを使って，どの主成分を使った分類が最適か調べる\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 主成分分析を行なう\n",
    "pca = PCA()\n",
    "pca.fit(iris.data)\n",
    "# 各主成分の寄与率（主成分の数は，最大でも次元数と同じまで）\n",
    "varianceratio = pd.DataFrame(pca.explained_variance_ratio_, index=[\"PCA\" + str(i+1) for i in range(iris.data.shape[1])], columns=[\"variance_ratio\"])\n",
    "print(varianceratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.68420713e+00   3.26607315e-01  -2.15118370e-02   1.00615724e-03]\n",
      " [ -2.71539062e+00  -1.69556848e-01  -2.03521425e-01   9.96024240e-02]\n",
      " [ -2.88981954e+00  -1.37345610e-01   2.47092410e-02   1.93045428e-02]\n",
      " [ -2.74643720e+00  -3.11124316e-01   3.76719753e-02  -7.59552741e-02]\n",
      " [ -2.72859298e+00   3.33924564e-01   9.62296998e-02  -6.31287327e-02]\n",
      " [ -2.27989736e+00   7.47782713e-01   1.74325619e-01  -2.71468037e-02]\n",
      " [ -2.82089068e+00  -8.21045110e-02   2.64251085e-01  -5.00996251e-02]\n",
      " [ -2.62648199e+00   1.70405349e-01  -1.58015103e-02  -4.62817610e-02]\n",
      " [ -2.88795857e+00  -5.70798026e-01   2.73354061e-02  -2.66154143e-02]\n",
      " [ -2.67384469e+00  -1.06691704e-01  -1.91533300e-01  -5.58909660e-02]\n",
      " [ -2.50652679e+00   6.51935014e-01  -6.92749958e-02  -1.66082478e-02]\n",
      " [ -2.61314272e+00   2.15206320e-02   1.07650353e-01  -1.57704569e-01]\n",
      " [ -2.78743398e+00  -2.27740189e-01  -2.00327788e-01  -7.23508674e-03]\n",
      " [ -3.22520045e+00  -5.03279909e-01   6.84136292e-02  -2.19466641e-02]\n",
      " [ -2.64354322e+00   1.18619490e+00  -1.44505704e-01   1.56980962e-01]\n",
      " [ -2.38386932e+00   1.34475434e+00   2.83730664e-01   1.92618171e-03]\n",
      " [ -2.62252620e+00   8.18089675e-01   1.45315989e-01   1.64740791e-01]\n",
      " [ -2.64832273e+00   3.19136668e-01   3.33942541e-02   7.61182133e-02]\n",
      " [ -2.19907796e+00   8.79244088e-01  -1.14521465e-01   2.53269397e-02]\n",
      " [ -2.58734619e+00   5.20473639e-01   2.19572088e-01  -6.90819912e-02]\n",
      " [ -2.31053170e+00   3.97867822e-01  -2.33695607e-01  -1.53237396e-02]\n",
      " [ -2.54323491e+00   4.40031755e-01   2.14836370e-01   3.84395001e-02]\n",
      " [ -3.21585769e+00   1.41615572e-01   2.99618982e-01   1.85704335e-03]\n",
      " [ -2.30312854e+00   1.05522678e-01   4.56800413e-02   1.47245500e-01]\n",
      " [ -2.35617109e+00  -3.12095891e-02   1.29407576e-01  -3.01620265e-01]\n",
      " [ -2.50791723e+00  -1.39056340e-01  -2.47116338e-01   3.53840813e-02]\n",
      " [ -2.46905600e+00   1.37887315e-01   1.01263079e-01   5.59704524e-02]\n",
      " [ -2.56239095e+00   3.74684563e-01  -7.23591574e-02  -1.52402868e-02]\n",
      " [ -2.63982127e+00   3.19290066e-01  -1.39253374e-01   6.51410472e-02]\n",
      " [ -2.63284791e+00  -1.90075831e-01   4.64664636e-02  -1.24611153e-01]\n",
      " [ -2.58846205e+00  -1.97393079e-01  -7.12750731e-02  -6.04762634e-02]\n",
      " [ -2.41007734e+00   4.18080008e-01  -1.38388240e-01   2.30844170e-01]\n",
      " [ -2.64763667e+00   8.19982633e-01   2.30585604e-01  -2.84808954e-01]\n",
      " [ -2.59715948e+00   1.10002193e+00   1.63581913e-01  -9.89580706e-02]\n",
      " [ -2.67384469e+00  -1.06691704e-01  -1.91533300e-01  -5.58909660e-02]\n",
      " [ -2.86699985e+00   7.71930957e-02  -1.56842350e-01   1.62452806e-01]\n",
      " [ -2.62522846e+00   6.06800008e-01  -2.61163156e-01   1.75879875e-01]\n",
      " [ -2.67384469e+00  -1.06691704e-01  -1.91533300e-01  -5.58909660e-02]\n",
      " [ -2.98184266e+00  -4.80250049e-01   7.97248074e-02  -1.10529508e-02]\n",
      " [ -2.59032303e+00   2.36059337e-01  -7.39012382e-02  -1.45563062e-02]\n",
      " [ -2.77013891e+00   2.71059420e-01   8.42415745e-02   9.23646573e-02]\n",
      " [ -2.85221108e+00  -9.32865367e-01  -3.40961491e-01   3.22650607e-01]\n",
      " [ -2.99829644e+00  -3.34307575e-01   1.99008425e-01  -7.58718213e-02]\n",
      " [ -2.40551410e+00   1.95917258e-01   2.70717070e-01   1.73785129e-01]\n",
      " [ -2.20883295e+00   4.42696030e-01   3.03487809e-01  -1.85857530e-01]\n",
      " [ -2.71566519e+00  -2.42681483e-01  -9.05156060e-02   1.42989025e-01]\n",
      " [ -2.53757337e+00   5.10367545e-01   1.71918404e-01  -1.92165946e-01]\n",
      " [ -2.84032130e+00  -2.20576338e-01   9.00613765e-02  -6.03928106e-02]\n",
      " [ -2.54268576e+00   5.86281025e-01  -1.11752678e-02  -4.83337025e-02]\n",
      " [ -2.70391231e+00   1.15010852e-01  -8.26957266e-02   3.40995730e-02]\n",
      " [  1.28479459e+00   6.85439186e-01  -4.06129553e-01   1.92901169e-02]\n",
      " [  9.32410753e-01   3.19198090e-01  -1.71299092e-02  -6.75794171e-06]\n",
      " [  1.46406132e+00   5.04189833e-01  -3.38260728e-01  -8.57644048e-04]\n",
      " [  1.80967206e-01  -8.25603944e-01  -1.77082856e-01   9.57844484e-02]\n",
      " [  1.08713449e+00   7.53903893e-02  -3.06544465e-01   1.13384539e-01]\n",
      " [  6.40436750e-01  -4.17323483e-01   4.11887694e-02  -2.42671312e-01]\n",
      " [  1.09522371e+00   2.83891211e-01   1.70022534e-01  -8.49733893e-02]\n",
      " [ -7.51467141e-01  -1.00110751e+00   1.56721942e-02  -1.65105922e-02]\n",
      " [  1.04329778e+00   2.28956909e-01  -4.14814566e-01  -3.75235536e-02]\n",
      " [ -1.01900707e-02  -7.20574867e-01   2.83437246e-01  -5.94570198e-03]\n",
      " [ -5.11086196e-01  -1.26249195e+00  -2.66489954e-01   4.89088061e-02]\n",
      " [  5.11098061e-01  -1.02284105e-01   1.32327890e-01   5.01005352e-02]\n",
      " [  2.62335756e-01  -5.47893298e-01  -6.91941578e-01   6.14849891e-02]\n",
      " [  9.84044545e-01  -1.24360420e-01  -6.21574276e-02  -1.69010670e-01]\n",
      " [ -1.74864002e-01  -2.51815571e-01   9.36586382e-02   1.24940887e-01]\n",
      " [  9.27572942e-01   4.68236205e-01  -3.13229401e-01   1.00438884e-01]\n",
      " [  6.59592789e-01  -3.51976291e-01   3.28384297e-01  -1.88991525e-01]\n",
      " [  2.34540586e-01  -3.31921829e-01  -2.70280671e-01  -2.11984995e-01]\n",
      " [  9.42361707e-01  -5.41822258e-01  -4.97348541e-01   2.60636685e-01]\n",
      " [  4.32464003e-02  -5.81489447e-01  -2.32963556e-01  -3.95611807e-02]\n",
      " [  1.11624072e+00  -8.42140139e-02   4.59844227e-01  -7.72135596e-02]\n",
      " [  3.56786568e-01  -6.68238279e-02  -2.27472180e-01   1.24090000e-01]\n",
      " [  1.29646885e+00  -3.27561520e-01  -3.47513213e-01   3.24623910e-03]\n",
      " [  9.20502649e-01  -1.82390363e-01  -2.31611419e-01  -2.86825347e-01]\n",
      " [  7.14008214e-01   1.50379153e-01  -3.20372333e-01   4.29412332e-02]\n",
      " [  8.99640863e-01   3.29610980e-01  -3.14771481e-01   1.01122865e-01]\n",
      " [  1.33104142e+00   2.44669521e-01  -5.21244925e-01   3.75050497e-02]\n",
      " [  1.55739627e+00   2.67392585e-01  -1.64638491e-01   7.03530951e-02]\n",
      " [  8.12455549e-01  -1.62331575e-01   3.63435763e-02  -2.96802711e-02]\n",
      " [ -3.07334756e-01  -3.65086613e-01  -3.15337197e-01   7.65303776e-02]\n",
      " [ -7.03428889e-02  -7.02537932e-01  -2.41758045e-01   9.09469852e-03]\n",
      " [ -1.91884492e-01  -6.77490544e-01  -3.03916543e-01  -1.80454588e-02]\n",
      " [  1.34994950e-01  -3.11709643e-01  -1.74973304e-01   3.41829142e-02]\n",
      " [  1.37873698e+00  -4.21205138e-01   1.54804951e-02  -1.77580737e-01]\n",
      " [  5.87274854e-01  -4.83284268e-01   4.44583753e-01  -2.52442435e-01]\n",
      " [  8.07205497e-01   1.95053964e-01   3.89458711e-01  -1.16615391e-01]\n",
      " [  1.22042897e+00   4.08035337e-01  -2.36566087e-01   3.16352440e-02]\n",
      " [  8.12867790e-01  -3.70678998e-01  -6.12871050e-01   1.57700491e-01]\n",
      " [  2.45195162e-01  -2.66728036e-01   1.89562485e-01  -1.47328042e-01]\n",
      " [  1.64513428e-01  -6.79661469e-01  -5.77992388e-02   3.09655779e-02]\n",
      " [  4.63030989e-01  -6.69526547e-01  -2.40538909e-02  -2.68443508e-01]\n",
      " [  8.90160446e-01  -3.38124427e-02  -9.76802637e-03  -1.53448206e-01]\n",
      " [  2.28879050e-01  -4.02257620e-01  -2.27362705e-01   1.86204508e-02]\n",
      " [ -7.07081284e-01  -1.00842476e+00  -1.02069343e-01   4.76242978e-02]\n",
      " [  3.55533039e-01  -5.03218487e-01   1.78894659e-02  -9.80716353e-02]\n",
      " [  3.31126947e-01  -2.11180141e-01   8.38090732e-02  -2.38686542e-01]\n",
      " [  3.75238229e-01  -2.91622025e-01   7.90733555e-02  -1.31165051e-01]\n",
      " [  6.41690278e-01   1.90711765e-02  -2.04172877e-01  -2.05096763e-02]\n",
      " [ -9.08463333e-01  -7.51568725e-01  -7.73658451e-03   2.33558634e-01]\n",
      " [  2.97807907e-01  -3.47016522e-01   1.21791392e-02  -5.07837171e-02]\n",
      " [  2.53172698e+00  -1.18422366e-02   7.58458652e-01  -3.25995685e-02]\n",
      " [  1.41407223e+00  -5.74925056e-01   2.96398224e-01  -1.56954783e-02]\n",
      " [  2.61648461e+00   3.41935287e-01  -1.12141371e-01   6.59560495e-02]\n",
      " [  1.97081495e+00  -1.81125695e-01   1.06539149e-01  -2.36858625e-01]\n",
      " [  2.34975798e+00  -4.18825497e-02   2.84110681e-01  -1.31272400e-03]\n",
      " [  3.39687992e+00   5.47168046e-01  -3.51873158e-01  -1.11219968e-01]\n",
      " [  5.19383245e-01  -1.19135169e+00   5.46685531e-01  -9.87984199e-02]\n",
      " [  2.93200510e+00   3.52377006e-01  -4.23691278e-01  -2.55407369e-01]\n",
      " [  2.31967279e+00  -2.45548171e-01  -3.49922183e-01  -7.62628625e-02]\n",
      " [  2.91813423e+00   7.80380629e-01   4.21738934e-01   1.07729319e-01]\n",
      " [  1.66193495e+00   2.42038401e-01   2.42815263e-01   1.19447585e-01]\n",
      " [  1.80234045e+00  -2.16154607e-01  -3.76953285e-02   7.87134526e-02]\n",
      " [  2.16537886e+00   2.15280283e-01   3.31481832e-02   1.62667280e-01]\n",
      " [  1.34459422e+00  -7.76415425e-01   2.82868018e-01   1.40481892e-01]\n",
      " [  1.58526730e+00  -5.39307054e-01   6.30570488e-01   3.27455367e-01]\n",
      " [  1.90474358e+00   1.18818991e-01   4.80138080e-01   2.17114500e-01]\n",
      " [  1.94924878e+00   4.07302594e-02   4.27290939e-02  -1.57845252e-01]\n",
      " [  3.48876538e+00   1.17154454e+00   1.29320083e-01  -3.11629838e-01]\n",
      " [  3.79468686e+00   2.53265571e-01  -5.16970716e-01   5.64516435e-02]\n",
      " [  1.29832982e+00  -7.61013937e-01  -3.44887047e-01  -4.26737181e-02]\n",
      " [  2.42816726e+00   3.76781971e-01   2.18649070e-01   1.83854179e-01]\n",
      " [  1.19809737e+00  -6.05578962e-01   5.12640765e-01   5.95000305e-02]\n",
      " [  3.49926548e+00   4.56773467e-01  -5.76910187e-01  -1.37759598e-01]\n",
      " [  1.38766825e+00  -2.04030987e-01  -6.35113218e-02   1.63763537e-01]\n",
      " [  2.27585365e+00   3.33386526e-01   2.84678153e-01  -6.22302776e-02]\n",
      " [  2.61419383e+00   5.58366950e-01  -2.08423347e-01  -2.40445433e-01]\n",
      " [  1.25762518e+00  -1.79136997e-01   4.69778074e-02   1.47600546e-01]\n",
      " [  1.29066965e+00  -1.16425252e-01   2.31613561e-01   3.08432157e-03]\n",
      " [  2.12285398e+00  -2.10854885e-01   1.53515885e-01   5.26124332e-02]\n",
      " [  2.38756440e+00   4.62519251e-01  -4.52023961e-01  -2.29906877e-01]\n",
      " [  2.84096093e+00   3.72742591e-01  -5.01031539e-01  -2.02166254e-02]\n",
      " [  3.23234290e+00   1.37052404e+00  -1.18448777e-01  -2.54487344e-01]\n",
      " [  2.15873837e+00  -2.18325532e-01   2.08421976e-01   1.27724489e-01]\n",
      " [  1.44310260e+00  -1.43801289e-01  -1.54082971e-01  -1.89925864e-01]\n",
      " [  1.77964011e+00  -5.01464795e-01  -1.75811186e-01  -5.03529453e-01]\n",
      " [  3.07652162e+00   6.85764442e-01  -3.36422741e-01   3.10589092e-01]\n",
      " [  2.14498686e+00   1.38906609e-01   7.34184739e-01   5.17665351e-02]\n",
      " [  1.90486293e+00   4.80475082e-02   1.60470631e-01  -2.21980142e-01]\n",
      " [  1.16885347e+00  -1.64502500e-01   2.82460881e-01   1.93307656e-02]\n",
      " [  2.10765373e+00   3.71482249e-01   2.74378565e-02   2.09955199e-01]\n",
      " [  2.31430339e+00   1.82608851e-01   3.22860401e-01   2.75896660e-01]\n",
      " [  1.92245088e+00   4.09271176e-01   1.15492816e-01   5.04095007e-01]\n",
      " [  1.41407223e+00  -5.74925056e-01   2.96398224e-01  -1.56954783e-02]\n",
      " [  2.56332271e+00   2.75974502e-01   2.91253613e-01   5.61849270e-02]\n",
      " [  2.41939122e+00   3.03503938e-01   5.04302517e-01   2.38217947e-01]\n",
      " [  1.94401705e+00   1.87415222e-01   1.79302871e-01   4.25081634e-01]\n",
      " [  1.52566363e+00  -3.75020848e-01  -1.20636441e-01   2.55722565e-01]\n",
      " [  1.76404594e+00   7.85191864e-02   1.30784053e-01   1.36294556e-01]\n",
      " [  1.90162908e+00   1.15876748e-01   7.22873561e-01   4.08728218e-02]\n",
      " [  1.38966613e+00  -2.82886709e-01   3.62317832e-01  -1.56310385e-01]]\n"
     ]
    }
   ],
   "source": [
    "# どの主成分までを使うのが最適な分類結果になるのか調べる\n",
    "\n",
    "# 特徴量を主成分に変換する\n",
    "pca_data = pca.transform(iris.data)\n",
    "print(pca_data)\n",
    "\n",
    "# 学習データとテストデータに分割する\n",
    "pca_train = pca_data[range(0, len(iris.data), 2)]\n",
    "pca_test = pca_data[range(1, len(iris.data), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component = 1\n",
      "best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.94\n",
      "best param: {'kernel': 'linear', 'C': 10}\n",
      "best score's index: 1\n",
      "\n",
      "\n",
      "component = 2\n",
      "best estimator: SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.966666666667\n",
      "best param: {'kernel': 'linear', 'C': 1}\n",
      "best score's index: 0\n",
      "\n",
      "\n",
      "component = 3\n",
      "best estimator: SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.98\n",
      "best param: {'kernel': 'linear', 'C': 1}\n",
      "best score's index: 0\n",
      "\n",
      "\n",
      "component = 4\n",
      "best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "best socre: 0.98\n",
      "best param: {'kernel': 'linear', 'C': 10}\n",
      "best score's index: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(iris.data.shape[1]) :\n",
    "    print(\"component = %s\" %(i+1))\n",
    "    svm_pca = GridSearchCV(SVC(probability=True, decision_function_shape=\"ovr\"), param_svm, cv=10, n_jobs=job)\n",
    "    svm_pca.fit(pca_data[:, :i+1], iris.target)\n",
    "    #df_pca = pd.DataFrame(svm_pca.cv_results_)\n",
    "    #print(df_pca)\n",
    "    print(\"best estimator: %s\" %svm_pca.best_estimator_)\n",
    "    print(\"best socre: %s\" %svm_pca.best_score_)\n",
    "    print(\"best param: %s\" %svm_pca.best_params_)\n",
    "    print(\"best score's index: %s\" %svm_pca.best_index_)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component = 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 1 2 1 2 2 2 2 2 2 2 2 2 2\n",
      " 1]\n",
      "[[25  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  6 19]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.80      0.96      0.87        25\n",
      "  virginica       0.95      0.76      0.84        25\n",
      "\n",
      "avg / total       0.92      0.91      0.91        75\n",
      "\n",
      "component = 1\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  1 24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.96      0.96      0.96        25\n",
      "  virginica       0.96      0.96      0.96        25\n",
      "\n",
      "avg / total       0.97      0.97      0.97        75\n",
      "\n",
      "component = 2\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 1 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  3 22]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.89      0.96      0.92        25\n",
      "  virginica       0.96      0.88      0.92        25\n",
      "\n",
      "avg / total       0.95      0.95      0.95        75\n",
      "\n",
      "component = 3\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[[25  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  1 24]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        25\n",
      " versicolor       0.96      0.96      0.96        25\n",
      "  virginica       0.96      0.96      0.96        25\n",
      "\n",
      "avg / total       0.97      0.97      0.97        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 各最良パラメータで主成分を使った次元削減を試してみる\n",
    "\n",
    "# 今回はkernelは全てlinearなので，Cだけ変更する\n",
    "pca_C = (10, 1, 1, 10)\n",
    "\n",
    "for i in range(iris.data.shape[1]) :\n",
    "    print(\"component = %s\" %i)\n",
    "    svm_bestpca = SVC(C=pca_C[i], kernel=\"linear\", probability=True, decision_function_shape=\"ovr\")\n",
    "\n",
    "    svm_bestpca.fit(pca_train[:, :i+1], y_train)\n",
    "\n",
    "    predict_bestpca= svm_bestpca.predict(pca_test[:, :i+1])\n",
    "    matrix_bestpca = confusion_matrix(y_test, predict_bestpca)\n",
    "    report_bestpca = classification_report(y_test, predict_bestpca, target_names=iris.target_names)\n",
    "\n",
    "    print(predict_bestpca)\n",
    "    print(matrix_bestpca)\n",
    "    print(report_bestpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
